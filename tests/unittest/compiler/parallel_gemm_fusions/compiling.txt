INFO:aitemplate.backend.build_cache_base:Build cache disabled
2024-07-12 10:54:10,312 INFO <aitemplate.testing.detect_target> Set target to CUDA
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:54:10,513 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:54:10,513 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:54:10,515 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:54:10,515 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:54:10,515 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:54:11,181 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:54:11,184 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:54:11,184 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:54:11,184 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=0
2024-07-12 10:54:11,184 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=9
2024-07-12 10:54:11,222 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:54:11,233 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:54:11,235 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:54:11,235 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:54:11,235 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=9
2024-07-12 10:54:11,235 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,241 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:54:11,253 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:54:11,254 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:54:11,255 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:54:11,255 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,255 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,311 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:54:11,321 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:54:11,322 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:54:11,323 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,323 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,362 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:54:11,362 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,362 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,424 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:54:11,429 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:54:11,430 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:54:11,430 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,444 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:54:11,459 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:11,461 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:11,461 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:11,461 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,461 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,512 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:11,523 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:54:11,524 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:54:11,525 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:54:11,525 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,525 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,530 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:54:11,530 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,530 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,541 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:54:11,542 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:54:11,542 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:54:11,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,548 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:54:11,548 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:54:11,559 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:54:11,560 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:54:11,560 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:54:11,560 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,560 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,567 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,577 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:54:11,579 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:54:11,579 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:54:11,579 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,579 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,585 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:54:11,596 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:54:11,598 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:54:11,598 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:54:11,598 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,598 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,603 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:54:11,604 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,604 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,614 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:54:11,616 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:54:11,616 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:54:11,616 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,616 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,662 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:54:11,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,663 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,673 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:54:11,675 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:54:11,675 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:54:11,675 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,675 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,680 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:54:11,691 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:54:11,693 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:54:11,693 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:54:11,694 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,694 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,699 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:54:11,709 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:54:11,711 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:54:11,711 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:11,711 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,711 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,716 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:54:11,716 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,716 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,717 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,717 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,727 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:54:11,729 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:54:11,729 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:54:11,729 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,729 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,734 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:54:11,734 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,734 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,745 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:54:11,746 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:54:11,746 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:54:11,746 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,746 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,791 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:54:11,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,802 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:54:11,804 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:54:11,804 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:11,804 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,804 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,809 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:11,820 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:54:11,821 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:54:11,821 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:54:11,821 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,822 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,838 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:54:11,840 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:54:11,840 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:11,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,845 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:54:11,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,856 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:54:11,858 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:54:11,858 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:54:11,858 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,858 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,864 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:54:11,867 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:54:11,870 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:54:11,873 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:54:11,876 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_1', 'split_0_2', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:54:11,877 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=19
2024-07-12 10:54:11,877 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=19
2024-07-12 10:54:11,892 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:54:11,894 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:54:11,894 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:54:11,935 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=19
2024-07-12 10:54:11,935 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=19
2024-07-12 10:54:11,940 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:54:11,941 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=19
2024-07-12 10:54:11,941 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=23
2024-07-12 10:54:11,941 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=23
2024-07-12 10:54:11,941 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:11,958 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:54:11,960 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:54:11,960 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:11,961 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:11,961 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:11,967 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:54:11,984 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:54:11,986 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:54:11,986 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:54:11,987 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:11,987 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:11,993 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:54:12,009 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:54:12,011 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:54:12,011 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:54:12,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,057 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:54:12,058 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,058 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,074 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:54:12,077 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:54:12,077 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:54:12,077 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,077 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,084 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:54:12,084 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,084 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,101 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:54:12,103 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:54:12,103 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:12,104 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,104 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,112 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,112 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,112 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,112 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,128 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:54:12,130 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:54:12,130 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:12,131 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,131 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,137 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,153 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:54:12,155 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:54:12,155 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:54:12,155 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,155 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,160 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:54:12,160 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,160 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,174 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:54:12,176 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:54:12,176 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:54:12,176 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,176 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,223 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:54:12,224 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:54:12,224 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_19: total_params_size=104
2024-07-12 10:54:12,224 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,224 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,238 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:54:12,240 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:54:12,240 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:54:12,240 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,240 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,245 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:54:12,245 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:54:12,260 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:54:12,261 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:54:12,261 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:54:12,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,266 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:54:12,280 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:54:12,282 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:54:12,282 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:54:12,282 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,282 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,288 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,302 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:54:12,304 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:54:12,304 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:12,304 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,304 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,308 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:54:12,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,309 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,323 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:54:12,325 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:54:12,325 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:54:12,325 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,325 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,329 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:54:12,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,344 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:54:12,345 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:54:12,346 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:54:12,346 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,346 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,392 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:54:12,407 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:54:12,408 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:54:12,409 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:54:12,409 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,409 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,413 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:54:12,413 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.883402
2024-07-12 10:54:12,414 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:54:12,414 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 9 to 9
2024-07-12 10:54:12,428 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:54:12,430 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:54:12,430 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:54:12,430 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,430 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,435 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:54:12,435 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:54:12,471 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:54:12,472 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_21 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tt_align_8_8', 0, 1)
2024-07-12 10:54:12,472 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.037255
2024-07-12 10:54:12,472 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:12,472 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000050
2024-07-12 10:54:12,472 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:54:12,472 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_21: B == 4 && M == 512 && N == 128 && K == 64
2024-07-12 10:54:12,472 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000304
2024-07-12 10:54:12,487 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:54:12,489 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:54:12,489 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:54:12,490 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,490 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,494 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:54:12,494 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:12,494 INFO <aitemplate.compiler.transform.memory_planning> max_blob=131072 constant_offset=66560
2024-07-12 10:54:12,495 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:54:12,496 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,496 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,507 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:54:12,508 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:54:12,508 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:54:12,509 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,509 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,512 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:54:12,512 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017422
2024-07-12 10:54:12,523 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:12,524 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:12,524 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:12,524 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,525 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,527 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:12,527 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:12,528 INFO <aitemplate.compiler.transform.memory_planning> max_blob=786432 constant_offset=66560
2024-07-12 10:54:12,539 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:54:12,540 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:54:12,540 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:54:12,540 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,540 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:12,543 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:54:12,545 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:54:12,547 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:54:12,547 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:12,555 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:54:21,812 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_12.obj fused_elementwise_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_11.obj fused_elementwise_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_10.obj fused_elementwise_10.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_18_constant_folding.obj permute021_18_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_19_constant_folding.obj concatenate_19_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_16_constant_folding.obj concatenate_16_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_21.obj perm102_bmm_rrr_bias_21.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so split_0.obj fused_elementwise_10.obj fused_elementwise_11.obj fused_elementwise_12.obj fused_elementwise_13.obj perm102_bmm_rrr_bias_21.obj concatenate_16_constant_folding.obj permute021_18_constant_folding.obj concatenate_19_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:54:21,812 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:54:21,812 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:09.265138, with optimize = True
[10:54:21] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:54:21] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:54:21] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 100
2024-07-12 10:54:21,895 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:54:21,895 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:54:21,895 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:54:21,895 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:54:21,895 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:54:22,464 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:54:22,466 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:54:22,466 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:54:22,466 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=29
2024-07-12 10:54:22,466 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,472 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:54:22,483 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:54:22,484 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:54:22,484 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:54:22,484 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,484 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,525 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:54:22,535 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:54:22,537 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:54:22,537 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:54:22,537 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,537 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,554 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:54:22,555 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:54:22,555 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:54:22,555 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,556 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,561 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:54:22,561 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,561 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,571 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:54:22,573 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:54:22,573 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:54:22,573 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,573 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,579 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:54:22,589 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:22,591 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:22,591 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:22,591 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,591 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,597 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:22,608 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:54:22,609 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:54:22,609 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:54:22,609 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,609 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,656 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:54:22,656 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,656 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,667 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:54:22,668 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:54:22,668 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:54:22,668 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,668 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,674 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:54:22,674 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:54:22,684 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:54:22,686 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:54:22,686 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:54:22,686 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,686 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,693 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,703 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:54:22,705 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:54:22,705 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:54:22,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,710 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:54:22,721 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:54:22,722 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:54:22,723 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:54:22,723 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,723 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,728 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:54:22,728 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,728 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,739 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:54:22,740 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:54:22,740 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:54:22,740 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,741 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,787 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:54:22,787 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,787 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,798 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:54:22,799 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:54:22,799 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:54:22,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,805 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:54:22,816 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:54:22,817 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:54:22,817 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:54:22,818 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,818 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,823 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:54:22,834 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:54:22,835 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:54:22,836 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:22,836 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,836 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,842 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:54:22,842 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,842 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,842 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,842 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,853 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:54:22,854 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:54:22,854 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:54:22,855 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,855 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,860 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:54:22,860 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,860 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,871 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:54:22,873 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:54:22,873 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:54:22,873 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,873 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,921 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:54:22,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,921 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,932 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:54:22,934 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:54:22,934 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:22,934 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,934 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,939 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:22,950 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:54:22,952 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:54:22,952 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:54:22,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,969 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:54:22,971 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:54:22,971 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:22,971 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,971 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,977 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:54:22,977 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,977 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,987 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:54:22,989 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:54:22,989 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:54:22,989 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,989 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:22,995 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:54:22,998 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, final_set: set()
2024-07-12 10:54:23,001 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, final_set: set()
2024-07-12 10:54:23,004 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, final_set: set()
2024-07-12 10:54:23,007 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 100,
  'values': [100]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_0', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [100, 100, 100, 100]}}, final_set: set()
2024-07-12 10:54:23,008 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:23,008 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:23,023 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:54:23,024 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:54:23,025 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:54:23,025 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:23,025 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:23,074 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:54:23,075 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:23,075 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,076 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,076 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,092 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:54:23,094 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:54:23,094 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:23,095 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,095 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,101 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:54:23,118 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:54:23,120 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:54:23,120 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:54:23,120 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,120 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,127 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:54:23,144 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:54:23,146 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:54:23,146 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:54:23,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,153 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:54:23,153 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,153 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,169 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:54:23,171 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:54:23,172 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:54:23,172 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,172 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,220 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:54:23,221 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,221 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,237 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:54:23,239 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:54:23,240 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:23,240 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,240 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,264 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:54:23,266 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:54:23,266 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:23,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,273 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:54:23,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,289 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:54:23,291 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:54:23,291 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:54:23,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,297 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:54:23,297 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,297 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,311 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:54:23,313 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:54:23,313 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:54:23,313 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,313 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,318 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:54:23,318 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:54:23,318 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_19: total_params_size=104
2024-07-12 10:54:23,318 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,318 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,332 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:54:23,334 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:54:23,334 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:54:23,335 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,335 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,340 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:54:23,340 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:54:23,354 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:54:23,356 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:54:23,356 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:54:23,356 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,356 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,406 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:54:23,421 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:54:23,423 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:54:23,423 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:54:23,423 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,423 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,429 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,429 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,443 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:54:23,445 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:54:23,445 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:23,445 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,445 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,450 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:54:23,450 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,450 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,464 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:54:23,466 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:54:23,466 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:54:23,466 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,467 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,471 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:54:23,471 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,471 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,485 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:54:23,487 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:54:23,487 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:54:23,487 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,487 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,492 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:54:23,506 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:54:23,508 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:54:23,508 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:54:23,508 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,509 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,557 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:54:23,557 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.901199
2024-07-12 10:54:23,557 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:54:23,557 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 9 to 9
2024-07-12 10:54:23,572 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:54:23,573 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:54:23,574 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:54:23,574 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,574 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,578 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:54:23,579 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:54:23,615 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:54:23,615 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_21 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_4_8', 0, 1)
2024-07-12 10:54:23,615 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.036784
2024-07-12 10:54:23,615 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:23,615 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000043
2024-07-12 10:54:23,615 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:54:23,615 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_21: B == 4 && M == 512 && N == 128 && K == 100
2024-07-12 10:54:23,616 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000106
2024-07-12 10:54:23,630 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:54:23,632 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:54:23,632 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:54:23,632 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,632 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,637 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:54:23,637 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:23,637 INFO <aitemplate.compiler.transform.memory_planning> max_blob=204800 constant_offset=103424
2024-07-12 10:54:23,638 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:54:23,638 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,638 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,650 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:54:23,651 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:54:23,651 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:54:23,651 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,651 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,654 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:54:23,654 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017339
2024-07-12 10:54:23,665 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:23,667 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:23,667 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:23,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,670 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:23,670 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:23,670 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1241088 constant_offset=103424
2024-07-12 10:54:23,681 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:54:23,682 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:54:23,682 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:54:23,683 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,683 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=29
2024-07-12 10:54:23,685 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:54:23,687 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:54:23,690 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:54:23,690 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:23,700 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:54:32,409 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_1.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_11.obj fused_elementwise_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_10.obj fused_elementwise_10.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_18_constant_folding.obj permute021_18_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_12.obj fused_elementwise_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_19_constant_folding.obj concatenate_19_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_16_constant_folding.obj concatenate_16_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_21.obj perm102_bmm_rrr_bias_21.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_1.so split_0.obj fused_elementwise_12.obj fused_elementwise_11.obj fused_elementwise_10.obj fused_elementwise_13.obj perm102_bmm_rrr_bias_21.obj concatenate_16_constant_folding.obj permute021_18_constant_folding.obj concatenate_19_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:54:32,410 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:54:32,410 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.719411, with optimize = True
[10:54:32] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:54:32] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:54:32] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 100, k: 32
2024-07-12 10:54:32,433 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:54:32,434 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:54:32,435 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:54:32,435 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:54:32,435 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:54:33,052 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:54:33,054 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:54:33,054 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:54:33,055 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=29
2024-07-12 10:54:33,055 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,060 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:54:33,070 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:54:33,072 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:54:33,072 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:54:33,072 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,072 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,114 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:54:33,124 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:54:33,126 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:54:33,126 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:54:33,126 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,126 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,131 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,132 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,143 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:54:33,144 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:54:33,144 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:54:33,144 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,144 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,150 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:54:33,150 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,150 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,161 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:54:33,162 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:54:33,162 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:54:33,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,168 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:54:33,179 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:33,180 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:33,180 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:33,181 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,181 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,186 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:33,197 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:54:33,198 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:54:33,198 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:54:33,198 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,198 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,204 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:54:33,204 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,204 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,214 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:54:33,216 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:54:33,216 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:54:33,216 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,216 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,265 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:54:33,265 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:54:33,275 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:54:33,277 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:54:33,277 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:54:33,277 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,277 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,282 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,294 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:54:33,296 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:54:33,296 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:54:33,296 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,296 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,301 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:54:33,312 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:54:33,314 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:54:33,314 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:54:33,314 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,314 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,319 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:54:33,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,320 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,330 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:54:33,332 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:54:33,332 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:54:33,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,338 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:54:33,338 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,338 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,349 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:54:33,350 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:54:33,350 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:54:33,351 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,351 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,400 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:54:33,411 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:54:33,412 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:54:33,412 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:54:33,413 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,413 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,418 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:54:33,429 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:54:33,430 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:54:33,430 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:33,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,436 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:54:33,436 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,436 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,437 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,437 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,447 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:54:33,448 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:54:33,448 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:54:33,448 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,448 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,454 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:54:33,454 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,454 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,464 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:54:33,466 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:54:33,466 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:54:33,466 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,466 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,472 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:54:33,472 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,472 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,482 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:54:33,484 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:54:33,484 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:33,484 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,484 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,489 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:33,500 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:54:33,501 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:54:33,501 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:54:33,502 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,502 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,550 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,551 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,551 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,562 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:54:33,563 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:54:33,563 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:33,564 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,564 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,569 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:54:33,569 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,569 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,579 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:54:33,581 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:54:33,581 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:54:33,581 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,581 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,587 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:54:33,590 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:54:33,594 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:54:33,597 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:54:33,600 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_3', 'split_0_0', 'split_0_2', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:54:33,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=29
2024-07-12 10:54:33,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:33,616 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:54:33,617 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:54:33,618 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:54:33,618 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:33,618 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:33,623 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:54:33,624 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=29
2024-07-12 10:54:33,624 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=29
2024-07-12 10:54:33,624 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=29
2024-07-12 10:54:33,624 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,640 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:54:33,642 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:54:33,642 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:33,642 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,642 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,649 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:54:33,665 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:54:33,667 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:54:33,668 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:54:33,711 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,712 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,718 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:54:33,734 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:54:33,736 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:54:33,736 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:54:33,736 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,743 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:54:33,743 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,743 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,759 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:54:33,761 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:54:33,761 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:54:33,761 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,761 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,768 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:54:33,768 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,768 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,784 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:54:33,786 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:54:33,786 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:33,786 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,786 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,792 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,809 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:54:33,811 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:54:33,811 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:33,812 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,812 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,865 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:54:33,865 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,865 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,881 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:54:33,882 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:54:33,883 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:54:33,883 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,883 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,888 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:54:33,888 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,888 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,901 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:54:33,903 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:54:33,903 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:54:33,903 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,903 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,908 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:54:33,908 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:54:33,908 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_18: total_params_size=104
2024-07-12 10:54:33,908 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,908 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,921 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:54:33,923 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:54:33,923 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:54:33,923 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,923 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,928 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:54:33,928 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:54:33,942 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:54:33,944 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:54:33,944 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:54:33,944 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,944 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,949 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:54:33,962 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:54:33,964 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:54:33,964 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:54:33,964 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,964 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,969 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,970 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,983 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:54:33,985 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:54:33,985 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:33,985 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:33,985 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,032 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:54:34,032 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,032 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,046 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:54:34,048 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:54:34,048 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:54:34,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,053 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:54:34,053 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,053 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,067 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:54:34,068 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:54:34,068 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:54:34,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,073 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:54:34,087 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:54:34,089 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:54:34,089 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:54:34,089 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,089 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,093 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:54:34,093 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.889677
2024-07-12 10:54:34,093 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:54:34,093 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 8 to 8
2024-07-12 10:54:34,107 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:54:34,109 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:54:34,109 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:54:34,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,113 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:54:34,113 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:54:34,151 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:54:34,151 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_20 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_4', 0, 1)
2024-07-12 10:54:34,151 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.037567
2024-07-12 10:54:34,151 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:34,151 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000067
2024-07-12 10:54:34,151 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:54:34,151 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_20: B == 4 && M == 256 && N == 100 && K == 32
2024-07-12 10:54:34,151 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000068
2024-07-12 10:54:34,164 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:54:34,166 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:54:34,166 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:54:34,166 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,166 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,213 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:54:34,213 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:34,213 INFO <aitemplate.compiler.transform.memory_planning> max_blob=26432 constant_offset=26624
2024-07-12 10:54:34,213 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:54:34,214 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,214 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,225 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:54:34,227 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:54:34,227 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:54:34,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,230 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:54:34,230 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.016761
2024-07-12 10:54:34,241 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:34,243 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:34,243 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:34,243 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,243 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,246 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:34,246 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:34,246 INFO <aitemplate.compiler.transform.memory_planning> max_blob=270336 constant_offset=26432
2024-07-12 10:54:34,257 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:54:34,258 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:54:34,258 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:54:34,259 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,259 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=32
2024-07-12 10:54:34,262 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:54:34,263 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:54:34,267 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:54:34,267 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:34,280 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:54:42,231 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_2.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_12.obj fused_elementwise_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_10.obj fused_elementwise_10.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_11.obj fused_elementwise_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_18_constant_folding.obj concatenate_18_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_16_constant_folding.obj concatenate_16_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_20.obj perm102_bmm_rcr_bias_20.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_2.so split_0.obj fused_elementwise_13.obj fused_elementwise_10.obj fused_elementwise_12.obj fused_elementwise_11.obj perm102_bmm_rcr_bias_20.obj concatenate_16_constant_folding.obj concatenate_18_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:54:42,231 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:54:42,231 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.964589, with optimize = True
[10:54:42] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:54:42] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:54:42] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 16, ms: [15, 31], n: 7, k: 5
2024-07-12 10:54:42,256 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:54:42,257 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:54:42,258 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:54:42,258 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:54:42,258 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:54:42,952 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:54:42,959 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:54:42,960 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:54:42,960 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=32
2024-07-12 10:54:42,961 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=56
2024-07-12 10:54:43,020 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:54:43,060 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:54:43,065 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:54:43,066 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:54:43,066 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=56
2024-07-12 10:54:43,066 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,085 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:54:43,127 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:54:43,132 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:54:43,133 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:54:43,133 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,133 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,202 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:54:43,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,203 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,244 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:54:43,249 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:54:43,250 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:54:43,250 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,250 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,315 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:54:43,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,357 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:54:43,362 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:54:43,363 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:54:43,363 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,363 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,383 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:54:43,425 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:43,430 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:43,430 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:43,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,499 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:43,540 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:54:43,545 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:54:43,546 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:54:43,547 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,547 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,610 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:54:43,610 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,610 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,652 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:54:43,657 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:54:43,657 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:54:43,658 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,658 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,723 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:54:43,723 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:54:43,765 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:54:43,770 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:54:43,770 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:54:43,771 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,771 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,790 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,792 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,792 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,792 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,792 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,832 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:54:43,838 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:54:43,838 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:54:43,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,910 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:54:43,951 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:54:43,956 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:54:43,956 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:54:43,957 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:43,957 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,023 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:54:44,023 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,023 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,064 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:54:44,069 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:54:44,070 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:54:44,070 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,070 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,136 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:54:44,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,178 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:54:44,183 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:54:44,183 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:54:44,183 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,184 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,203 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:54:44,244 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:54:44,249 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:54:44,249 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:54:44,249 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,249 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,320 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:54:44,361 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:54:44,367 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:54:44,367 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:44,368 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,368 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,434 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:54:44,435 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,435 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,435 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,435 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,475 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:54:44,480 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:54:44,481 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:54:44,481 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,481 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,500 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:54:44,501 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,501 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,541 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:54:44,546 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:54:44,546 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:54:44,547 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,547 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,617 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:54:44,617 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,617 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,658 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:54:44,663 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:54:44,663 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:44,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,664 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,727 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:44,767 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:54:44,772 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:54:44,773 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:54:44,773 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,773 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,844 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:54:44,844 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,844 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,844 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,844 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,887 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:54:44,892 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:54:44,893 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:44,893 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,893 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,913 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:54:44,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,953 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:54:44,958 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:54:44,959 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:54:44,959 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:44,959 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:45,028 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:54:45,041 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,054 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,066 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,079 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,092 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,104 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,117 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,129 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,142 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,154 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,167 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,179 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,192 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,204 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,217 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,229 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_14',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_14_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_12',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_12_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_4_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_5',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_5_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_6',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_6_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_16'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_15',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_15_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_7',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_7_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_9',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_9_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_8',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_8_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_11',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_11_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_10',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_10_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_13',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'split_0_13_dim_1',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [ True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True,
                    True],
  'outputs': [ 'split_0_14',
               'split_0_12',
               'split_0_4',
               'split_0_0',
               'split_0_2',
               'split_0_5',
               'split_0_6',
               'split_0_15',
               'split_0_7',
               'split_0_9',
               'split_0_8',
               'split_0_1',
               'split_0_11',
               'split_0_3',
               'split_0_10',
               'split_0_13'],
  'split_dim': 1,
  'split_sizes': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}}, final_set: set()
2024-07-12 10:54:45,231 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=34, tensor_cnt=0, len(func_name_to_tensor_cnt)=34, len(user_provided_dim)=80
2024-07-12 10:54:45,231 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=50, tensor_cnt=0, len(func_name_to_tensor_cnt)=50, len(user_provided_dim)=80
2024-07-12 10:54:45,296 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:54:45,304 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:54:45,304 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:54:45,304 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=50, tensor_cnt=0, len(func_name_to_tensor_cnt)=50, len(user_provided_dim)=80
2024-07-12 10:54:45,304 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=50, tensor_cnt=0, len(func_name_to_tensor_cnt)=50, len(user_provided_dim)=80
2024-07-12 10:54:45,377 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:54:45,379 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=50, tensor_cnt=0, len(func_name_to_tensor_cnt)=50, len(user_provided_dim)=80
2024-07-12 10:54:45,379 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=84
2024-07-12 10:54:45,379 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=84
2024-07-12 10:54:45,379 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,431 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:54:45,438 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:54:45,438 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:54:45,439 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,439 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,503 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:54:45,555 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:54:45,561 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:54:45,561 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:54:45,562 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,562 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,580 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:54:45,630 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:54:45,636 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:54:45,636 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:54:45,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,704 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:54:45,704 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, alignment_var_to_padding_length: 
 {'K': 1, 'N': 1} 

2024-07-12 10:54:45,707 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['reshape_51'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'concatenate_50_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'concatenate_50_0_dim_1',
  'nop': False,
  'symbolic_value': 80,
  'values': [80]}],
  'skip_constant_folding': False,
  'src_ops': ['concatenate_50'],
  'value': None},
  'name': 'reshape_51_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_51_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['reshape_51'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 5,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:54:45,708 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'permute021_54_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_53_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]},
             { 'depth': 0,
  'name': 'reshape_53_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': ['permute021_54'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             { 'depth': 0,
  'name': 'reshape_53_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:54:45,708 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             { 'depth': 0,
  'name': 'reshape_53_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 5,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:54:45,709 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['reshape_56'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'concatenate_55_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'concatenate_55_0_dim_0',
  'nop': False,
  'symbolic_value': 112,
  'values': [112]}],
  'skip_constant_folding': False,
  'src_ops': ['concatenate_55'],
  'value': None},
  'name': 'reshape_56_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_56_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_56_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': ['reshape_56'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['perm102_bmm_rrr_bias_57'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_56_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:54:45,711 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace op 
 { 'alpha': 1.0,
  'depth': 4,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 1,
  'f_ab_alignment': <function perm102_bmm_rrr.__init__.<locals>.cal_align_ab at 0x7f7a10ec9d00>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_51_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_53_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]},
                       { 'depth': 0,
  'name': 'reshape_53_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_56_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_56_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['reshape_51_0', 'permute021_54_0', 'reshape_56_0'],
  'name': 'perm102_bmm_rrr_bias_57',
  'nop': False,
  'num_sources': 0,
  'op': 'perm102_bmm_rrr_bias',
  'original_name': 'perm102_bmm_rrr_bias_57',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_53_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['perm102_bmm_rrr_bias_57_0'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0} 
 with 
 { 'alpha': 1.0,
  'depth': 5,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'f_ab_alignment': <function perm102_bmm_rrr.__init__.<locals>.cal_align_ab at 0x7f7a1f3f3ba0>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_53_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_56_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': [None, None, None],
  'name': None,
  'nop': False,
  'num_sources': 0,
  'op': 'perm102_bmm_rrr_bias',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_51_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': [None],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0} 

2024-07-12 10:54:45,711 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=59, tensor_cnt=0, len(func_name_to_tensor_cnt)=59, len(user_provided_dim)=90
2024-07-12 10:54:45,711 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=92
2024-07-12 10:54:45,764 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:54:45,771 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:54:45,771 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:54:45,772 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=92
2024-07-12 10:54:45,772 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,843 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:54:45,844 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,844 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,899 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:54:45,906 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:54:45,906 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:54:45,907 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,907 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,926 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:54:45,926 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,926 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,926 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,926 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,927 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,928 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,982 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:54:45,989 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:54:45,989 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:45,990 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:45,990 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,091 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:54:46,092 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,092 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,093 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,094 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,095 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:54:46,095 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:54:46,095 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:54:46,095 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,095 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,096 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,097 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,098 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,098 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,099 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,099 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,100 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,100 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,101 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,101 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,102 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,102 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,215 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:54:46,250 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:54:46,256 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:54:46,282 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,282 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,434 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:54:46,434 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,434 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,484 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:54:46,502 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:54:46,505 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:54:46,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,523 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,591 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_52: total_params_size=120
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_55: total_params_size=104
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_59: total_params_size=120
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_60: total_params_size=136
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_61: total_params_size=136
2024-07-12 10:54:46,591 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_62: total_params_size=104
2024-07-12 10:54:46,592 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,592 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,694 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:54:46,867 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:54:46,869 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:54:46,917 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:46,918 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,092 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:54:47,092 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:54:47,143 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:54:47,165 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:54:47,177 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:54:47,200 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,301 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:54:47,423 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:54:47,487 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:54:47,505 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:54:47,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,710 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:54:47,711 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,711 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,712 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,712 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,713 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,713 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,714 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,714 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,715 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,715 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,716 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,716 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,717 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,717 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,718 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,720 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,720 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,840 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:54:47,854 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:54:47,866 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:54:47,895 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:47,896 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,073 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:54:48,074 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,074 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,217 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:54:48,314 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:54:48,350 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:54:48,353 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,354 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,455 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:54:48,455 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,559 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:54:48,565 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:54:48,568 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:54:48,575 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,575 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,655 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:54:48,710 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:54:48,716 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:54:48,716 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:54:48,716 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,716 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,777 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:54:48,777 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:05.167206
2024-07-12 10:54:48,777 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:54:48,777 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 27 to 27
2024-07-12 10:54:48,827 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:54:48,833 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:54:48,834 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:54:48,834 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,834 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,851 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:54:48,851 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:54:48,889 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:54:48,889 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_63 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tt_align_2_8', 0, 1)
2024-07-12 10:54:48,889 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038044
2024-07-12 10:54:48,889 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:48,889 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000073
2024-07-12 10:54:48,889 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:54:48,889 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_63: B == 16 && M == 31 && N == 8 && K == 6
2024-07-12 10:54:48,889 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000077
2024-07-12 10:54:48,942 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:54:48,948 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:54:48,949 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:54:48,949 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:48,949 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,015 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:54:49,015 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:49,015 INFO <aitemplate.compiler.transform.memory_planning> max_blob=4288 constant_offset=3584
2024-07-12 10:54:49,016 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:54:49,018 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,018 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,055 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:54:49,058 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:54:49,059 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:54:49,059 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,059 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,068 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:54:49,068 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.053272
2024-07-12 10:54:49,105 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:54:49,109 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:54:49,109 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:54:49,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,118 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:54:49,118 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:54:49,118 INFO <aitemplate.compiler.transform.memory_planning> max_blob=14912 constant_offset=2816
2024-07-12 10:54:49,154 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:54:49,158 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:54:49,158 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:54:49,159 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,159 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=65, tensor_cnt=4, len(func_name_to_tensor_cnt)=65, len(user_provided_dim)=99
2024-07-12 10:54:49,215 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:54:49,219 INFO <aitemplate.backend.codegen> generated 21 function srcs
2024-07-12 10:54:49,224 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:54:49,224 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:54:49,232 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:00,426 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_3.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o reshape_58.obj reshape_58.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_38.obj fused_elementwise_38.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_36.obj fused_elementwise_36.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_46.obj fused_elementwise_46.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_45.obj fused_elementwise_45.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_34.obj fused_elementwise_34.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_41.obj fused_elementwise_41.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_48.obj fused_elementwise_48.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_47.obj fused_elementwise_47.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_39.obj fused_elementwise_39.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_35.obj fused_elementwise_35.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_49.obj fused_elementwise_49.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_43.obj fused_elementwise_43.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_44.obj fused_elementwise_44.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_54_constant_folding.obj permute021_54_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_40.obj fused_elementwise_40.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_42.obj fused_elementwise_42.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o dynamic_slice_64.obj dynamic_slice_64.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_37.obj fused_elementwise_37.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_59.obj concatenate_59.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_55_constant_folding.obj concatenate_55_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_52_constant_folding.obj concatenate_52_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_60_constant_folding.obj concatenate_60_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_62_constant_folding.obj concatenate_62_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_61_constant_folding.obj concatenate_61_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_63.obj perm102_bmm_rrr_bias_63.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_3.so split_0.obj fused_elementwise_48.obj fused_elementwise_46.obj fused_elementwise_38.obj fused_elementwise_34.obj fused_elementwise_36.obj fused_elementwise_39.obj fused_elementwise_40.obj fused_elementwise_49.obj fused_elementwise_41.obj fused_elementwise_43.obj fused_elementwise_42.obj fused_elementwise_35.obj fused_elementwise_45.obj fused_elementwise_37.obj fused_elementwise_44.obj fused_elementwise_47.obj concatenate_59.obj perm102_bmm_rrr_bias_63.obj dynamic_slice_64.obj reshape_58.obj concatenate_52_constant_folding.obj permute021_54_constant_folding.obj concatenate_55_constant_folding.obj concatenate_60_constant_folding.obj concatenate_61_constant_folding.obj concatenate_62_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:00,427 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:00,427 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:11.202849, with optimize = True
[10:55:00] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:00] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:00] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 100, k: 32
2024-07-12 10:55:00,446 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:00,446 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:00,446 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:00,446 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:00,446 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:01,033 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:55:01,035 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:55:01,035 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:55:01,036 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=99
2024-07-12 10:55:01,036 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=103
2024-07-12 10:55:01,043 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:55:01,055 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:55:01,057 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:55:01,057 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:55:01,057 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=103
2024-07-12 10:55:01,057 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,064 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:55:01,077 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:55:01,079 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:55:01,079 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:01,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,141 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:55:01,143 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:55:01,143 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:01,143 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,143 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,150 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:55:01,150 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,150 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,163 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:55:01,164 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:55:01,165 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:55:01,165 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,165 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,172 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:55:01,184 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:01,186 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:01,187 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:01,187 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,187 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,194 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:01,207 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:55:01,209 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:55:01,209 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:01,209 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,209 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,263 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:55:01,263 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,263 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,275 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:01,277 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:01,278 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:01,278 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,278 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,284 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:01,284 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:01,297 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:01,299 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:01,299 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:01,299 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,299 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,320 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:01,322 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:01,322 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:01,322 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,322 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,329 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:01,342 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:01,345 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:01,345 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:01,346 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,346 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,402 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:01,402 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,402 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,414 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:01,416 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:01,416 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:01,417 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,417 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,423 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:01,424 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,424 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,436 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:01,438 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:55:01,438 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:01,438 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,438 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,445 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:01,458 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:01,460 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:01,460 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:01,460 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,460 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,467 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:01,479 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:01,481 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:01,481 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:01,481 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,481 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,533 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:01,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,546 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:01,548 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:01,548 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:01,549 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,549 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,556 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:01,556 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,556 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,568 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:01,570 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:01,570 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:01,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,577 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:01,577 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,577 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,590 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:01,591 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:01,592 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:01,592 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,592 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,599 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:01,611 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:55:01,613 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:55:01,613 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:01,614 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,614 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,666 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,679 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:55:01,681 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:55:01,681 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:01,682 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,682 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,688 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:01,688 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,688 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,702 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:55:01,703 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:55:01,704 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:01,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,711 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:55:01,714 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:55:01,717 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:55:01,721 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:55:01,724 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_0', 'split_0_2', 'split_0_1', 'split_0_3'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:55:01,724 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=107
2024-07-12 10:55:01,724 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=107
2024-07-12 10:55:01,741 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:55:01,745 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:55:01,746 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:01,747 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=107
2024-07-12 10:55:01,747 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=107
2024-07-12 10:55:01,761 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:01,762 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=107
2024-07-12 10:55:01,762 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=108
2024-07-12 10:55:01,762 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=108
2024-07-12 10:55:01,762 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,799 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:01,814 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:01,816 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:01,817 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,817 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,915 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:01,934 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:55:01,936 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:55:01,936 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:01,937 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,937 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,944 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:01,963 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:55:01,965 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:55:01,965 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:01,966 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,966 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,973 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:01,973 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,973 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,991 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:55:01,994 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:55:01,994 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:01,994 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:01,994 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,049 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:55:02,050 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,050 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,068 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:02,070 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:02,071 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:02,071 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,071 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,080 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,098 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:55:02,100 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:55:02,100 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:02,101 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,101 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,110 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,125 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:55:02,127 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:55:02,127 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:02,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,131 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:02,131 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,131 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,146 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:02,148 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:02,148 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:02,148 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,148 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,200 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:02,200 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_20: total_params_size=120
2024-07-12 10:55:02,200 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_22: total_params_size=104
2024-07-12 10:55:02,200 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,200 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,215 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:02,217 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:55:02,217 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:02,217 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,217 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,222 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:02,222 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:55:02,237 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:55:02,239 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:55:02,239 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:02,240 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,240 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,244 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:02,259 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:02,261 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:02,261 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:02,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,266 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:02,266 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,266 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,266 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,266 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,282 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:55:02,284 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:55:02,284 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:02,285 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,285 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,289 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:02,289 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,289 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,304 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:55:02,306 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:55:02,306 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:02,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,310 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:02,310 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,310 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,325 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:02,327 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:02,327 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:02,327 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,327 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,382 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:02,397 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:55:02,398 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:55:02,399 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:55:02,399 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,399 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,403 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:55:02,403 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.140580
2024-07-12 10:55:02,403 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:02,403 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 8 to 8
2024-07-12 10:55:02,418 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:55:02,420 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:55:02,420 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:55:02,421 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,421 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,425 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:55:02,425 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:02,463 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:55:02,463 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_24 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_4', 0, 1)
2024-07-12 10:55:02,463 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038073
2024-07-12 10:55:02,463 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:02,463 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000045
2024-07-12 10:55:02,463 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:02,463 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_24: B == 4 && M == 256 && N == 100 && K == 32
2024-07-12 10:55:02,463 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000097
2024-07-12 10:55:02,479 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:55:02,481 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:55:02,481 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:55:02,481 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,481 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,486 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:55:02,486 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:02,486 INFO <aitemplate.compiler.transform.memory_planning> max_blob=26432 constant_offset=26624
2024-07-12 10:55:02,486 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:55:02,487 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,487 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,499 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:55:02,500 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:55:02,500 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:55:02,500 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,500 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,504 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:55:02,504 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017869
2024-07-12 10:55:02,515 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:02,516 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:02,516 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:02,517 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,517 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,519 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:02,519 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:02,519 INFO <aitemplate.compiler.transform.memory_planning> max_blob=270336 constant_offset=26432
2024-07-12 10:55:02,531 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:55:02,532 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:55:02,532 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:55:02,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=116
2024-07-12 10:55:02,535 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:55:02,537 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:55:02,540 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:02,540 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:02,555 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:10,499 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_4.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_16.obj fused_elementwise_16.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_14.obj fused_elementwise_14.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_17.obj fused_elementwise_17.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_15.obj fused_elementwise_15.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_20_constant_folding.obj concatenate_20_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_22_constant_folding.obj concatenate_22_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_24.obj perm102_bmm_rcr_bias_24.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_4.so split_0.obj fused_elementwise_14.obj fused_elementwise_16.obj fused_elementwise_15.obj fused_elementwise_17.obj perm102_bmm_rcr_bias_24.obj concatenate_20_constant_folding.obj concatenate_22_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:10,499 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:10,499 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.959027, with optimize = True
[10:55:10] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:10] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:10] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:55:10,505 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:10,505 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:10,505 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:10,505 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:10,505 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:11,226 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:55:11,227 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:55:11,227 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:55:11,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=116
2024-07-12 10:55:11,228 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,232 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:55:11,242 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:55:11,243 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:55:11,243 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:55:11,244 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,244 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,248 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:55:11,258 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:55:11,259 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:55:11,259 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:11,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,307 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:55:11,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,318 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:55:11,319 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:55:11,319 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:11,320 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,320 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,324 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:55:11,324 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,324 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,334 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:55:11,335 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:55:11,336 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:55:11,336 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,336 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,340 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:55:11,350 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:11,352 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:11,352 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:11,352 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,352 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,356 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:11,366 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:55:11,368 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:55:11,368 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:11,368 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,368 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,372 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:55:11,372 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,372 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,382 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:11,383 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:11,383 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:11,384 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,384 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,388 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:11,388 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:11,398 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:11,399 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:11,399 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:11,400 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,400 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,405 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,405 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,415 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:11,416 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:11,416 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:11,416 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,416 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,465 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:11,476 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:11,477 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:11,477 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:11,477 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,477 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,482 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:11,482 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,482 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,492 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:11,493 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:11,493 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:11,494 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,494 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,498 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:11,498 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,498 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,508 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:11,509 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:55:11,510 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:11,510 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,510 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,514 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:11,524 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:11,525 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:11,525 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:11,526 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,526 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,530 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:11,540 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:11,541 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:11,541 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:11,541 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,541 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,546 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:11,546 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,546 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,546 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,546 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,556 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:11,557 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:11,557 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:11,558 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,558 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,562 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:11,562 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,562 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,571 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:11,573 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:11,573 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:11,573 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,573 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,621 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:11,621 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,621 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,631 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:11,632 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:11,633 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:11,633 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,633 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,637 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:11,647 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:55:11,649 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:55:11,649 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:11,649 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,649 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,654 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,664 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:55:11,665 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:55:11,665 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:11,665 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,665 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,670 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:11,670 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,670 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,680 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:55:11,681 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:55:11,681 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:11,681 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,681 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,686 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:55:11,686 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,686 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,696 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:55:11,698 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:55:11,698 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:11,698 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,698 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,702 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:11,702 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,702 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,702 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=116
2024-07-12 10:55:11,702 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=119
2024-07-12 10:55:11,713 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:11,715 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:11,715 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:11,715 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=119
2024-07-12 10:55:11,715 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,763 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:11,774 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:55:11,776 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:55:11,776 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:11,777 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,777 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,782 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:11,793 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:55:11,794 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:55:11,795 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:11,795 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,795 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,800 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:11,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,812 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:55:11,813 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:55:11,813 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:11,813 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,814 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,819 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:55:11,819 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,819 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,830 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:11,832 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:11,832 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:11,832 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,832 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,848 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:55:11,849 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:55:11,849 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:11,849 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,849 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,853 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,854 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,861 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:55:11,861 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:55:11,862 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:11,862 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,862 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,865 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:11,865 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,865 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,871 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:11,872 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:11,872 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:11,872 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,872 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,921 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:11,921 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_8: total_params_size=120
2024-07-12 10:55:11,921 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_11: total_params_size=104
2024-07-12 10:55:11,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,921 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,927 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:11,928 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:55:11,928 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:11,928 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,928 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,931 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:11,937 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:55:11,938 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:55:11,938 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:11,938 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,938 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,941 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:11,947 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:11,948 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:11,948 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:11,948 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,948 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,951 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:11,951 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,958 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:55:11,959 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:55:11,959 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:11,959 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,960 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,962 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:11,963 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,963 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,969 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:55:11,970 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:55:11,970 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:11,970 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,970 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,973 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:11,973 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,973 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,979 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:11,980 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:11,980 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:11,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,983 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:11,989 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:55:11,990 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:55:11,990 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:55:11,990 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,990 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:11,993 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:55:11,994 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.621379
2024-07-12 10:55:11,994 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:11,994 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 4 to 4
2024-07-12 10:55:12,000 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:55:12,001 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:55:12,001 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:55:12,001 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,001 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,004 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:55:12,004 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:12,041 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:55:12,041 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_13 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tt_align_8_8', 0, 1)
2024-07-12 10:55:12,041 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.037375
2024-07-12 10:55:12,042 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:12,042 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000041
2024-07-12 10:55:12,042 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:12,042 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_13: B == 4 && M == 512 && N == 128 && K == 64
2024-07-12 10:55:12,042 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000065
2024-07-12 10:55:12,048 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:55:12,049 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:55:12,049 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:55:12,049 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,049 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,052 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:55:12,052 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:12,052 INFO <aitemplate.compiler.transform.memory_planning> max_blob=131072 constant_offset=66560
2024-07-12 10:55:12,053 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:55:12,054 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,054 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,057 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:55:12,057 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:55:12,057 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:55:12,058 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,058 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,058 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:55:12,058 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.006087
2024-07-12 10:55:12,062 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:12,062 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:12,062 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:12,063 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,063 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,064 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:12,064 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:12,064 INFO <aitemplate.compiler.transform.memory_planning> max_blob=786432 constant_offset=66560
2024-07-12 10:55:12,067 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:55:12,067 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:55:12,067 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:55:12,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=125
2024-07-12 10:55:12,068 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:55:12,069 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:55:12,071 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:12,071 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:12,084 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:19,363 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_5.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_10_constant_folding.obj permute021_10_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_11_constant_folding.obj concatenate_11_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_8_constant_folding.obj concatenate_8_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_13.obj perm102_bmm_rrr_bias_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_5.so perm102_bmm_rrr_bias_13.obj concatenate_8_constant_folding.obj permute021_10_constant_folding.obj concatenate_11_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:19,363 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:19,364 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.292774, with optimize = True
[10:55:19] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:19] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:19] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 100, k: 32
2024-07-12 10:55:19,373 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:19,374 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:19,374 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:19,374 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:19,374 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:19,947 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:55:19,995 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:55:20,036 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:55:20,049 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=125
2024-07-12 10:55:20,049 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,090 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:55:20,154 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:55:20,183 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:55:20,202 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:55:20,242 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,242 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,280 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:55:20,345 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:55:20,355 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:55:20,366 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:20,384 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,385 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,521 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:55:20,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,523 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,523 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,523 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,523 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,524 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,524 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,583 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:55:20,598 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:55:20,619 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:20,645 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,646 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,683 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:55:20,683 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,683 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,748 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:55:20,763 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:55:20,776 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:55:20,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,843 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:55:20,907 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:20,918 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:20,953 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:20,962 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,963 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:20,993 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:21,057 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:55:21,073 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:55:21,084 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:21,104 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,104 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,151 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:55:21,151 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,152 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,206 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:21,213 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:21,235 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:21,264 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,264 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,301 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:21,301 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:21,365 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:21,391 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:21,401 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:21,416 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,416 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,563 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:21,563 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,563 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,564 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,564 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,564 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,564 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,565 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,565 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,565 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,565 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,566 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,566 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,567 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,567 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,567 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,567 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,567 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,622 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:21,626 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:21,627 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:21,627 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,627 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,638 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:21,654 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:21,655 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:21,655 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:21,656 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,656 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,660 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:21,660 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,660 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,670 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:21,671 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:21,672 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:21,672 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,672 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,676 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:21,676 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,676 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,686 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:21,687 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:55:21,687 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:21,687 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,688 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,692 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:21,702 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:21,703 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:21,703 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:21,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,708 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:21,718 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:21,719 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:21,719 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:21,720 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,720 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,724 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:21,724 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,724 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,724 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,724 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,734 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:21,735 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:21,735 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:21,736 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,736 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,783 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:21,783 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,783 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,793 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:21,794 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:21,795 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:21,795 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,795 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,799 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:21,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,809 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:21,810 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:21,811 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:21,811 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,811 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,815 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:21,825 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:55:21,826 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:55:21,826 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:21,826 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,826 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,831 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,832 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,832 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,841 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:55:21,843 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:55:21,843 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:21,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,848 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:21,848 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,848 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,858 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:55:21,860 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:55:21,860 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:21,860 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,860 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,864 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:55:21,864 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,864 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,874 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:55:21,875 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:55:21,875 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:21,876 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,876 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,880 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:21,880 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,880 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,881 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=125
2024-07-12 10:55:21,881 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=125
2024-07-12 10:55:21,891 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:21,893 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:21,893 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:21,893 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=125
2024-07-12 10:55:21,893 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,941 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:21,952 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:55:21,954 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:55:21,954 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:21,954 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,954 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,960 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:21,970 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:55:21,971 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:55:21,972 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:21,972 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,972 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,977 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:21,977 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,977 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,988 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:55:21,989 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:55:21,989 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:21,989 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,990 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,994 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:55:21,995 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:21,995 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,005 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:22,006 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:22,007 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:22,007 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,007 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,013 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,020 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:55:22,021 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:55:22,021 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:22,021 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,022 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,025 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:22,025 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,032 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:55:22,033 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:55:22,033 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:22,033 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,033 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,079 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:22,079 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,079 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,085 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:22,086 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:22,086 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:22,086 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,086 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,089 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:22,089 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_8: total_params_size=120
2024-07-12 10:55:22,089 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_10: total_params_size=104
2024-07-12 10:55:22,089 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,089 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,094 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:22,095 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:55:22,095 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:22,096 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,096 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,098 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:22,104 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:55:22,105 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:55:22,105 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:22,105 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,105 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,107 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:22,113 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:22,114 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:22,114 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:22,114 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,114 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,117 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,123 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:55:22,124 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:55:22,124 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:22,124 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,124 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,126 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:22,126 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,126 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,132 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:55:22,133 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:55:22,133 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:22,133 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,133 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,136 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:22,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,141 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:22,142 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:22,142 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:22,143 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,143 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,145 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:22,151 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:55:22,151 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:55:22,151 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:55:22,152 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,152 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,154 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:55:22,154 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.003057
2024-07-12 10:55:22,154 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:22,154 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 3 to 3
2024-07-12 10:55:22,160 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:55:22,161 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:55:22,161 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:55:22,161 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,161 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,164 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:55:22,164 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:22,201 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:55:22,201 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_12 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_4', 0, 1)
2024-07-12 10:55:22,201 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.037731
2024-07-12 10:55:22,201 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:22,201 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000045
2024-07-12 10:55:22,201 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:22,201 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_12: B == 4 && M == 256 && N == 100 && K == 32
2024-07-12 10:55:22,201 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000069
2024-07-12 10:55:22,207 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:55:22,208 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:55:22,208 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:55:22,208 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,209 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,211 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:55:22,211 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:22,211 INFO <aitemplate.compiler.transform.memory_planning> max_blob=26432 constant_offset=26624
2024-07-12 10:55:22,212 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:55:22,212 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,212 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,216 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:55:22,216 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:55:22,216 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:55:22,216 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,216 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,217 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:55:22,217 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.006257
2024-07-12 10:55:22,221 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:22,221 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:22,221 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:22,221 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,221 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,223 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:22,223 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:22,223 INFO <aitemplate.compiler.transform.memory_planning> max_blob=270336 constant_offset=26432
2024-07-12 10:55:22,226 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:55:22,226 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:55:22,227 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:55:22,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=128
2024-07-12 10:55:22,228 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:55:22,228 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:55:22,231 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:22,231 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:22,251 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:29,815 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_6.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_10_constant_folding.obj concatenate_10_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_8_constant_folding.obj concatenate_8_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_12.obj perm102_bmm_rcr_bias_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_6.so perm102_bmm_rcr_bias_12.obj concatenate_8_constant_folding.obj concatenate_10_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:29,815 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:29,816 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.584760, with optimize = True
[10:55:29] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:29] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:29] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 16, ms: [15, 31], n: 7, k: 5
2024-07-12 10:55:29,841 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:29,842 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:29,843 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:29,843 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:29,843 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:30,564 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:55:30,568 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:55:30,568 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:55:30,569 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=128
2024-07-12 10:55:30,569 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,620 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:55:30,658 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:55:30,662 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:55:30,663 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:55:30,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,663 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,677 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:55:30,715 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:55:30,720 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:55:30,720 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:30,721 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,721 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,780 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,818 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:55:30,823 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:55:30,823 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:30,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,884 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:55:30,884 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,885 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,923 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:55:30,927 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:55:30,928 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:55:30,928 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,928 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,942 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:55:30,980 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:30,985 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:30,985 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:30,985 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:30,985 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,048 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:31,087 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:55:31,091 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:55:31,092 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:31,092 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,092 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,107 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:55:31,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,147 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:31,152 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:31,152 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:31,153 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,153 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,214 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:31,214 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:31,252 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:31,257 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:31,257 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:31,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,272 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:31,272 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,272 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,272 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,272 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,312 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:31,317 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:31,317 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:31,318 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,318 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,382 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:31,421 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:31,426 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:31,426 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:31,426 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,426 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,485 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:31,485 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,485 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,523 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:31,528 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:31,528 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:31,528 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,528 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,542 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:31,542 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,542 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,582 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:31,587 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:55:31,587 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:31,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,651 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:31,690 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:31,695 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:31,695 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:31,695 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,695 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,709 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:31,748 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:31,753 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:31,753 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:31,754 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,754 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,816 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:31,816 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,816 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,817 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,817 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,855 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:31,860 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:31,860 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:31,861 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,861 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,875 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:31,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,914 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:31,919 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:31,919 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:31,919 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,919 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,982 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:31,982 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:31,982 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,020 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:32,025 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:32,025 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:32,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,040 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:32,078 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:55:32,082 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:55:32,083 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:32,083 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,083 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,145 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:32,145 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,145 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,146 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,147 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,147 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,147 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,147 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,147 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,186 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:55:32,190 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:55:32,191 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:32,191 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,191 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,205 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:32,205 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,205 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,243 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:55:32,248 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:55:32,248 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:32,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,310 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:55:32,310 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,310 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,348 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:55:32,353 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:55:32,353 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:32,354 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,354 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,369 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:32,369 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,369 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,370 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=128
2024-07-12 10:55:32,370 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=128
2024-07-12 10:55:32,398 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:32,401 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:32,401 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:32,402 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=128
2024-07-12 10:55:32,402 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,459 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:32,488 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:55:32,492 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:55:32,492 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:32,492 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,492 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,504 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:32,533 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:55:32,537 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:55:32,537 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:32,537 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,537 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,593 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:32,593 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, alignment_var_to_padding_length: 
 {'K': 1, 'N': 1} 

2024-07-12 10:55:32,597 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['reshape_19'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'concatenate_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'concatenate_18_0_dim_1',
  'nop': False,
  'symbolic_value': 80,
  'values': [80]}],
  'skip_constant_folding': False,
  'src_ops': ['concatenate_18'],
  'value': None},
  'name': 'reshape_19_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_19_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'skip_constant_folding': False,
  'src_ops': ['reshape_19'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
             { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:55:32,597 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'permute021_22_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_21_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]},
             { 'depth': 0,
  'name': 'reshape_21_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': ['permute021_22'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             { 'depth': 0,
  'name': 'reshape_21_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:55:32,597 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 4,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             { 'depth': 0,
  'name': 'reshape_21_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 5,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:55:32,598 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace input tensor 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['reshape_24'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'concatenate_23_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'concatenate_23_0_dim_0',
  'nop': False,
  'symbolic_value': 112,
  'values': [112]}],
  'skip_constant_folding': False,
  'src_ops': ['concatenate_23'],
  'value': None},
  'name': 'reshape_24_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_24_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'skip_constant_folding': False,
  'src_ops': ['reshape_24'],
  'value': None} 
 with 
 { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['perm102_bmm_rrr_bias_25'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': None,
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'reshape_24_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
             {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'skip_constant_folding': False,
  'src_ops': [None],
  'value': None} 

2024-07-12 10:55:32,600 DEBUG <aitemplate.compiler.transform.apply_padding> **** Apply padding ****, replace op 
 { 'alpha': 1.0,
  'depth': 3,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 1,
  'f_ab_alignment': <function perm102_bmm_rrr.__init__.<locals>.cal_align_ab at 0x7f7a1114a520>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_19_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_21_0_dim_2',
  'nop': False,
  'symbolic_value': 5,
  'values': [5]},
                       { 'depth': 0,
  'name': 'reshape_21_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_24_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['reshape_19_0', 'permute021_22_0', 'reshape_24_0'],
  'name': 'perm102_bmm_rrr_bias_25',
  'nop': False,
  'num_sources': 0,
  'op': 'perm102_bmm_rrr_bias',
  'original_name': 'perm102_bmm_rrr_bias_25',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       { 'depth': 0,
  'name': 'reshape_21_0_dim_1',
  'nop': False,
  'symbolic_value': 7,
  'values': [7]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['perm102_bmm_rrr_bias_25_0'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0} 
 with 
 { 'alpha': 1.0,
  'depth': 5,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'f_ab_alignment': <function perm102_bmm_rrr.__init__.<locals>.cal_align_ab at 0x7f7a10a6aa20>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_21_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 6, 'values': [6]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'reshape_24_0_dim_0',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': [None, None, None],
  'name': None,
  'nop': False,
  'num_sources': 0,
  'op': 'perm102_bmm_rrr_bias',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1]), ([2], [2])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [15, 31]},
                       { 'depth': 0,
  'name': 'reshape_19_0_dim_1',
  'nop': False,
  'symbolic_value': 16,
  'values': [16]},
                       {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 8, 'values': [8]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': [None],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0} 

2024-07-12 10:55:32,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=27, tensor_cnt=0, len(func_name_to_tensor_cnt)=27, len(user_provided_dim)=131
2024-07-12 10:55:32,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=133
2024-07-12 10:55:32,633 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:55:32,637 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:55:32,638 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:32,638 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=133
2024-07-12 10:55:32,638 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,694 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:55:32,695 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,695 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,728 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:32,733 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:32,733 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:32,733 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,733 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,747 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:32,747 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,747 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,747 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,747 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,748 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,768 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:55:32,771 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:55:32,771 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:32,771 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,771 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,781 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:32,781 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,781 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,781 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,781 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,781 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,801 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:55:32,804 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:55:32,804 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:32,804 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,804 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,869 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:32,869 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,869 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,888 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:32,890 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:32,891 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:32,891 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,891 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,900 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_20: total_params_size=120
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_23: total_params_size=104
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_27: total_params_size=120
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_28: total_params_size=136
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_29: total_params_size=136
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_30: total_params_size=104
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,900 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,919 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:32,921 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:55:32,921 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:32,922 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,922 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,931 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:32,949 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:55:32,952 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:55:32,952 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:32,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:32,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,006 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:33,025 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:33,027 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:33,028 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:33,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,037 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,056 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:55:33,059 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:55:33,059 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:33,059 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,060 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,112 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:33,112 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,112 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,130 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:55:33,133 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:55:33,133 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:33,133 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,133 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,142 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:33,142 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,142 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,161 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:33,164 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:33,164 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:33,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,173 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:33,192 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:55:33,194 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:55:33,195 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:55:33,195 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,195 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,250 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:55:33,250 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:02.143310
2024-07-12 10:55:33,250 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:33,250 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 10 to 10
2024-07-12 10:55:33,269 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:55:33,272 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:55:33,272 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:55:33,272 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,272 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,281 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:55:33,281 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:33,318 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:55:33,318 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_31 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tt_align_2_8', 0, 1)
2024-07-12 10:55:33,318 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.036956
2024-07-12 10:55:33,318 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:33,318 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000044
2024-07-12 10:55:33,318 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:33,318 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_31: B == 16 && M == 31 && N == 8 && K == 6
2024-07-12 10:55:33,318 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000065
2024-07-12 10:55:33,337 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:55:33,340 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:55:33,340 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:55:33,340 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,341 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,350 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:55:33,350 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:33,350 INFO <aitemplate.compiler.transform.memory_planning> max_blob=4288 constant_offset=3584
2024-07-12 10:55:33,351 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:55:33,352 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,352 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,357 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:55:33,358 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:55:33,358 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:55:33,359 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,359 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,361 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:55:33,361 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.011055
2024-07-12 10:55:33,366 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:33,366 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:33,366 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:33,367 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,367 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,369 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:33,369 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:33,369 INFO <aitemplate.compiler.transform.memory_planning> max_blob=14912 constant_offset=2816
2024-07-12 10:55:33,374 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:55:33,375 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:55:33,375 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:55:33,375 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,375 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=33, tensor_cnt=4, len(func_name_to_tensor_cnt)=33, len(user_provided_dim)=136
2024-07-12 10:55:33,424 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:55:33,424 INFO <aitemplate.backend.codegen> generated 4 function srcs
2024-07-12 10:55:33,428 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:33,428 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:33,436 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:42,415 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_7.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o reshape_26.obj reshape_26.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o dynamic_slice_32.obj dynamic_slice_32.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_22_constant_folding.obj permute021_22_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_28_constant_folding.obj concatenate_28_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_27.obj concatenate_27.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_29_constant_folding.obj concatenate_29_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_23_constant_folding.obj concatenate_23_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_30_constant_folding.obj concatenate_30_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_20_constant_folding.obj concatenate_20_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_31.obj perm102_bmm_rrr_bias_31.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_7.so concatenate_27.obj perm102_bmm_rrr_bias_31.obj dynamic_slice_32.obj reshape_26.obj concatenate_20_constant_folding.obj permute021_22_constant_folding.obj concatenate_23_constant_folding.obj concatenate_28_constant_folding.obj concatenate_29_constant_folding.obj concatenate_30_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:42,415 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:42,415 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.987065, with optimize = True
[10:55:42] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:42] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:42] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 16, ms: [1024, 2048], n: 100, k: 128
2024-07-12 10:55:42,449 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:42,450 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:42,451 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:42,451 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:42,451 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:43,096 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:55:43,101 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:55:43,101 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:55:43,102 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=136
2024-07-12 10:55:43,102 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,153 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:55:43,191 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:55:43,195 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:55:43,196 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:55:43,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,210 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:55:43,248 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:55:43,253 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:55:43,253 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:43,254 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,254 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,311 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:55:43,311 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,311 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,312 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,352 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:55:43,357 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:55:43,357 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:43,357 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,357 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,416 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:55:43,416 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,416 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,454 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:55:43,458 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:55:43,459 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:55:43,459 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,459 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,473 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:55:43,511 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:43,516 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:43,516 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:43,517 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,517 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,578 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:43,617 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:55:43,621 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:55:43,622 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:43,622 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,622 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,636 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:55:43,636 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,636 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,675 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:43,680 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:43,680 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:43,681 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,681 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,741 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:43,741 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:43,780 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:43,785 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:43,785 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:43,786 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,786 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,799 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,801 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,840 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:43,845 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:43,845 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:43,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,907 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:43,945 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:43,950 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:43,950 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:43,950 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:43,950 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,010 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:44,010 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,010 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,049 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:44,053 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:44,054 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:44,054 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,054 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,068 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:44,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,107 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:44,112 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:55:44,112 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:44,113 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,175 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:44,214 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:44,218 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:44,219 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:44,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,219 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,233 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:44,272 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:44,277 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:44,277 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:44,278 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,278 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,346 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:44,346 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,347 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,348 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,348 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,386 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:44,391 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:44,391 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:44,392 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,392 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,406 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:44,406 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,406 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,444 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:44,449 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:44,449 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:44,450 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,450 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,514 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:44,514 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,514 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,552 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:44,556 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:44,557 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:44,557 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,557 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,571 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:44,609 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:55:44,614 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:55:44,614 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:44,614 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,614 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,676 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,677 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,678 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,678 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,716 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:55:44,721 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:55:44,721 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:44,721 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,721 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,735 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:44,735 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,735 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,774 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:55:44,779 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:55:44,779 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:44,779 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,779 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,842 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:55:44,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,881 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:55:44,886 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:55:44,886 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:44,887 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,887 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,901 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:44,901 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,902 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,903 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=136
2024-07-12 10:55:44,903 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:44,931 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:44,935 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:44,935 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:44,936 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:44,936 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:44,993 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:45,022 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:55:45,025 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:55:45,026 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:45,026 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,026 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,037 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:45,065 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:55:45,069 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:55:45,069 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:45,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,124 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:45,125 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,125 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,153 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:55:45,157 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:55:45,157 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:45,157 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,157 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,169 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:55:45,169 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,169 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,197 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:45,201 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:45,201 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:45,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,256 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:45,256 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,256 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,257 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,258 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,258 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,272 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:55:45,275 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:55:45,275 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:45,275 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,275 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,283 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,284 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,284 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,297 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:55:45,299 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:55:45,299 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:45,299 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,299 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,355 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:45,355 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,355 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,368 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:45,370 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:45,370 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:45,371 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,371 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,377 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:45,377 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_20: total_params_size=120
2024-07-12 10:55:45,377 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_22: total_params_size=104
2024-07-12 10:55:45,377 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,377 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,390 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:45,392 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:55:45,392 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:45,393 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,393 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,399 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:45,412 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:55:45,414 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:55:45,414 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:45,414 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,414 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,421 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:45,434 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:45,436 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:45,436 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:45,436 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,436 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,443 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,456 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:55:45,458 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:55:45,458 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:45,459 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,459 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,511 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:45,511 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,511 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,525 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:55:45,526 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:55:45,527 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:45,527 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,527 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,533 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:45,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,546 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:45,548 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:45,548 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:45,549 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,549 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,555 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:45,568 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:55:45,570 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:55:45,570 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:55:45,570 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,570 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,576 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:55:45,576 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.940150
2024-07-12 10:55:45,576 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:45,576 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 3 to 3
2024-07-12 10:55:45,590 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:55:45,592 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:55:45,592 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:55:45,592 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,592 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,598 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:55:45,598 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:45,683 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:55:45,683 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_24 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x128_32x3_tn_align_8_4', 0, 1)
2024-07-12 10:55:45,683 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.084921
2024-07-12 10:55:45,683 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:45,683 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000055
2024-07-12 10:55:45,683 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:45,683 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_24: B == 16 && M == 2048 && N == 100 && K == 128
2024-07-12 10:55:45,683 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000107
2024-07-12 10:55:45,697 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:55:45,699 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:55:45,700 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:55:45,700 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,700 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,707 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:55:45,708 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:45,708 INFO <aitemplate.compiler.transform.memory_planning> max_blob=412800 constant_offset=413696
2024-07-12 10:55:45,708 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:55:45,709 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,709 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,713 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:55:45,714 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:55:45,714 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:55:45,714 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,714 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,715 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:55:45,715 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.008045
2024-07-12 10:55:45,719 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:55:45,719 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:55:45,719 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:45,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,720 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:45,720 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:45,720 INFO <aitemplate.compiler.transform.memory_planning> max_blob=14942208 constant_offset=412800
2024-07-12 10:55:45,724 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:55:45,724 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:55:45,724 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:55:45,724 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,724 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:45,726 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:55:45,726 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:55:45,730 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:45,730 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:45,741 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:55:53,406 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_8.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_22_constant_folding.obj concatenate_22_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_20_constant_folding.obj concatenate_20_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_24.obj perm102_bmm_rcr_bias_24.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_8.so perm102_bmm_rcr_bias_24.obj concatenate_20_constant_folding.obj concatenate_22_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:55:53,406 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:55:53,406 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.676547, with optimize = True
[10:55:53] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:55:53] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:55:53] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_2_split_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:55:53,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=136
2024-07-12 10:55:53,432 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=136
2024-07-12 10:55:53,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=136
2024-07-12 10:55:53,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=146
.INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:55:53,436 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:55:53,436 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:55:53,437 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:55:53,438 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:55:53,438 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:55:54,158 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:55:54,159 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:55:54,159 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:55:54,160 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=146
2024-07-12 10:55:54,160 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,165 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:55:54,176 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:55:54,178 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:55:54,178 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:55:54,178 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,178 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,183 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:55:54,194 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:55:54,196 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:55:54,196 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:55:54,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,213 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:55:54,214 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:55:54,215 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:55:54,215 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,215 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,261 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:55:54,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,272 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:55:54,273 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:55:54,273 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:55:54,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,279 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:55:54,289 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:55:54,291 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:55:54,291 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:54,291 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,291 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,297 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:54,307 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:55:54,309 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:55:54,309 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:55:54,309 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,309 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,314 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:55:54,314 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,314 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,325 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:55:54,326 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:55:54,326 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:55:54,327 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,327 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,333 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:55:54,333 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:55:54,344 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:55:54,346 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:55:54,346 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:55:54,346 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,346 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,396 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:55:54,396 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,396 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,396 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,396 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,396 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,397 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,408 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:55:54,409 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:55:54,410 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:55:54,410 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,410 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,415 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:55:54,426 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:55:54,427 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:55:54,427 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:55:54,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,433 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:55:54,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,444 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:55:54,445 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:55:54,445 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:55:54,445 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,446 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,451 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:55:54,451 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,451 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,462 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:55:54,463 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:55:54,463 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:55:54,464 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,464 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,469 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:55:54,480 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:55:54,482 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:55:54,482 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:55:54,482 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,482 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,489 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:55:54,508 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:55:54,511 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:55:54,511 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:54,512 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,512 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,628 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:55:54,628 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,628 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,629 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,629 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,643 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:55:54,645 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:55:54,645 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:55:54,645 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,645 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,650 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:55:54,651 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,651 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,661 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:55:54,663 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:55:54,663 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:55:54,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,663 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,669 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:55:54,669 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,669 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,679 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:55:54,681 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:55:54,681 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:54,681 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,681 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,686 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:54,697 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:55:54,698 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:55:54,699 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:55:54,699 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,699 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,716 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:55:54,717 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:55:54,717 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:54,762 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,762 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,767 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:55:54,768 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,768 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,778 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:55:54,780 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:55:54,780 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:55:54,780 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,780 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,786 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:55:54,789 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:55:54,793 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:55:54,796 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:55:54,799 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_1', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:55:54,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:55:54,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:55:54,815 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:55:54,817 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:55:54,817 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:55:54,817 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:55:54,817 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:55:54,823 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:55:54,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:55:54,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,840 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:55:54,843 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:55:54,843 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:55:54,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,850 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:55:54,867 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:55:54,869 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:55:54,869 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:55:54,870 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,870 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,920 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:55:54,936 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:55:54,939 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:55:54,939 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:55:54,939 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,939 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,946 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:55:54,946 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,946 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,962 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:55:54,965 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:55:54,965 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:55:54,965 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,965 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,971 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:55:54,971 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,972 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,988 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:55:54,990 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:55:54,990 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:55:54,990 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,990 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:54,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,014 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:55:55,016 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:55:55,017 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:55,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,068 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,084 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:55:55,085 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:55:55,086 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:55:55,086 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,086 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,091 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:55:55,091 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,091 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,105 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:55:55,107 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:55:55,107 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:55:55,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,112 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:55:55,112 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:55:55,112 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_19: total_params_size=104
2024-07-12 10:55:55,112 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,112 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,126 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:55:55,128 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:55:55,128 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:55:55,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,133 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:55:55,133 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:55:55,147 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:55:55,149 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:55:55,149 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:55:55,150 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,150 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,154 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:55:55,168 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:55:55,170 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:55:55,170 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:55:55,170 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,171 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,220 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,234 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:55:55,236 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:55:55,236 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:55:55,236 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,236 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,241 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:55:55,241 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,241 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,256 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:55:55,257 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:55:55,257 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:55:55,258 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,258 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,262 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:55:55,262 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,262 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,277 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:55:55,278 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:55:55,278 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:55:55,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,283 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:55:55,298 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:55:55,300 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:55:55,300 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:55:55,300 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,300 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,305 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:55:55,305 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.990269
2024-07-12 10:55:55,305 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:55:55,305 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 9 to 9
2024-07-12 10:55:55,319 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:55:55,321 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:55:55,321 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:55:55,321 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,321 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,326 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:55:55,326 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:55:55,529 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:55:55,530 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_21 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_16x10_tt_align_4_4', 0, 1)
2024-07-12 10:55:55,530 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.204058
2024-07-12 10:55:55,530 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:55,530 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000050
2024-07-12 10:55:55,530 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:55:55,530 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_21: B == 4 && M == 512 && N == 128 && K == 64
2024-07-12 10:55:55,530 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000073
2024-07-12 10:55:55,544 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:55:55,546 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:55:55,546 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:55:55,546 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,546 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,551 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:55:55,551 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:55,551 INFO <aitemplate.compiler.transform.memory_planning> max_blob=262144 constant_offset=133120
2024-07-12 10:55:55,552 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:55:55,552 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,552 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,564 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:55:55,565 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:55:55,565 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:55:55,565 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,565 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,568 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:55:55,568 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017375
2024-07-12 10:55:55,580 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:55:55,581 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:55:55,581 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:55:55,582 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,582 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,585 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:55:55,585 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:55:55,585 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1572864 constant_offset=133120
2024-07-12 10:55:55,596 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:55:55,597 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:55:55,598 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:55:55,598 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,598 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=23, tensor_cnt=0, len(func_name_to_tensor_cnt)=23, len(user_provided_dim)=146
2024-07-12 10:55:55,600 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:55:55,602 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:55:55,604 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:55:55,604 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:55:55,612 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:56:04,104 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_11.obj fused_elementwise_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_10.obj fused_elementwise_10.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_12.obj fused_elementwise_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_18_constant_folding.obj permute021_18_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_16_constant_folding.obj concatenate_16_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_19_constant_folding.obj concatenate_19_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_21.obj perm102_bmm_rrr_bias_21.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so split_0.obj fused_elementwise_12.obj fused_elementwise_13.obj fused_elementwise_11.obj fused_elementwise_10.obj perm102_bmm_rrr_bias_21.obj concatenate_16_constant_folding.obj permute021_18_constant_folding.obj concatenate_19_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:56:04,104 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:04,104 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.499876, with optimize = True
[10:56:04] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:04] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:04] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 10, k: 32
2024-07-12 10:56:04,134 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:04,135 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:04,136 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:04,136 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:04,136 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:04,803 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:56:04,804 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:56:04,805 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:56:04,805 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=146
2024-07-12 10:56:04,805 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,811 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:56:04,821 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:56:04,823 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:56:04,823 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:56:04,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,829 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:56:04,840 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:56:04,841 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:56:04,841 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:04,841 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,841 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,858 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:56:04,859 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:56:04,860 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:04,860 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,860 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,911 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:56:04,911 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,911 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,922 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:56:04,924 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:56:04,924 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:56:04,924 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,924 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,929 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:56:04,940 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:04,942 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:04,942 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:04,942 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,943 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,948 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:04,959 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:56:04,961 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:56:04,961 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:04,961 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,961 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,967 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:56:04,967 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,967 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,978 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:04,979 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:04,979 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:04,979 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,985 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:04,985 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:04,996 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:04,997 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:04,998 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:04,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:04,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,047 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,048 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,060 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:05,061 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:05,061 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:05,062 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,062 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,069 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:05,079 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:05,081 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:05,081 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:05,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,088 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:05,088 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,088 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,099 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:05,100 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:05,100 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:05,100 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,101 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,106 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:05,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,117 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:05,118 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:56:05,118 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:05,119 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,119 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,124 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:05,135 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:05,137 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:05,137 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:05,137 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,137 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,189 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:05,199 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:05,201 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:05,201 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:05,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,208 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:05,208 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,208 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,209 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,209 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,219 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:05,221 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:05,221 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:05,221 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,221 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,227 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:05,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,238 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:05,240 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:05,240 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:05,241 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,241 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,248 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:05,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,259 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:05,260 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:05,260 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:05,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,266 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:05,277 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:56:05,278 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:56:05,278 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:05,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,340 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:56:05,342 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:56:05,342 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:05,342 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,342 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,347 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:05,348 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,348 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,358 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:56:05,360 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:56:05,360 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:05,361 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,361 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,367 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:56:05,370 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:05,373 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:05,376 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:05,380 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_1', 'split_0_0', 'split_0_3', 'split_0_2'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:05,380 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=10, tensor_cnt=0, len(func_name_to_tensor_cnt)=10, len(user_provided_dim)=146
2024-07-12 10:56:05,380 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:05,395 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:56:05,397 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:56:05,397 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:05,398 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:05,398 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:05,404 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:05,404 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:05,404 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,405 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,405 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,421 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:05,424 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:05,424 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:05,424 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,424 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,431 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:05,447 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:56:05,449 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:56:05,449 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:05,450 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,450 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,504 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:56:05,520 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:56:05,522 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:56:05,523 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:56:05,523 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,523 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,529 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:56:05,529 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,529 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,545 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:56:05,548 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:56:05,548 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:56:05,548 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,548 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,554 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:56:05,555 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,555 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,570 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:56:05,573 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:56:05,573 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:05,573 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,573 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,597 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:56:05,599 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:56:05,599 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:05,599 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,599 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,605 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,606 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,621 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:56:05,622 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:56:05,623 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:56:05,623 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,623 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,674 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:56:05,674 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,674 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,688 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:56:05,689 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:56:05,690 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:56:05,690 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,690 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,694 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:56:05,694 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:56:05,694 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_18: total_params_size=104
2024-07-12 10:56:05,695 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,695 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,708 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:56:05,710 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:56:05,710 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:56:05,710 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,710 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,715 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:56:05,715 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:56:05,729 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:56:05,730 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:56:05,731 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:56:05,731 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,731 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,735 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:56:05,749 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:56:05,750 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:56:05,751 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:56:05,751 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,751 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,757 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,771 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:56:05,773 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:56:05,773 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:05,773 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,773 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,778 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:56:05,778 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,778 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,792 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:56:05,794 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:56:05,794 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:56:05,795 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,795 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,799 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:56:05,800 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,800 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,813 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:56:05,815 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:56:05,815 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:56:05,816 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,816 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,882 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:56:05,895 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:56:05,897 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:56:05,897 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:56:05,897 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,897 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,902 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:56:05,902 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.934521
2024-07-12 10:56:05,902 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:56:05,902 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 8 to 8
2024-07-12 10:56:05,916 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:56:05,917 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:56:05,917 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:56:05,918 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,918 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,922 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:56:05,922 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:56:05,964 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:56:05,965 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_20 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_2', 0, 1)
2024-07-12 10:56:05,965 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.042446
2024-07-12 10:56:05,965 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:05,965 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000082
2024-07-12 10:56:05,965 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:56:05,965 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_20: B == 4 && M == 256 && N == 10 && K == 32
2024-07-12 10:56:05,965 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000084
2024-07-12 10:56:05,980 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:56:05,983 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:56:05,983 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:56:05,983 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,983 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,989 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:56:05,989 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:05,989 INFO <aitemplate.compiler.transform.memory_planning> max_blob=5312 constant_offset=5376
2024-07-12 10:56:05,990 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:56:05,991 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:05,991 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,004 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:56:06,005 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:56:06,006 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:56:06,006 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,006 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,009 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:56:06,010 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.020440
2024-07-12 10:56:06,021 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:06,023 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:06,023 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:06,023 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,023 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,026 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:06,026 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:06,026 INFO <aitemplate.compiler.transform.memory_planning> max_blob=262144 constant_offset=5312
2024-07-12 10:56:06,038 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:56:06,039 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:56:06,039 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:56:06,040 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,040 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=22, tensor_cnt=0, len(func_name_to_tensor_cnt)=22, len(user_provided_dim)=146
2024-07-12 10:56:06,043 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:56:06,045 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:56:06,048 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:56:06,048 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:06,059 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:56:14,342 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_1.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_12.obj fused_elementwise_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_11.obj fused_elementwise_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_10.obj fused_elementwise_10.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_16_constant_folding.obj concatenate_16_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_18_constant_folding.obj concatenate_18_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_20.obj perm102_bmm_rcr_bias_20.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_1.so split_0.obj fused_elementwise_11.obj fused_elementwise_10.obj fused_elementwise_13.obj fused_elementwise_12.obj perm102_bmm_rcr_bias_20.obj concatenate_16_constant_folding.obj concatenate_18_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:56:14,342 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:14,342 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.294090, with optimize = True
[10:56:14] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:14] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:14] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 10, k: 32
2024-07-12 10:56:14,349 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:14,349 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:14,350 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:14,350 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:14,350 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:14,923 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:56:14,925 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:56:14,925 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:56:14,926 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=146
2024-07-12 10:56:14,926 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:14,933 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:56:14,945 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:56:14,947 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:56:14,947 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:56:14,948 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:14,948 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:14,991 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:56:15,004 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:56:15,006 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:56:15,006 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:15,006 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,006 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,013 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,026 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:56:15,028 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:56:15,028 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:15,029 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,029 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,035 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:56:15,035 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,035 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,047 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:56:15,049 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:56:15,049 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:56:15,050 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,050 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,056 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:56:15,068 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:15,070 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:15,070 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:15,071 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,071 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,121 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:15,134 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:56:15,135 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:56:15,136 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:15,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,142 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:56:15,142 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,142 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,155 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:15,156 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:15,156 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:15,157 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,157 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,163 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:15,163 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:15,176 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:15,177 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:15,177 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:15,178 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,178 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,184 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:15,184 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,184 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,184 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,198 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:15,200 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:15,200 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:15,200 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,200 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,251 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:15,263 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:15,265 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:15,265 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:15,266 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,266 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,272 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:15,272 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,272 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,285 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:15,286 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:15,287 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:15,287 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,287 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,294 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:15,294 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,294 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,306 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:15,308 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:56:15,308 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:15,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,309 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,315 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:15,328 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:15,329 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:15,330 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:15,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,381 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:15,394 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:15,395 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:15,396 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:15,396 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,396 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,402 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:15,402 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,402 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,403 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,403 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,415 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:15,417 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:15,417 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:15,417 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,417 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,424 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:15,424 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,424 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,437 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:15,438 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:15,439 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:15,439 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,439 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,445 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:15,445 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,445 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,458 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:15,460 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:15,460 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:15,460 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,460 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,466 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:15,479 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:56:15,480 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:56:15,481 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:15,481 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,481 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,547 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:56:15,549 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:56:15,549 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:15,549 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,549 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,556 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:15,556 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,556 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,568 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:56:15,570 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:56:15,570 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:15,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,577 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:56:15,581 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:15,584 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:15,587 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:15,590 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_2'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_1'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_1', 'split_0_3', 'split_0_0'],
  'split_dim': 1,
  'split_sizes': [32, 32, 32, 32]}}, final_set: set()
2024-07-12 10:56:15,591 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:15,591 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=146
2024-07-12 10:56:15,608 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:56:15,610 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:56:15,610 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:15,610 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=146
2024-07-12 10:56:15,610 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=146
2024-07-12 10:56:15,617 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:15,618 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=18, tensor_cnt=0, len(func_name_to_tensor_cnt)=18, len(user_provided_dim)=146
2024-07-12 10:56:15,618 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,618 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,618 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,635 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:15,638 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:15,638 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:15,638 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,638 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,691 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:15,709 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:56:15,711 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:56:15,711 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:15,711 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,712 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,719 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:56:15,736 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:56:15,738 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:56:15,739 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:56:15,739 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,739 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,746 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:56:15,747 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,747 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,764 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:56:15,766 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:56:15,766 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:56:15,767 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,767 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,818 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:56:15,818 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,818 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,835 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:56:15,837 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:56:15,838 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:15,838 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,838 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,847 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,847 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,864 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:56:15,867 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:56:15,867 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:15,867 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,867 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,875 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,876 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,891 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:56:15,893 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:56:15,893 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:56:15,893 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,893 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,897 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:56:15,897 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,897 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,912 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:56:15,913 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:56:15,914 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:56:15,914 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,914 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,963 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:56:15,963 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_20: total_params_size=120
2024-07-12 10:56:15,963 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_22: total_params_size=104
2024-07-12 10:56:15,963 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,963 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,977 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:56:15,979 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:56:15,979 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:56:15,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:15,984 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:56:15,984 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:56:15,999 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:56:16,001 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:56:16,001 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:56:16,001 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,001 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,006 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:56:16,020 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:56:16,022 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:56:16,022 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:56:16,022 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,022 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,042 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:56:16,044 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:56:16,044 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:16,044 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,044 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,049 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:56:16,049 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,049 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,063 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:56:16,065 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:56:16,065 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:56:16,065 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,065 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,069 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:56:16,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,084 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:56:16,086 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:56:16,086 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:56:16,086 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,086 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,134 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:56:16,148 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:56:16,149 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:56:16,150 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:56:16,150 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,150 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,154 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:56:16,154 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.011968
2024-07-12 10:56:16,154 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:56:16,154 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 8 to 8
2024-07-12 10:56:16,169 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:56:16,171 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:56:16,171 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:56:16,171 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,171 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,176 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:56:16,176 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:56:16,214 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:56:16,214 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_24 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_2', 0, 1)
2024-07-12 10:56:16,214 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038229
2024-07-12 10:56:16,214 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:16,214 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000074
2024-07-12 10:56:16,214 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:56:16,214 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_24: B == 4 && M == 256 && N == 10 && K == 32
2024-07-12 10:56:16,214 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000070
2024-07-12 10:56:16,229 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:56:16,231 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:56:16,231 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:56:16,231 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,231 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,236 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:56:16,236 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:16,236 INFO <aitemplate.compiler.transform.memory_planning> max_blob=5312 constant_offset=5376
2024-07-12 10:56:16,236 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:56:16,237 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,237 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,248 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:56:16,250 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:56:16,250 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:56:16,250 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,250 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,253 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:56:16,253 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017484
2024-07-12 10:56:16,264 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:16,266 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:16,266 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:16,266 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,266 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,269 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:16,269 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:16,269 INFO <aitemplate.compiler.transform.memory_planning> max_blob=262144 constant_offset=5312
2024-07-12 10:56:16,280 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:56:16,281 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:56:16,281 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:56:16,282 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,282 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=26, tensor_cnt=0, len(func_name_to_tensor_cnt)=26, len(user_provided_dim)=146
2024-07-12 10:56:16,285 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:56:16,286 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:56:16,289 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:56:16,289 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:16,299 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:56:24,865 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_2.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_15.obj fused_elementwise_15.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_14.obj fused_elementwise_14.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_17.obj fused_elementwise_17.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_16.obj fused_elementwise_16.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_20_constant_folding.obj concatenate_20_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_22_constant_folding.obj concatenate_22_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_24.obj perm102_bmm_rcr_bias_24.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_2.so split_0.obj fused_elementwise_16.obj fused_elementwise_15.obj fused_elementwise_17.obj fused_elementwise_14.obj perm102_bmm_rcr_bias_24.obj concatenate_20_constant_folding.obj concatenate_22_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:56:24,865 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:24,865 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.575774, with optimize = True
[10:56:24] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:24] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:24] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 32, k: 64
2024-07-12 10:56:24,886 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:24,886 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:24,887 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:24,887 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:24,888 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:25,716 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:56:25,717 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:56:25,717 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:56:25,717 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=146
2024-07-12 10:56:25,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,722 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:56:25,732 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:56:25,733 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:56:25,734 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:56:25,734 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,734 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,738 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:56:25,748 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:56:25,750 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:56:25,750 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:25,750 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,750 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,803 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:56:25,804 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:56:25,805 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:25,805 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,805 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,809 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:56:25,809 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,809 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,819 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:56:25,820 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:56:25,820 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:56:25,821 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,821 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,825 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:56:25,835 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:25,836 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:25,837 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:25,837 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,837 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,841 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:25,851 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:56:25,852 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:56:25,853 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:25,853 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,853 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,857 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:56:25,857 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,857 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,867 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:25,868 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:25,868 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:25,868 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,869 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,873 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:25,873 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:25,883 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:25,884 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:25,884 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:25,884 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,884 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,900 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:25,901 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:25,901 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:25,901 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,901 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,947 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:25,958 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:25,959 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:25,959 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:25,960 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,960 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,964 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:25,964 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,964 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,974 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:25,975 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:25,975 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:25,976 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,976 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,980 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:25,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,990 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:25,992 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:56:25,992 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:25,992 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,992 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:25,996 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:26,006 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:26,008 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:26,008 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:26,008 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,008 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,012 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:26,022 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:26,024 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:26,024 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:26,024 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,024 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,028 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:26,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,038 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:26,040 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:26,040 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:26,040 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,040 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,044 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:26,044 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,044 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,054 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:26,055 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:26,056 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:26,056 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,056 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,103 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:26,103 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,103 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,113 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:26,115 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:26,115 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:26,115 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,115 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,119 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:26,129 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:56:26,131 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:56:26,131 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:26,131 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,131 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,146 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:56:26,147 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:56:26,148 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:26,148 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,148 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,152 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:26,152 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,152 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,162 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:56:26,164 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:56:26,164 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:26,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,168 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:56:26,168 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,168 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,179 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:56:26,180 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:56:26,180 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:26,180 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,180 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,184 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:26,184 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,184 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,185 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:26,185 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,196 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:26,197 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:26,198 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:26,198 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,198 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,245 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:26,256 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:56:26,258 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:56:26,258 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:26,258 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,258 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,263 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:56:26,274 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:56:26,276 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:56:26,276 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:56:26,276 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,276 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,282 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:56:26,282 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,282 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,293 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:56:26,295 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:56:26,295 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:56:26,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,300 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:56:26,300 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,300 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,311 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:56:26,313 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:56:26,313 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:26,313 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,313 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,327 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:56:26,328 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:56:26,329 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:26,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,334 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,334 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,334 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,334 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,340 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:56:26,341 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:56:26,341 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:56:26,341 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,341 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,344 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:56:26,344 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,344 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,350 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:56:26,351 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:56:26,351 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:56:26,351 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,352 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,400 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:56:26,400 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_8: total_params_size=120
2024-07-12 10:56:26,400 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_11: total_params_size=104
2024-07-12 10:56:26,400 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,400 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,406 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:56:26,407 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:56:26,407 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:56:26,407 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,407 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,410 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:56:26,416 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:56:26,417 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:56:26,417 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:56:26,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,420 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:56:26,426 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:56:26,427 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:56:26,427 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:56:26,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,430 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,437 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:56:26,438 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:56:26,438 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:26,439 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,439 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,442 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:56:26,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,448 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:56:26,449 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:56:26,449 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:56:26,449 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,449 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,452 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:56:26,452 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,452 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,458 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:56:26,459 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:56:26,459 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:56:26,459 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,459 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,462 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:56:26,468 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:56:26,469 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:56:26,469 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:56:26,469 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,469 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,472 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:56:26,472 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.615343
2024-07-12 10:56:26,472 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:56:26,472 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 4 to 4
2024-07-12 10:56:26,479 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:56:26,479 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:56:26,479 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:56:26,480 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,480 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,483 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:56:26,483 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:56:26,521 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:56:26,521 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_13 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_16x10_tt_align_4_4', 0, 1)
2024-07-12 10:56:26,521 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038077
2024-07-12 10:56:26,521 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:26,521 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000043
2024-07-12 10:56:26,521 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:56:26,521 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_13: B == 4 && M == 512 && N == 32 && K == 64
2024-07-12 10:56:26,521 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000064
2024-07-12 10:56:26,527 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:56:26,528 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:56:26,528 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:56:26,529 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,529 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,532 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:56:26,532 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:26,532 INFO <aitemplate.compiler.transform.memory_planning> max_blob=65536 constant_offset=33280
2024-07-12 10:56:26,532 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:56:26,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,533 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,536 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:56:26,537 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:56:26,537 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:56:26,537 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,537 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,538 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:56:26,538 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.006412
2024-07-12 10:56:26,541 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:26,542 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:26,542 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:26,542 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,542 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,543 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:26,543 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:26,543 INFO <aitemplate.compiler.transform.memory_planning> max_blob=786432 constant_offset=33280
2024-07-12 10:56:26,546 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:56:26,547 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:56:26,547 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:56:26,547 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,547 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=15, tensor_cnt=0, len(func_name_to_tensor_cnt)=15, len(user_provided_dim)=146
2024-07-12 10:56:26,548 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:56:26,548 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:56:26,551 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:56:26,551 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:26,565 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:56:33,948 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_3.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_10_constant_folding.obj permute021_10_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_11_constant_folding.obj concatenate_11_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_8_constant_folding.obj concatenate_8_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_13.obj perm102_bmm_rrr_bias_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_3.so perm102_bmm_rrr_bias_13.obj concatenate_8_constant_folding.obj permute021_10_constant_folding.obj concatenate_11_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:56:33,948 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:33,948 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.397435, with optimize = True
[10:56:33] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:33] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:33] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat, b: 4, ms: [128, 256], n: 10, k: 32
2024-07-12 10:56:33,954 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:33,954 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:33,954 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:33,954 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:33,954 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:34,525 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:56:34,527 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:56:34,527 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:56:34,527 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=146
2024-07-12 10:56:34,527 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,532 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:56:34,542 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:56:34,543 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:56:34,543 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:56:34,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,584 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:56:34,594 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:56:34,595 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:56:34,596 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:34,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,600 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,610 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:56:34,612 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:56:34,612 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:34,612 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,612 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,616 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:56:34,616 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,616 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,626 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:56:34,628 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:56:34,628 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:56:34,628 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,628 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,632 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:56:34,642 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:34,643 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:34,643 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:34,644 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,644 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,648 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:34,657 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:56:34,659 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:56:34,659 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:34,659 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,659 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,663 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:56:34,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,663 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,673 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:34,674 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:34,675 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:34,675 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,675 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,679 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:34,679 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:34,689 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:34,690 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:34,690 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:34,691 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,691 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,748 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:34,749 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:34,749 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:34,749 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,749 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,754 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:34,763 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:34,765 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:34,765 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:34,765 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,765 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,769 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:34,769 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,769 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,779 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:34,781 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:34,781 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:34,781 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,781 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,785 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:34,785 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,785 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,795 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:34,796 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:56:34,796 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:34,797 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,797 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,801 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:34,811 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:34,812 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:34,812 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:34,813 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,813 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,817 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:34,827 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:34,828 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:34,828 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:34,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,832 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:34,832 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,832 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,833 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,833 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,842 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:34,844 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:34,844 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:34,844 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,844 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,892 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:34,892 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,892 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,902 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:34,903 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:34,903 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:34,904 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,904 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,908 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:34,908 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,908 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,918 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:34,919 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:34,919 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:34,919 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,920 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,924 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:34,934 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:56:34,935 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:56:34,935 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:34,935 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,935 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,940 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,950 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:56:34,952 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:56:34,952 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:34,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,956 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:34,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,966 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:56:34,968 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:56:34,968 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:34,968 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,968 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,972 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:56:34,972 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,972 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,982 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:56:34,983 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:56:34,983 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:34,984 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,984 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,988 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:34,988 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,988 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,988 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=146
2024-07-12 10:56:34,989 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:34,999 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:35,001 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:35,001 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:35,001 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,001 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,050 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:35,060 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:56:35,062 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:56:35,062 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:35,062 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,062 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,068 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:56:35,079 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:56:35,081 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:56:35,081 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:56:35,081 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,081 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,086 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:56:35,086 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,086 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,096 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:56:35,098 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:56:35,098 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:56:35,098 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,098 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,103 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:56:35,103 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,104 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,114 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:56:35,115 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:56:35,116 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:35,116 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,116 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,129 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:56:35,130 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:56:35,130 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:35,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,134 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,135 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,140 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:56:35,141 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:56:35,141 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:56:35,142 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,142 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,144 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:56:35,144 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,144 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,150 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:56:35,151 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:56:35,151 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:56:35,151 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,151 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,198 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:56:35,198 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_8: total_params_size=120
2024-07-12 10:56:35,198 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_10: total_params_size=104
2024-07-12 10:56:35,199 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,199 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,204 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:56:35,205 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:56:35,205 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:56:35,205 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,205 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,208 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:56:35,214 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:56:35,214 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:56:35,215 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:56:35,215 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,215 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,217 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:56:35,223 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:56:35,224 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:56:35,224 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:56:35,224 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,224 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,226 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,233 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:56:35,233 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:56:35,233 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:35,234 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,234 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,236 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:56:35,236 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,236 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,242 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:56:35,243 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:56:35,243 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:56:35,243 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,243 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,246 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:56:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,251 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:56:35,252 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:56:35,252 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:56:35,252 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,252 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,255 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:56:35,260 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:56:35,261 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:56:35,261 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:56:35,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,264 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:56:35,264 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.600753
2024-07-12 10:56:35,264 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:56:35,264 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 3 to 3
2024-07-12 10:56:35,270 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:56:35,270 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:56:35,271 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:56:35,271 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,271 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,273 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:56:35,273 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:56:35,312 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:56:35,312 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_12 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_2', 0, 1)
2024-07-12 10:56:35,312 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038571
2024-07-12 10:56:35,312 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:35,312 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000042
2024-07-12 10:56:35,312 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:56:35,312 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_12: B == 4 && M == 256 && N == 10 && K == 32
2024-07-12 10:56:35,312 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000092
2024-07-12 10:56:35,318 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:56:35,319 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:56:35,319 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:56:35,319 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,319 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,322 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:56:35,322 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:35,322 INFO <aitemplate.compiler.transform.memory_planning> max_blob=5312 constant_offset=5376
2024-07-12 10:56:35,322 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:56:35,323 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,323 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,326 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:56:35,327 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:56:35,327 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:56:35,327 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,327 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,328 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:56:35,328 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.006258
2024-07-12 10:56:35,331 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:35,332 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:35,332 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:35,332 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,332 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,333 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:35,333 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:35,333 INFO <aitemplate.compiler.transform.memory_planning> max_blob=172032 constant_offset=5312
2024-07-12 10:56:35,336 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:56:35,337 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:56:35,337 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:56:35,337 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,337 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:35,338 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:56:35,338 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:56:35,341 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:56:35,341 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:35,353 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:56:42,946 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_4.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_8_constant_folding.obj concatenate_8_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_10_constant_folding.obj concatenate_10_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_12.obj perm102_bmm_rcr_bias_12.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_4.so perm102_bmm_rcr_bias_12.obj concatenate_8_constant_folding.obj concatenate_10_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:56:42,947 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:42,947 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:07.605744, with optimize = True
[10:56:42] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:42] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:42] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_2_split_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:56:42,966 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=14, tensor_cnt=0, len(func_name_to_tensor_cnt)=14, len(user_provided_dim)=146
2024-07-12 10:56:42,967 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=25, tensor_cnt=0, len(func_name_to_tensor_cnt)=25, len(user_provided_dim)=146
2024-07-12 10:56:42,968 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=25, tensor_cnt=0, len(func_name_to_tensor_cnt)=25, len(user_provided_dim)=146
2024-07-12 10:56:42,969 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=25, tensor_cnt=0, len(func_name_to_tensor_cnt)=25, len(user_provided_dim)=154
.INFO:__main__:_fuse_parallel_gemm_cat_partial, b1: 4, b2: 4, ms: [128, 256], n: 32, k: 64
2024-07-12 10:56:43,094 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:43,095 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:43,095 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:43,095 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:43,095 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:43,640 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:56:43,644 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:56:43,645 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:56:43,645 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=154
2024-07-12 10:56:43,645 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=166
2024-07-12 10:56:43,695 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:56:43,728 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:56:43,733 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:56:43,733 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:56:43,733 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=166
2024-07-12 10:56:43,733 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,747 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:56:43,780 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:56:43,784 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:56:43,784 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:43,784 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,784 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,843 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,844 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,844 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,877 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:56:43,881 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:56:43,881 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:43,881 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,881 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,938 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:56:43,938 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,938 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,970 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:56:43,974 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:56:43,975 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:56:43,975 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,975 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:43,989 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:56:44,023 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:56:44,027 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:56:44,027 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:44,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,089 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:44,122 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:56:44,127 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:56:44,127 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:44,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,141 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:56:44,141 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,142 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,174 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:44,178 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:44,179 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:44,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,240 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:44,240 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:44,273 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:44,277 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:44,277 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:44,277 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,277 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,292 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,326 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:44,330 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:44,331 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:44,331 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,331 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,390 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:44,427 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:44,432 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:44,433 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:44,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,434 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,584 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:44,584 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,584 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,643 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:44,670 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:44,672 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:44,673 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,674 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,757 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:44,758 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,758 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,808 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:44,812 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:56:44,812 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:44,813 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,813 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,876 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:44,909 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:44,913 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:44,913 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:44,914 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,914 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,928 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:44,960 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:44,964 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:44,965 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:44,965 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:44,965 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,027 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:45,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,061 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:45,065 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:45,066 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:45,066 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,066 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,080 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:45,080 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,080 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,113 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:45,117 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:45,118 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:45,118 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,118 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,180 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:45,180 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,180 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,214 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:45,218 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:45,218 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:45,219 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,219 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,233 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:45,265 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:56:45,269 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:56:45,270 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:45,270 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,270 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,332 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:45,332 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,332 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,332 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,332 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,334 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,334 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,366 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:56:45,370 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:56:45,371 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:45,371 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,371 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,385 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:45,385 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,385 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,418 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:56:45,422 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:56:45,422 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:45,423 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,423 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,484 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:56:45,487 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,491 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,494 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,497 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_1', 'split_1_0', 'split_1_3', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,501 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,504 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,507 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,511 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_0', 'split_2_1', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:45,511 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=170
2024-07-12 10:56:45,511 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=170
2024-07-12 10:56:45,554 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:56:45,559 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:56:45,559 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:45,560 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=170
2024-07-12 10:56:45,560 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=170
2024-07-12 10:56:45,574 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:45,575 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=170
2024-07-12 10:56:45,575 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=178
2024-07-12 10:56:45,575 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=178
2024-07-12 10:56:45,575 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,621 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:45,626 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:45,627 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:45,627 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,627 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,690 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:45,735 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:56:45,740 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:56:45,741 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:45,741 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,741 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,802 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:56:45,848 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:56:45,854 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:56:45,854 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:56:45,855 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,855 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,917 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:56:45,918 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,918 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,963 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:56:45,969 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:56:45,969 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:56:45,970 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,970 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,987 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:56:45,987 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:45,987 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,032 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:56:46,038 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:56:46,038 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:46,039 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,039 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,107 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,153 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:56:46,158 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:56:46,159 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:46,159 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,159 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,223 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,223 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,224 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_42_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_45_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,225 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,263 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:56:46,267 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:56:46,268 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:56:46,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,279 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:56:46,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,316 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:56:46,321 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:56:46,321 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:56:46,321 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,321 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,332 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:56:46,332 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_41: total_params_size=120
2024-07-12 10:56:46,332 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_44: total_params_size=120
2024-07-12 10:56:46,332 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_47: total_params_size=104
2024-07-12 10:56:46,332 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_51: total_params_size=104
2024-07-12 10:56:46,332 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,333 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,370 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:56:46,374 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:56:46,374 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:56:46,375 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,375 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,435 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:56:46,436 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:56:46,436 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:56:46,474 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:56:46,478 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:56:46,478 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:56:46,478 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,479 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,490 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:56:46,527 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:56:46,531 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:56:46,532 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:56:46,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,625 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:56:46,629 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:56:46,629 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:46,629 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,629 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,640 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:56:46,641 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,641 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,679 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:56:46,684 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:56:46,684 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:56:46,684 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,684 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,741 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:56:46,741 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,741 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,778 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:56:46,782 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:56:46,782 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:56:46,783 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,783 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,794 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:56:46,831 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:56:46,835 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:56:46,835 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:56:46,836 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,836 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,893 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:56:46,893 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:02.751626
2024-07-12 10:56:46,893 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'split', 'concatenate', 'fused_elementwise', 'permute021'}
2024-07-12 10:56:46,893 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 23 to 15
2024-07-12 10:56:46,930 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:56:46,934 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:56:46,934 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:56:46,935 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,935 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:46,945 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:56:46,945 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:56:46,983 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:46,983 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_49 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_8_8', 0, 1)
2024-07-12 10:56:47,019 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:47,020 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_11 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8', 0, 1)
2024-07-12 10:56:47,056 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:47,056 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_16 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8', 0, 1)
2024-07-12 10:56:47,092 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:47,093 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_14 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_8_8', 0, 1)
2024-07-12 10:56:47,129 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:47,129 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_17 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_8_8', 0, 1)
2024-07-12 10:56:47,165 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:56:47,165 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_53 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_8_8', 0, 1)
2024-07-12 10:56:47,165 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.219964
2024-07-12 10:56:47,165 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:47,165 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000043
2024-07-12 10:56:47,165 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_49: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_11: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_16: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_14: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_17: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_53: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:56:47,166 INFO <aitemplate.compiler.transform.profile> ran 6 profilers elapsed time: 0:00:00.000122
2024-07-12 10:56:47,204 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:56:47,209 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:56:47,209 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:56:47,209 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,210 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,266 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:56:47,266 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:47,266 INFO <aitemplate.compiler.transform.memory_planning> max_blob=65536 constant_offset=49664
2024-07-12 10:56:47,267 INFO <aitemplate.backend.codegen> generated 4 function srcs
2024-07-12 10:56:47,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,299 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:56:47,303 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:56:47,303 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:56:47,303 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,303 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,310 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:56:47,310 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.044647
2024-07-12 10:56:47,341 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:56:47,345 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:56:47,345 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:47,345 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,345 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,353 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:47,353 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:56:47,353 INFO <aitemplate.compiler.transform.memory_planning> max_blob=786432 constant_offset=66304
2024-07-12 10:56:47,384 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:56:47,387 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:56:47,387 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:56:47,388 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,388 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:47,394 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:56:47,396 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_42_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,396 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,397 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,397 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,398 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,398 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_45_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:56:47,398 INFO <aitemplate.backend.codegen> generated 11 function srcs
2024-07-12 10:56:47,402 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:56:47,402 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:56:47,413 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:56:57,404 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_32.obj fused_elementwise_32.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_1.obj split_1.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_30.obj fused_elementwise_30.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_31.obj fused_elementwise_31.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_29.obj fused_elementwise_29.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_43_constant_folding.obj permute021_43_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_13_constant_folding.obj permute021_13_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_47_constant_folding.obj concatenate_47_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_41_constant_folding.obj concatenate_41_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_49.obj perm102_bmm_rrr_bias_49.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_16.obj perm102_bmm_rcr_bias_16.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_17.obj perm102_bmm_rrr_bias_17.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_14.obj perm102_bmm_rrr_14.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_53.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_11.obj perm102_bmm_rcr_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so split_1.obj fused_elementwise_30.obj fused_elementwise_29.obj fused_elementwise_32.obj fused_elementwise_31.obj perm102_bmm_rrr_bias_49.obj perm102_bmm_rcr_11.obj perm102_bmm_rcr_bias_16.obj perm102_bmm_rrr_14.obj perm102_bmm_rrr_bias_17.obj perm102_bmm_rrr_bias_53.obj permute021_13_constant_folding.obj concatenate_41_constant_folding.obj permute021_43_constant_folding.obj concatenate_47_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:56:57,404 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:56:57,404 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:10.001871, with optimize = True
[10:56:57] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:56:57] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:56:57] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
EINFO:__main__:_fuse_parallel_gemm_cat_partial, b1: 4, b2: 4, ms: [128, 256], n: 32, k: 64
2024-07-12 10:56:57,411 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:56:57,411 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:56:57,411 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:56:57,412 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:56:57,412 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:56:58,017 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:56:58,022 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:56:58,022 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:56:58,022 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=192
2024-07-12 10:56:58,023 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,078 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:56:58,111 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:56:58,115 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:56:58,116 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:56:58,116 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,116 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,131 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:56:58,164 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:56:58,168 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:56:58,169 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:56:58,169 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,169 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,233 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:56:58,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,234 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,234 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,234 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,234 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,234 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,268 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:56:58,272 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:56:58,272 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:56:58,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,336 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:56:58,336 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,336 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,368 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:56:58,373 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:56:58,373 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:56:58,374 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,374 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,388 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:56:58,423 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:56:58,427 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:56:58,427 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:56:58,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,491 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:56:58,525 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:56:58,529 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:56:58,530 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:56:58,530 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,530 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,545 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:56:58,545 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,545 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,578 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:56:58,582 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:56:58,583 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:56:58,583 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,583 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,649 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:56:58,649 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:56:58,682 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:56:58,687 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:56:58,687 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:56:58,687 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,687 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,702 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:56:58,702 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,702 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,702 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,702 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,703 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,704 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,704 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,737 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:56:58,741 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:56:58,742 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:56:58,742 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,742 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,808 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:56:58,841 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:56:58,846 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:56:58,846 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:56:58,846 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,846 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,913 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:56:58,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,914 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,945 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:56:58,950 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:56:58,950 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:56:58,950 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,950 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,965 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:56:58,965 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,965 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:58,999 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:56:59,003 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:56:59,004 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:56:59,004 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,004 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,070 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:56:59,104 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:56:59,108 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:56:59,108 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:56:59,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,109 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,123 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:56:59,156 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:56:59,161 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:56:59,161 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:59,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,226 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:56:59,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,260 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:56:59,264 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:56:59,264 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:56:59,264 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,264 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,278 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:56:59,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,311 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:56:59,316 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:56:59,316 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:56:59,316 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,316 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,378 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:56:59,378 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,378 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,411 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:56:59,415 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:56:59,416 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:56:59,416 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,416 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,430 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:56:59,466 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:56:59,471 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:56:59,472 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:56:59,520 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,520 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,534 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:56:59,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,536 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,568 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:56:59,573 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:56:59,573 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:56:59,573 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,573 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,630 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:56:59,630 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,630 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,663 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:56:59,668 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:56:59,668 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:56:59,668 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,668 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,683 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:56:59,686 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,689 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,692 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,696 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X1'],
  'name': 'split_1',
  'nop': False,
  'op': 'split',
  'original_name': 'split_1',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_3'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_5'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_1_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_1_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_1'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_1_0', 'split_1_3', 'split_1_1', 'split_1_2'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,699 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,702 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,705 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,708 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, to_be_removed_set: {{ 'depth': 0,
  'has_profiler': False,
  'inputs': ['X2'],
  'name': 'split_2',
  'nop': False,
  'op': 'split',
  'original_name': 'split_2',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_8'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_7'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float32',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_2_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]},
             { 'depth': 0,
  'name': 'split_2_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_2'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_2_1', 'split_2_0', 'split_2_2', 'split_2_3'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}}, final_set: set()
2024-07-12 10:56:59,709 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=29, tensor_cnt=0, len(func_name_to_tensor_cnt)=29, len(user_provided_dim)=192
2024-07-12 10:56:59,709 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=192
2024-07-12 10:56:59,749 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:56:59,755 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:56:59,755 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:56:59,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=192
2024-07-12 10:56:59,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=192
2024-07-12 10:56:59,819 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:56:59,820 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=192
2024-07-12 10:56:59,820 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,821 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,821 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,867 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:56:59,872 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:56:59,873 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:56:59,873 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,873 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,891 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:56:59,936 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:56:59,942 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:56:59,942 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:56:59,943 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:56:59,943 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,009 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:57:00,055 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:57:00,061 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:57:00,062 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:57:00,062 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,062 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,126 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:57:00,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,172 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:57:00,178 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:57:00,178 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:57:00,178 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,196 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:57:00,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,240 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:57:00,246 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:57:00,246 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:00,247 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,247 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,314 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:00,314 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,314 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,314 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,314 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,315 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,316 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,361 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:57:00,367 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:57:00,367 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:00,368 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,368 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,430 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:57:00,430 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,430 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,430 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,430 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,431 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,432 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_42_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,432 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,432 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,432 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,432 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_45_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,433 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,471 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:57:00,475 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:57:00,476 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:57:00,476 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,476 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,487 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:57:00,487 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,487 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,524 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:57:00,528 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:57:00,529 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:57:00,529 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,529 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,589 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_41: total_params_size=120
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_44: total_params_size=120
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_47: total_params_size=104
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_51: total_params_size=104
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,589 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,627 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:57:00,631 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:57:00,631 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:57:00,632 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,632 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,643 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:57:00,643 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:57:00,643 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:57:00,680 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:57:00,684 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:57:00,684 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:57:00,685 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,685 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,743 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:57:00,780 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:57:00,784 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:57:00,784 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:57:00,784 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,784 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,795 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,797 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,797 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,797 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,797 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,835 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:57:00,839 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:57:00,839 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:00,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,850 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:57:00,850 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,850 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,887 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:57:00,891 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:57:00,891 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:57:00,891 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,891 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,952 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:57:00,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,990 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:57:00,994 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:57:00,994 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:57:00,994 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:00,994 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,005 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:57:01,042 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:57:01,047 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:57:01,047 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:57:01,047 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,047 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,105 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:57:01,105 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:02.559724
2024-07-12 10:57:01,105 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'split', 'concatenate', 'fused_elementwise', 'permute021'}
2024-07-12 10:57:01,105 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 23 to 15
2024-07-12 10:57:01,142 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:57:01,146 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:57:01,147 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:57:01,147 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,147 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,158 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:57:01,158 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:57:01,197 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,197 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_49 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:01,235 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,236 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_11 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_4', 0, 1)
2024-07-12 10:57:01,273 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,274 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_16 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_4', 0, 1)
2024-07-12 10:57:01,311 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,312 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_14 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:01,349 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,349 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_17 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:01,387 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_53 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.229084
2024-07-12 10:57:01,387 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000045
2024-07-12 10:57:01,387 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_49: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_11: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,387 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_16: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,388 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_14: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,388 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_17: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,388 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_53: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:01,388 INFO <aitemplate.compiler.transform.profile> ran 6 profilers elapsed time: 0:00:00.000150
2024-07-12 10:57:01,427 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:57:01,431 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:57:01,431 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:57:01,432 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,432 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,487 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:57:01,487 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:01,487 INFO <aitemplate.compiler.transform.memory_planning> max_blob=131072 constant_offset=99328
2024-07-12 10:57:01,488 INFO <aitemplate.backend.codegen> generated 4 function srcs
2024-07-12 10:57:01,489 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,489 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,521 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:57:01,525 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:57:01,525 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:57:01,525 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,525 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,533 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:57:01,533 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.045502
2024-07-12 10:57:01,564 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:57:01,568 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:57:01,568 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:01,568 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,568 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,575 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:01,576 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:01,576 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1572864 constant_offset=132608
2024-07-12 10:57:01,607 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:57:01,610 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:57:01,611 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:57:01,611 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,611 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=55, tensor_cnt=0, len(func_name_to_tensor_cnt)=55, len(user_provided_dim)=192
2024-07-12 10:57:01,664 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:57:01,666 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_42_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,666 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,666 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,667 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,667 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,668 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_45_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:01,668 INFO <aitemplate.backend.codegen> generated 11 function srcs
2024-07-12 10:57:01,672 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:57:01,672 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:01,685 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:57:12,406 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_32.obj fused_elementwise_32.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_31.obj fused_elementwise_31.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_29.obj fused_elementwise_29.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_13_constant_folding.obj permute021_13_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_30.obj fused_elementwise_30.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_43_constant_folding.obj permute021_43_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_1.obj split_1.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_41_constant_folding.obj concatenate_41_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_47_constant_folding.obj concatenate_47_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_16.obj perm102_bmm_rcr_bias_16.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_53.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_14.obj perm102_bmm_rrr_14.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_49.obj perm102_bmm_rrr_bias_49.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_11.obj perm102_bmm_rcr_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_17.obj perm102_bmm_rrr_bias_17.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so split_1.obj fused_elementwise_29.obj fused_elementwise_32.obj fused_elementwise_30.obj fused_elementwise_31.obj perm102_bmm_rrr_bias_49.obj perm102_bmm_rcr_11.obj perm102_bmm_rcr_bias_16.obj perm102_bmm_rrr_14.obj perm102_bmm_rrr_bias_17.obj perm102_bmm_rrr_bias_53.obj permute021_13_constant_folding.obj concatenate_41_constant_folding.obj permute021_43_constant_folding.obj concatenate_47_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:57:12,406 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:57:12,406 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:10.733435, with optimize = True
[10:57:12] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:57:12] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:57:12] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
INFO:__main__:_fuse_parallel_gemm_cat_partial, b1: 4, b2: 4, ms: [128, 256], n: 32, k: 64
2024-07-12 10:57:12,413 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:57:12,413 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:57:12,413 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:57:12,413 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:57:12,413 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:57:12,975 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.txt
2024-07-12 10:57:12,992 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph.json
2024-07-12 10:57:13,013 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/toposort_pseudo_code.txt
2024-07-12 10:57:13,077 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=192
2024-07-12 10:57:13,077 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=192
2024-07-12 10:57:13,329 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float32/toposort_graph_vis.html
2024-07-12 10:57:13,379 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.txt
2024-07-12 10:57:13,417 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph.json
2024-07-12 10:57:13,418 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_pseudo_code.txt
2024-07-12 10:57:13,436 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=192
2024-07-12 10:57:13,436 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,479 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float32/bind_constants_graph_vis.html
2024-07-12 10:57:13,511 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.txt
2024-07-12 10:57:13,524 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph.json
2024-07-12 10:57:13,540 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:57:13,561 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,561 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,735 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:57:13,735 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,736 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,736 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,736 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,737 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,737 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,738 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,738 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,739 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,739 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,846 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.txt
2024-07-12 10:57:13,864 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph.json
2024-07-12 10:57:13,875 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:57:13,896 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,897 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,977 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/remove_no_ops_graph_vis.html
2024-07-12 10:57:13,978 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:13,978 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,061 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.txt
2024-07-12 10:57:14,081 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph.json
2024-07-12 10:57:14,086 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_pseudo_code.txt
2024-07-12 10:57:14,109 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,110 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,243 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/name_graph_graph_vis.html
2024-07-12 10:57:14,275 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:57:14,280 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:57:14,280 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:14,280 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,280 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,293 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:14,323 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.txt
2024-07-12 10:57:14,327 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph.json
2024-07-12 10:57:14,328 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:57:14,328 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,328 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,388 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:57:14,389 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,389 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,420 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:57:14,424 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:57:14,424 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:57:14,424 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,425 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,436 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:57:14,436 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:57:14,468 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:57:14,472 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:57:14,472 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:57:14,472 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,472 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,530 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:57:14,530 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,530 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,531 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,532 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,564 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:57:14,568 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:57:14,568 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:57:14,568 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,568 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,580 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:57:14,610 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:57:14,614 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:57:14,615 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:57:14,615 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,615 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,627 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:57:14,627 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,627 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,658 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:57:14,662 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:57:14,663 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:57:14,663 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,663 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,725 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:57:14,725 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,725 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,757 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:57:14,761 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:57:14,761 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:57:14,761 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,761 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,773 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:57:14,805 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:57:14,809 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:57:14,809 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:57:14,810 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,810 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,867 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:57:14,900 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:57:14,904 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:57:14,904 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:14,904 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,904 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,916 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:57:14,916 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,916 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,917 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,917 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,948 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:57:14,952 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:57:14,952 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:57:14,953 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:14,953 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,010 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:57:15,010 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,010 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,042 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:57:15,046 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:57:15,046 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:57:15,047 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,047 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,058 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:57:15,058 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,059 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,090 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:57:15,094 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:57:15,094 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:15,094 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,094 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,152 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:15,184 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.txt
2024-07-12 10:57:15,188 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph.json
2024-07-12 10:57:15,188 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:57:15,189 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,189 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,200 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,201 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,202 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,202 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,234 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:57:15,238 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph.json
2024-07-12 10:57:15,238 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:15,238 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,238 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,306 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:57:15,307 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,340 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.txt
2024-07-12 10:57:15,344 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph.json
2024-07-12 10:57:15,344 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:57:15,345 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,345 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,357 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:57:15,357 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,357 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,388 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:57:15,392 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph.json
2024-07-12 10:57:15,393 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:57:15,393 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,393 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,453 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:57:15,453 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,453 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,454 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=194
2024-07-12 10:57:15,454 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=201
2024-07-12 10:57:15,488 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:57:15,492 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:57:15,493 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:15,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=201
2024-07-12 10:57:15,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,508 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:57:15,543 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:57:15,547 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph.json
2024-07-12 10:57:15,548 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:57:15,548 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,548 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,612 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:57:15,647 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.txt
2024-07-12 10:57:15,651 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph.json
2024-07-12 10:57:15,652 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:57:15,652 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,652 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,667 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:57:15,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,701 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.txt
2024-07-12 10:57:15,706 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph.json
2024-07-12 10:57:15,706 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:57:15,707 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,707 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,771 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float32/18-apply_padding_graph_vis.html
2024-07-12 10:57:15,772 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,772 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,807 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:57:15,812 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:57:15,812 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:15,812 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,812 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,827 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:15,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,827 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,827 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,829 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,829 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,856 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:57:15,860 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph.json
2024-07-12 10:57:15,860 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:15,860 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,860 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,921 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:57:15,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,921 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,922 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_22_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_26_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_29_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,923 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,924 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,945 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:57:15,948 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph.json
2024-07-12 10:57:15,948 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:57:15,948 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,948 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,956 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:57:15,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,978 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:57:15,980 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:57:15,980 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:57:15,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,981 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,988 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_25: total_params_size=120
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_28: total_params_size=120
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_31: total_params_size=104
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_35: total_params_size=104
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:15,988 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,009 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:57:16,012 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:57:16,012 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:57:16,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,066 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:57:16,087 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:57:16,089 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph.json
2024-07-12 10:57:16,090 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:57:16,090 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,090 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,097 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:57:16,119 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:57:16,121 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:57:16,121 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:57:16,122 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,122 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,130 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,152 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:57:16,154 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph.json
2024-07-12 10:57:16,154 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:16,155 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,155 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,162 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:57:16,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,183 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:57:16,185 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph.json
2024-07-12 10:57:16,186 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:57:16,186 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,186 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,240 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:57:16,240 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,241 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,261 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:57:16,264 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:57:16,264 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:57:16,264 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,264 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,272 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:57:16,293 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.txt
2024-07-12 10:57:16,295 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph.json
2024-07-12 10:57:16,296 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:57:16,296 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,296 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,303 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/optimize_graph_graph_vis.html
2024-07-12 10:57:16,303 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.914750
2024-07-12 10:57:16,303 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'concatenate', 'permute021'}
2024-07-12 10:57:16,303 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 13 to 10
2024-07-12 10:57:16,325 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.txt
2024-07-12 10:57:16,327 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph.json
2024-07-12 10:57:16,327 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_pseudo_code.txt
2024-07-12 10:57:16,328 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,328 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,335 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float32/refine_graph_graph_vis.html
2024-07-12 10:57:16,335 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:57:16,420 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,420 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_33 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:16,458 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,458 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_3 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_4', 0, 1)
2024-07-12 10:57:16,496 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rcr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,496 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rcr_bias_8 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tn_align_4_4', 0, 1)
2024-07-12 10:57:16,533 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,534 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_6 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:16,572 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,572 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_9 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:16,609 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:16,609 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_37 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:16,609 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.274172
2024-07-12 10:57:16,609 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:16,609 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000050
2024-07-12 10:57:16,610 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_33: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_3: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rcr_bias_8: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_6: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_9: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_37: B == 4 && M == 256 && N == 32 && K == 64
2024-07-12 10:57:16,610 INFO <aitemplate.compiler.transform.profile> ran 6 profilers elapsed time: 0:00:00.000123
2024-07-12 10:57:16,631 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.txt
2024-07-12 10:57:16,634 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph.json
2024-07-12 10:57:16,634 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/profile_pseudo_code.txt
2024-07-12 10:57:16,634 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,635 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,642 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float32/profile_graph_vis.html
2024-07-12 10:57:16,642 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:16,642 INFO <aitemplate.compiler.transform.memory_planning> max_blob=131072 constant_offset=99328
2024-07-12 10:57:16,643 INFO <aitemplate.backend.codegen> generated 4 function srcs
2024-07-12 10:57:16,644 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,644 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,660 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.txt
2024-07-12 10:57:16,662 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph.json
2024-07-12 10:57:16,662 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_pseudo_code.txt
2024-07-12 10:57:16,662 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,662 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,666 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float32/constant_folding_graph_vis.html
2024-07-12 10:57:16,666 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.023605
2024-07-12 10:57:16,681 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:57:16,683 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph.json
2024-07-12 10:57:16,683 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:16,684 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,684 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,687 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:16,687 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:16,687 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1048576 constant_offset=132608
2024-07-12 10:57:16,702 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.txt
2024-07-12 10:57:16,704 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph.json
2024-07-12 10:57:16,705 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_pseudo_code.txt
2024-07-12 10:57:16,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=39, tensor_cnt=0, len(func_name_to_tensor_cnt)=39, len(user_provided_dim)=214
2024-07-12 10:57:16,708 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float32/memory_planning_graph_vis.html
2024-07-12 10:57:16,709 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_22_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_26_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,709 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,709 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,710 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,710 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_0_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'W_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,711 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_29_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}], actual: [{ 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [128, 256]}, { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:16,711 INFO <aitemplate.backend.codegen> generated 6 function srcs
2024-07-12 10:57:16,714 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:57:16,715 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:16,727 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float32 -j24 all ']
2024-07-12 10:57:25,872 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
rm -f *.obj test_1.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_27_constant_folding.obj permute021_27_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_5_constant_folding.obj permute021_5_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_31_constant_folding.obj concatenate_31_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_25_constant_folding.obj concatenate_25_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_3.obj perm102_bmm_rcr_3.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_37.obj perm102_bmm_rrr_bias_37.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rcr_bias_8.obj perm102_bmm_rcr_bias_8.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_9.obj perm102_bmm_rrr_bias_9.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_33.obj perm102_bmm_rrr_bias_33.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_6.obj perm102_bmm_rrr_6.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_1.so perm102_bmm_rrr_bias_33.obj perm102_bmm_rcr_3.obj perm102_bmm_rcr_bias_8.obj perm102_bmm_rrr_6.obj perm102_bmm_rrr_bias_9.obj perm102_bmm_rrr_bias_37.obj permute021_5_constant_folding.obj concatenate_25_constant_folding.obj permute021_27_constant_folding.obj concatenate_31_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float32'

2024-07-12 10:57:25,872 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:57:25,872 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:09.157166, with optimize = True
[10:57:25] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:57:25] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:57:25] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
.2024-07-12 10:57:25,881 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/test_multi_parallel_gemm_cat_groups_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:57:25,881 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:57:25,881 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:57:25,881 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:57:25,881 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:57:26,464 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph.txt
2024-07-12 10:57:26,467 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph.json
2024-07-12 10:57:26,467 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_pseudo_code.txt
2024-07-12 10:57:26,467 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=214
2024-07-12 10:57:26,467 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=235
2024-07-12 10:57:26,525 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph_vis.html
2024-07-12 10:57:26,544 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph.txt
2024-07-12 10:57:26,546 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph.json
2024-07-12 10:57:26,547 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_pseudo_code.txt
2024-07-12 10:57:26,547 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=235
2024-07-12 10:57:26,547 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,558 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph_vis.html
2024-07-12 10:57:26,576 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph.txt
2024-07-12 10:57:26,579 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph.json
2024-07-12 10:57:26,579 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:57:26,580 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,580 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,636 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,656 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph.txt
2024-07-12 10:57:26,659 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph.json
2024-07-12 10:57:26,659 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:57:26,659 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,659 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,670 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph_vis.html
2024-07-12 10:57:26,670 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,670 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,689 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph.txt
2024-07-12 10:57:26,691 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph.json
2024-07-12 10:57:26,692 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_pseudo_code.txt
2024-07-12 10:57:26,692 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,692 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,703 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph_vis.html
2024-07-12 10:57:26,722 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:57:26,725 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.json
2024-07-12 10:57:26,725 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:26,725 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,725 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,784 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:26,803 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph.txt
2024-07-12 10:57:26,806 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph.json
2024-07-12 10:57:26,806 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:57:26,807 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,807 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,818 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:57:26,818 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,818 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,837 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:57:26,840 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:57:26,840 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:57:26,840 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,840 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,898 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:57:26,898 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:57:26,917 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:57:26,920 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:57:26,920 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:57:26,920 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,920 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,931 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:57:26,931 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,931 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,931 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,933 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,933 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,952 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:57:26,954 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:57:26,954 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:57:26,955 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:26,955 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,014 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:57:27,033 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:57:27,036 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:57:27,036 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:57:27,036 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,036 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,047 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:57:27,047 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,047 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,066 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:57:27,069 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:57:27,069 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:57:27,069 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,069 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,080 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:57:27,081 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,081 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,100 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:57:27,102 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:57:27,103 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:57:27,103 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,103 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,162 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:57:27,181 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:57:27,184 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:57:27,184 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:57:27,184 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,184 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,196 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:57:27,214 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:57:27,217 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:57:27,217 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:27,217 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,217 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,274 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:57:27,274 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,274 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,275 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,275 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,293 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:57:27,296 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:57:27,296 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:57:27,297 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,297 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,308 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:57:27,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,327 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:57:27,329 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:57:27,329 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:57:27,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,389 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:57:27,389 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,389 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,408 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:57:27,411 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:57:27,411 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:27,411 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,411 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,423 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:27,441 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph.txt
2024-07-12 10:57:27,444 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph.json
2024-07-12 10:57:27,444 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:57:27,444 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,444 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,455 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:57:27,455 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,455 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,455 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,455 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,456 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,488 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:57:27,504 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph.json
2024-07-12 10:57:27,506 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:27,507 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,508 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,660 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:57:27,660 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,660 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,679 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph.txt
2024-07-12 10:57:27,682 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph.json
2024-07-12 10:57:27,682 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:57:27,682 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,682 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,693 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,693 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:27,694 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=256
2024-07-12 10:57:27,694 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=256
2024-07-12 10:57:27,722 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:57:27,725 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph.json
2024-07-12 10:57:27,726 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:57:27,726 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=256
2024-07-12 10:57:27,726 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=256
2024-07-12 10:57:27,782 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:57:27,783 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=256
2024-07-12 10:57:27,784 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=268
2024-07-12 10:57:27,784 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=268
2024-07-12 10:57:27,784 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:27,824 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:57:27,830 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:57:27,830 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:27,830 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:27,830 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:27,896 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:57:27,936 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:57:27,942 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph.json
2024-07-12 10:57:27,942 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:57:27,942 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:27,942 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:27,962 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:57:28,002 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph.txt
2024-07-12 10:57:28,007 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph.json
2024-07-12 10:57:28,007 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:57:28,008 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,008 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,080 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:57:28,080 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,080 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,120 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph.txt
2024-07-12 10:57:28,126 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph.json
2024-07-12 10:57:28,126 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:57:28,126 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,193 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph_vis.html
2024-07-12 10:57:28,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,234 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:57:28,240 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:57:28,240 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:28,240 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,240 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,259 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:28,259 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,259 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,261 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,301 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:57:28,307 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph.json
2024-07-12 10:57:28,307 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:28,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,379 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:57:28,379 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,379 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,379 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,379 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,380 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_36_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_36_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_46_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_54_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['513'], original: [{ 'depth': 0,
  'name': 'reshape_32_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_32_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_58_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 513, 'values': [513]}]
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_34_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_34_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_43_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_62_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_38_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_49_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_66_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,381 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,382 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,382 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,414 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:57:28,418 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph.json
2024-07-12 10:57:28,418 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:57:28,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,477 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:57:28,477 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,477 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,509 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:57:28,512 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:57:28,513 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:57:28,513 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,513 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,525 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_39: total_params_size=120
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_42: total_params_size=120
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_45: total_params_size=120
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_48: total_params_size=120
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_51: total_params_size=104
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_55: total_params_size=104
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_59: total_params_size=104
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_63: total_params_size=104
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,525 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,557 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:57:28,561 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:57:28,561 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:57:28,561 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,561 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,621 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:57:28,653 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:57:28,657 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph.json
2024-07-12 10:57:28,657 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:57:28,657 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,657 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,669 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:57:28,701 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:57:28,705 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:57:28,705 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:57:28,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,719 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,752 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:57:28,755 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph.json
2024-07-12 10:57:28,756 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:28,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,817 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:57:28,817 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,817 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,849 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:57:28,853 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph.json
2024-07-12 10:57:28,853 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:57:28,853 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,853 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,864 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:57:28,864 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,864 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,896 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:57:28,900 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:57:28,900 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:57:28,901 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,901 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,958 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:57:28,990 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph.txt
2024-07-12 10:57:28,994 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph.json
2024-07-12 10:57:28,994 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:57:28,994 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:28,995 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,006 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph_vis.html
2024-07-12 10:57:29,006 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:02.187501
2024-07-12 10:57:29,006 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'concatenate', 'fused_elementwise', 'permute021'}
2024-07-12 10:57:29,006 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 26 to 20
2024-07-12 10:57:29,038 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph.txt
2024-07-12 10:57:29,042 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph.json
2024-07-12 10:57:29,042 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_pseudo_code.txt
2024-07-12 10:57:29,043 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,043 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,100 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph_vis.html
2024-07-12 10:57:29,100 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:57:29,138 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:29,138 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_53 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tt_align_8_8', 0, 1)
2024-07-12 10:57:29,175 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:29,175 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_57 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tt_align_8_8', 0, 1)
2024-07-12 10:57:29,212 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:29,212 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_61 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tt_align_8_8', 0, 1)
2024-07-12 10:57:29,248 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_65 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tt_align_8_8', 0, 1)
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.148225
2024-07-12 10:57:29,249 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000044
2024-07-12 10:57:29,249 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_53: B == 2 && M == 256 && N == 128 && K == 64
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_57: B == 4 && M == 256 && N == 128 && K == 120
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_61: B == 2 && M == 256 && N == 128 && K == 72
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_65: B == 2 && M == 256 && N == 128 && K == 64
2024-07-12 10:57:29,249 INFO <aitemplate.compiler.transform.profile> ran 4 profilers elapsed time: 0:00:00.000112
2024-07-12 10:57:29,282 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph.txt
2024-07-12 10:57:29,286 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph.json
2024-07-12 10:57:29,286 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_pseudo_code.txt
2024-07-12 10:57:29,286 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,286 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,298 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph_vis.html
2024-07-12 10:57:29,298 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:29,298 INFO <aitemplate.compiler.transform.memory_planning> max_blob=278528 constant_offset=227840
2024-07-12 10:57:29,299 INFO <aitemplate.backend.codegen> generated 8 function srcs
2024-07-12 10:57:29,301 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,301 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,324 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph.txt
2024-07-12 10:57:29,327 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph.json
2024-07-12 10:57:29,327 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_pseudo_code.txt
2024-07-12 10:57:29,327 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,327 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,334 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph_vis.html
2024-07-12 10:57:29,334 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.035779
2024-07-12 10:57:29,357 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:57:29,360 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.json
2024-07-12 10:57:29,360 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:29,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,413 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:29,413 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:29,413 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1105920 constant_offset=227840
2024-07-12 10:57:29,437 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph.txt
2024-07-12 10:57:29,439 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph.json
2024-07-12 10:57:29,440 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_pseudo_code.txt
2024-07-12 10:57:29,440 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,440 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=291
2024-07-12 10:57:29,446 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph_vis.html
2024-07-12 10:57:29,448 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_36_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_36_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_46_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:29,448 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_32_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_32_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:29,449 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_34_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_34_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_43_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:29,449 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_38_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_49_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:29,449 INFO <aitemplate.backend.codegen> generated 12 function srcs
2024-07-12 10:57:29,453 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:57:29,453 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:29,465 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float16 -j24 all ']
2024-07-12 10:57:41,127 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_26.obj fused_elementwise_26.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_23.obj fused_elementwise_23.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_22.obj fused_elementwise_22.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_25.obj fused_elementwise_25.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_28.obj fused_elementwise_28.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_27.obj fused_elementwise_27.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_24.obj fused_elementwise_24.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_21.obj fused_elementwise_21.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_41_constant_folding.obj permute021_41_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_44_constant_folding.obj permute021_44_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_47_constant_folding.obj permute021_47_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_55_constant_folding.obj concatenate_55_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_42_constant_folding.obj concatenate_42_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_45_constant_folding.obj concatenate_45_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_39_constant_folding.obj concatenate_39_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_51_constant_folding.obj concatenate_51_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_53.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_57.obj perm102_bmm_rrr_bias_57.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_61.obj perm102_bmm_rrr_bias_61.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_65.obj perm102_bmm_rrr_bias_65.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so fused_elementwise_21.obj fused_elementwise_22.obj fused_elementwise_23.obj fused_elementwise_24.obj fused_elementwise_25.obj fused_elementwise_26.obj fused_elementwise_27.obj fused_elementwise_28.obj perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_57.obj perm102_bmm_rrr_bias_61.obj perm102_bmm_rrr_bias_65.obj concatenate_39_constant_folding.obj permute021_41_constant_folding.obj concatenate_42_constant_folding.obj permute021_44_constant_folding.obj concatenate_45_constant_folding.obj permute021_47_constant_folding.obj concatenate_51_constant_folding.obj concatenate_55_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'

2024-07-12 10:57:41,127 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:57:41,127 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:11.674475, with optimize = True
[10:57:41] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:57:41] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:57:41] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
2024-07-12 10:57:41,136 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/test_multi_parallel_gemm_cat_groups_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:57:41,136 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:57:41,137 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:57:41,137 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:57:41,137 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:57:41,878 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph.txt
2024-07-12 10:57:41,879 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph.json
2024-07-12 10:57:41,880 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_pseudo_code.txt
2024-07-12 10:57:41,880 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=291
2024-07-12 10:57:41,880 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,887 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/toposort_graph_vis.html
2024-07-12 10:57:41,899 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph.txt
2024-07-12 10:57:41,901 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph.json
2024-07-12 10:57:41,901 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_pseudo_code.txt
2024-07-12 10:57:41,901 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,901 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,908 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/bind_constants_graph_vis.html
2024-07-12 10:57:41,920 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph.txt
2024-07-12 10:57:41,922 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph.json
2024-07-12 10:57:41,922 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:57:41,922 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,922 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,980 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,991 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph.txt
2024-07-12 10:57:41,993 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph.json
2024-07-12 10:57:41,993 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:57:41,994 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:41,994 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,001 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/remove_no_ops_graph_vis.html
2024-07-12 10:57:42,001 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,001 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,013 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph.txt
2024-07-12 10:57:42,015 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph.json
2024-07-12 10:57:42,016 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_pseudo_code.txt
2024-07-12 10:57:42,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,016 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,024 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/name_graph_graph_vis.html
2024-07-12 10:57:42,036 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:57:42,037 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.json
2024-07-12 10:57:42,037 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:42,038 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,038 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,045 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:42,056 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph.txt
2024-07-12 10:57:42,058 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph.json
2024-07-12 10:57:42,058 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:57:42,058 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,059 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,121 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:57:42,121 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,121 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,132 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:57:42,134 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:57:42,134 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:57:42,134 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,134 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,141 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:57:42,141 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:57:42,153 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:57:42,154 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:57:42,154 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:57:42,155 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,155 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,162 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,174 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:57:42,176 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:57:42,176 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:57:42,177 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,177 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,184 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:57:42,195 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:57:42,197 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:57:42,197 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:57:42,198 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,198 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,250 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:57:42,250 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,250 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,261 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:57:42,263 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:57:42,263 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:57:42,263 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,263 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,271 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:57:42,271 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,271 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,282 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:57:42,284 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:57:42,284 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:57:42,284 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,285 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,292 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:57:42,304 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:57:42,306 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:57:42,306 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:57:42,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,306 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,314 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:57:42,325 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:57:42,327 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:57:42,328 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:42,328 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,328 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,385 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:57:42,385 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,385 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,385 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,385 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,397 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:57:42,398 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:57:42,399 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:57:42,399 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,399 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,406 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:57:42,406 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,406 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,418 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:57:42,420 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:57:42,420 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:57:42,420 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,420 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,428 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:57:42,428 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,428 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,439 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:57:42,441 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:57:42,441 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:42,441 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,448 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:42,460 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph.txt
2024-07-12 10:57:42,462 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph.json
2024-07-12 10:57:42,462 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:57:42,462 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,462 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,521 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,522 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,533 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:57:42,535 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph.json
2024-07-12 10:57:42,535 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:42,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,536 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,543 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:57:42,543 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,543 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,554 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph.txt
2024-07-12 10:57:42,556 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph.json
2024-07-12 10:57:42,556 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:57:42,556 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,556 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,563 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,563 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:42,564 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=291
2024-07-12 10:57:42,564 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=19, tensor_cnt=0, len(func_name_to_tensor_cnt)=19, len(user_provided_dim)=291
2024-07-12 10:57:42,580 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:57:42,583 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph.json
2024-07-12 10:57:42,583 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:57:42,583 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=19, tensor_cnt=0, len(func_name_to_tensor_cnt)=19, len(user_provided_dim)=291
2024-07-12 10:57:42,583 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=19, tensor_cnt=0, len(func_name_to_tensor_cnt)=19, len(user_provided_dim)=291
2024-07-12 10:57:42,590 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:57:42,591 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=19, tensor_cnt=0, len(func_name_to_tensor_cnt)=19, len(user_provided_dim)=291
2024-07-12 10:57:42,591 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=295
2024-07-12 10:57:42,591 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=295
2024-07-12 10:57:42,591 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,615 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:57:42,618 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:57:42,618 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:42,619 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,619 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,677 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:57:42,701 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:57:42,704 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph.json
2024-07-12 10:57:42,704 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:57:42,705 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,705 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,716 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:57:42,740 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph.txt
2024-07-12 10:57:42,743 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph.json
2024-07-12 10:57:42,743 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:57:42,744 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,744 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,819 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:57:42,819 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,819 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,844 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph.txt
2024-07-12 10:57:42,847 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph.json
2024-07-12 10:57:42,848 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:57:42,848 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,848 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,860 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/18-apply_padding_graph_vis.html
2024-07-12 10:57:42,860 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,860 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,885 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:57:42,888 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:57:42,889 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:42,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,889 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,955 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:42,955 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,955 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,956 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,957 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,957 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,981 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:57:42,984 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph.json
2024-07-12 10:57:42,985 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:42,985 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,985 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,996 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:57:42,996 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,996 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,997 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_22_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_22_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_27_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_32_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'w_2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_20_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_20_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_36_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1], [1])], stride_strs: ['129'], original: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'w_5_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 129, 'values': [129]}]
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:42,998 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,018 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:57:43,021 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph.json
2024-07-12 10:57:43,021 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:57:43,021 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,021 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,029 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:57:43,029 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,029 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,048 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:57:43,051 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:57:43,051 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:57:43,051 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,051 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,123 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:57:43,123 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_23: total_params_size=120
2024-07-12 10:57:43,123 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_26: total_params_size=120
2024-07-12 10:57:43,123 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_29: total_params_size=104
2024-07-12 10:57:43,123 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_33: total_params_size=104
2024-07-12 10:57:43,123 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,124 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,144 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:57:43,147 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:57:43,148 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:57:43,148 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,148 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,156 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:57:43,177 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:57:43,179 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph.json
2024-07-12 10:57:43,180 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:57:43,180 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,180 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,188 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:57:43,208 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:57:43,211 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:57:43,211 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:57:43,211 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,211 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,268 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,287 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:57:43,289 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph.json
2024-07-12 10:57:43,289 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:43,290 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,290 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,297 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:57:43,297 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,297 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,317 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:57:43,319 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph.json
2024-07-12 10:57:43,320 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:57:43,320 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,320 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,327 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:57:43,327 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,327 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,347 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:57:43,349 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:57:43,349 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:57:43,349 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,349 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,357 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:57:43,376 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph.txt
2024-07-12 10:57:43,379 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph.json
2024-07-12 10:57:43,379 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:57:43,379 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,379 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,450 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/optimize_graph_graph_vis.html
2024-07-12 10:57:43,450 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.329464
2024-07-12 10:57:43,450 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'concatenate'}
2024-07-12 10:57:43,450 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 16 to 15
2024-07-12 10:57:43,471 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph.txt
2024-07-12 10:57:43,473 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph.json
2024-07-12 10:57:43,474 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_pseudo_code.txt
2024-07-12 10:57:43,474 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,474 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,482 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/refine_graph_graph_vis.html
2024-07-12 10:57:43,483 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:57:43,522 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:43,522 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_31 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tt_align_8_8', 0, 1)
2024-07-12 10:57:43,560 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:43,560 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_8 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8', 0, 1)
2024-07-12 10:57:43,597 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:43,597 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_35 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tt_align_8_8', 0, 1)
2024-07-12 10:57:43,634 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_11 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8', 0, 1)
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.151689
2024-07-12 10:57:43,634 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000052
2024-07-12 10:57:43,634 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_31: B == 2 && M == 256 && N == 128 && K == 64
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_bias_8: M == 256 && N == 128 && K == 120
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_35: B == 2 && M == 256 && N == 128 && K == 72
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_bias_11: M == 256 && N == 128 && K == 64
2024-07-12 10:57:43,634 INFO <aitemplate.compiler.transform.profile> ran 4 profilers elapsed time: 0:00:00.000105
2024-07-12 10:57:43,654 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph.txt
2024-07-12 10:57:43,657 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph.json
2024-07-12 10:57:43,657 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_pseudo_code.txt
2024-07-12 10:57:43,658 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,658 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,665 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/profile_graph_vis.html
2024-07-12 10:57:43,665 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:43,665 INFO <aitemplate.compiler.transform.memory_planning> max_blob=106496 constant_offset=70656
2024-07-12 10:57:43,666 INFO <aitemplate.backend.codegen> generated 5 function srcs
2024-07-12 10:57:43,667 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,667 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,683 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph.txt
2024-07-12 10:57:43,685 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph.json
2024-07-12 10:57:43,686 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_pseudo_code.txt
2024-07-12 10:57:43,686 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,686 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,753 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/constant_folding_graph_vis.html
2024-07-12 10:57:43,753 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.088209
2024-07-12 10:57:43,769 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:57:43,772 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph.json
2024-07-12 10:57:43,772 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:43,772 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,772 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,777 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:43,777 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:43,777 INFO <aitemplate.compiler.transform.memory_planning> max_blob=626688 constant_offset=118272
2024-07-12 10:57:43,793 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph.txt
2024-07-12 10:57:43,795 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph.json
2024-07-12 10:57:43,795 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_pseudo_code.txt
2024-07-12 10:57:43,796 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,796 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=37, tensor_cnt=0, len(func_name_to_tensor_cnt)=37, len(user_provided_dim)=302
2024-07-12 10:57:43,801 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float16/memory_planning_graph_vis.html
2024-07-12 10:57:43,802 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'reshape_22_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_22_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_27_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:43,803 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['768'], original: [{ 'depth': 0,
  'name': 'reshape_20_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_20_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_24_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 768,
  'values': [768]}]
2024-07-12 10:57:43,803 INFO <aitemplate.backend.codegen> generated 10 function srcs
2024-07-12 10:57:43,807 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:57:43,807 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:43,817 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float16 -j24 all ']
2024-07-12 10:57:54,342 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
rm -f *.obj test_1.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_17.obj fused_elementwise_17.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_18.obj fused_elementwise_18.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_16.obj fused_elementwise_16.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_15.obj fused_elementwise_15.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_14.obj fused_elementwise_14.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_13.obj fused_elementwise_13.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_28_constant_folding.obj permute021_28_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_25_constant_folding.obj permute021_25_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_23_constant_folding.obj concatenate_23_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_26_constant_folding.obj concatenate_26_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_29_constant_folding.obj concatenate_29_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_31.obj perm102_bmm_rrr_bias_31.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o gemm_rcr_bias_8.obj gemm_rcr_bias_8.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o gemm_rcr_bias_11.obj gemm_rcr_bias_11.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_35.obj perm102_bmm_rrr_bias_35.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_1.so fused_elementwise_13.obj fused_elementwise_14.obj fused_elementwise_15.obj fused_elementwise_16.obj fused_elementwise_17.obj fused_elementwise_18.obj perm102_bmm_rrr_bias_31.obj gemm_rcr_bias_8.obj perm102_bmm_rrr_bias_35.obj gemm_rcr_bias_11.obj concatenate_23_constant_folding.obj permute021_25_constant_folding.obj concatenate_26_constant_folding.obj permute021_28_constant_folding.obj concatenate_29_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float16'

2024-07-12 10:57:54,342 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:57:54,342 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:10.534355, with optimize = True
[10:57:54] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:57:54] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:57:54] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
.2024-07-12 10:57:54,348 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/test_multi_parallel_gemm_cat_groups_float32', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:57:54,348 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:57:54,349 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:57:54,349 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:57:54,349 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:57:54,949 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/toposort_graph.txt
2024-07-12 10:57:54,951 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/toposort_graph.json
2024-07-12 10:57:54,952 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/toposort_pseudo_code.txt
2024-07-12 10:57:54,952 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=302
2024-07-12 10:57:54,952 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:54,964 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/toposort_graph_vis.html
2024-07-12 10:57:54,983 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/bind_constants_graph.txt
2024-07-12 10:57:54,985 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/bind_constants_graph.json
2024-07-12 10:57:54,986 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/bind_constants_pseudo_code.txt
2024-07-12 10:57:54,986 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:54,986 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,074 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/bind_constants_graph_vis.html
2024-07-12 10:57:55,096 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_unused_ops_graph.txt
2024-07-12 10:57:55,099 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_unused_ops_graph.json
2024-07-12 10:57:55,099 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_unused_ops_pseudo_code.txt
2024-07-12 10:57:55,100 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,100 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,112 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_unused_ops_graph_vis.html
2024-07-12 10:57:55,112 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,113 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,133 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_no_ops_graph.txt
2024-07-12 10:57:55,135 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_no_ops_graph.json
2024-07-12 10:57:55,136 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_no_ops_pseudo_code.txt
2024-07-12 10:57:55,136 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,136 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,147 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/remove_no_ops_graph_vis.html
2024-07-12 10:57:55,147 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,147 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,166 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/name_graph_graph.txt
2024-07-12 10:57:55,169 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/name_graph_graph.json
2024-07-12 10:57:55,169 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/name_graph_pseudo_code.txt
2024-07-12 10:57:55,169 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,170 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,243 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/name_graph_graph_vis.html
2024-07-12 10:57:55,262 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:57:55,265 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph.json
2024-07-12 10:57:55,266 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:55,266 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,266 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,279 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:55,299 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/mark_param_tensor_graph.txt
2024-07-12 10:57:55,302 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/mark_param_tensor_graph.json
2024-07-12 10:57:55,302 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/mark_param_tensor_pseudo_code.txt
2024-07-12 10:57:55,302 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,302 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,389 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/mark_param_tensor_graph_vis.html
2024-07-12 10:57:55,389 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,389 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,408 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:57:55,411 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:57:55,411 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:57:55,412 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,412 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,424 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:57:55,424 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:57:55,444 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:57:55,447 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:57:55,447 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:57:55,448 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,448 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,533 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:57:55,533 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,534 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,554 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:57:55,557 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:57:55,558 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:57:55,558 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,558 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,571 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:57:55,590 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/03-fuse_bmm_permute_graph.txt
2024-07-12 10:57:55,593 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/03-fuse_bmm_permute_graph.json
2024-07-12 10:57:55,594 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:57:55,594 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,594 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,607 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:57:55,607 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,607 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,626 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/04-fuse_expand_bmm_graph.txt
2024-07-12 10:57:55,629 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/04-fuse_expand_bmm_graph.json
2024-07-12 10:57:55,630 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:57:55,630 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,630 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,717 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:57:55,718 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,718 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,737 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/05-transform_odd_alignment_graph.txt
2024-07-12 10:57:55,740 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/05-transform_odd_alignment_graph.json
2024-07-12 10:57:55,741 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:57:55,741 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,741 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,755 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:57:55,776 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:57:55,780 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/06-fuse_conv_elementwise_graph.json
2024-07-12 10:57:55,780 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:57:55,780 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,780 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:55,993 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:57:56,023 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:57:56,027 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:57:56,027 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:56,027 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,027 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,042 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:57:56,042 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,042 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,043 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,043 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,063 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:57:56,066 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/08-fuse_mm_elementwise_graph.json
2024-07-12 10:57:56,066 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:57:56,067 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,067 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,138 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:57:56,138 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,138 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,157 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:57:56,159 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:57:56,160 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:57:56,160 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,160 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,171 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:57:56,171 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,171 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,190 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/10-move_view_op_before_concat_graph.txt
2024-07-12 10:57:56,193 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/10-move_view_op_before_concat_graph.json
2024-07-12 10:57:56,193 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:56,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,205 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:56,224 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/11-merge_view_ops_graph.txt
2024-07-12 10:57:56,227 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/11-merge_view_ops_graph.json
2024-07-12 10:57:56,227 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:57:56,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,294 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/11-merge_view_ops_graph_vis.html
2024-07-12 10:57:56,294 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,294 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,294 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,295 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,296 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,314 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/12-transform_memory_ops_graph.txt
2024-07-12 10:57:56,317 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/12-transform_memory_ops_graph.json
2024-07-12 10:57:56,317 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:56,318 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,318 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,329 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/12-transform_memory_ops_graph_vis.html
2024-07-12 10:57:56,329 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,329 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,349 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/13-fuse_ops_graph.txt
2024-07-12 10:57:56,351 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/13-fuse_ops_graph.json
2024-07-12 10:57:56,352 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/13-fuse_ops_pseudo_code.txt
2024-07-12 10:57:56,352 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,352 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,420 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/13-fuse_ops_graph_vis.html
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,420 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: set(), to_be_removed_set: set(), final_set: set()
2024-07-12 10:57:56,421 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=21, tensor_cnt=0, len(func_name_to_tensor_cnt)=21, len(user_provided_dim)=302
2024-07-12 10:57:56,421 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=302
2024-07-12 10:57:56,449 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/14-fuse_elementwise_graph.txt
2024-07-12 10:57:56,453 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/14-fuse_elementwise_graph.json
2024-07-12 10:57:56,453 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:57:56,453 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=302
2024-07-12 10:57:56,454 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=302
2024-07-12 10:57:56,465 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/14-fuse_elementwise_graph_vis.html
2024-07-12 10:57:56,465 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=31, tensor_cnt=0, len(func_name_to_tensor_cnt)=31, len(user_provided_dim)=302
2024-07-12 10:57:56,466 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,466 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,466 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,516 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:57:56,541 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/15-fuse_parallel_gemms_graph.json
2024-07-12 10:57:56,543 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:57:56,545 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,545 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,710 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:57:56,751 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/16-fuse_group_ops_graph.txt
2024-07-12 10:57:56,757 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/16-fuse_group_ops_graph.json
2024-07-12 10:57:56,757 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:57:56,757 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,757 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,826 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/16-fuse_group_ops_graph_vis.html
2024-07-12 10:57:56,865 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/17-transform_special_ops_graph.txt
2024-07-12 10:57:56,871 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/17-transform_special_ops_graph.json
2024-07-12 10:57:56,871 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:57:56,872 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,872 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,891 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/17-transform_special_ops_graph_vis.html
2024-07-12 10:57:56,891 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,891 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,931 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/18-apply_padding_graph.txt
2024-07-12 10:57:56,937 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/18-apply_padding_graph.json
2024-07-12 10:57:56,937 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/18-apply_padding_pseudo_code.txt
2024-07-12 10:57:56,937 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:56,937 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,012 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/18-apply_padding_graph_vis.html
2024-07-12 10:57:57,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,052 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/19-move_view_op_before_concat_graph.txt
2024-07-12 10:57:57,058 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/19-move_view_op_before_concat_graph.json
2024-07-12 10:57:57,058 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:57:57,058 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,058 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,126 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,128 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,129 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,168 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/20-transform_memory_ops_graph.txt
2024-07-12 10:57:57,174 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/20-transform_memory_ops_graph.json
2024-07-12 10:57:57,174 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:57,174 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,174 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,194 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/20-transform_memory_ops_graph_vis.html
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,194 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0]), ([2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0, 1], [0])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> generate dim_mapping: [([0], [0]), ([1, 2], [1])]
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,195 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_36_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_36_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_46_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_54_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['513'], original: [{ 'depth': 0,
  'name': 'reshape_32_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_32_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_58_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 513, 'values': [513]}]
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_34_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_34_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_43_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_62_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['257'], original: [{ 'depth': 0,
  'name': 'reshape_38_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_49_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'reshape_66_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, {'depth': 0, 'name': None, 'nop': False, 'symbolic_value': 257, 'values': [257]}]
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,196 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,229 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/21-transform_strided_ops_graph.txt
2024-07-12 10:57:57,233 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/21-transform_strided_ops_graph.json
2024-07-12 10:57:57,233 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:57:57,234 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,234 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,298 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/21-transform_strided_ops_graph_vis.html
2024-07-12 10:57:57,298 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,298 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,330 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:57:57,334 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:57:57,334 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:57:57,335 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,335 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,346 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_39: total_params_size=120
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_42: total_params_size=120
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_45: total_params_size=120
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_48: total_params_size=120
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_51: total_params_size=104
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_55: total_params_size=104
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_59: total_params_size=104
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_63: total_params_size=104
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,347 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,380 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/23-split_large_concat_ops_graph.txt
2024-07-12 10:57:57,383 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/23-split_large_concat_ops_graph.json
2024-07-12 10:57:57,384 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:57:57,384 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,384 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,443 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:57:57,475 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/24-split_large_split_ops_graph.txt
2024-07-12 10:57:57,479 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/24-split_large_split_ops_graph.json
2024-07-12 10:57:57,479 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:57:57,479 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,480 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,491 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/24-split_large_split_ops_graph_vis.html
2024-07-12 10:57:57,523 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:57:57,527 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/25-transform_permute_to_reshape_graph.json
2024-07-12 10:57:57,527 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:57:57,528 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,528 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,587 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:57:57,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,587 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,587 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,621 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/26-transform_memory_ops_graph.txt
2024-07-12 10:57:57,624 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/26-transform_memory_ops_graph.json
2024-07-12 10:57:57,625 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:57:57,625 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,625 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,637 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/26-transform_memory_ops_graph_vis.html
2024-07-12 10:57:57,637 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,637 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,668 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/27-eliminate_permutations_graph.txt
2024-07-12 10:57:57,672 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/27-eliminate_permutations_graph.json
2024-07-12 10:57:57,672 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:57:57,673 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,673 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,684 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/27-eliminate_permutations_graph_vis.html
2024-07-12 10:57:57,684 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,684 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,716 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:57:57,720 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:57:57,720 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:57:57,769 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,769 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,780 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:57:57,811 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/optimize_graph_graph.txt
2024-07-12 10:57:57,815 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/optimize_graph_graph.json
2024-07-12 10:57:57,815 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/optimize_graph_pseudo_code.txt
2024-07-12 10:57:57,816 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,816 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,827 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/optimize_graph_graph_vis.html
2024-07-12 10:57:57,827 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:02.438414
2024-07-12 10:57:57,827 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'concatenate', 'fused_elementwise', 'permute021'}
2024-07-12 10:57:57,827 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 26 to 20
2024-07-12 10:57:57,859 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/refine_graph_graph.txt
2024-07-12 10:57:57,863 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/refine_graph_graph.json
2024-07-12 10:57:57,863 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/refine_graph_pseudo_code.txt
2024-07-12 10:57:57,863 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,863 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:57,919 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/refine_graph_graph_vis.html
2024-07-12 10:57:57,919 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:57:57,958 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:57,958 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_53 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:57,996 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:57,997 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_57 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:58,034 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:58,035 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_61 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_16x10_tt_align_4_4', 0, 1)
2024-07-12 10:57:58,073 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for perm102_bmm_rrr_bias: reduced the number of generated kernels from 288 to 32
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for perm102_bmm_rrr_bias_65 from cache: ('cutlass_tensorop_s1688tf32gemm_64x64_32x5_tt_align_4_4', 0, 1)
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.153669
2024-07-12 10:57:58,073 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000044
2024-07-12 10:57:58,073 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_53: B == 2 && M == 256 && N == 128 && K == 64
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_57: B == 4 && M == 256 && N == 128 && K == 120
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_61: B == 2 && M == 256 && N == 128 && K == 72
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: perm102_bmm_rrr_bias_65: B == 2 && M == 256 && N == 128 && K == 64
2024-07-12 10:57:58,073 INFO <aitemplate.compiler.transform.profile> ran 4 profilers elapsed time: 0:00:00.000102
2024-07-12 10:57:58,105 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/profile_graph.txt
2024-07-12 10:57:58,110 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/profile_graph.json
2024-07-12 10:57:58,110 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/profile_pseudo_code.txt
2024-07-12 10:57:58,110 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,110 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,164 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/profile_graph_vis.html
2024-07-12 10:57:58,165 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:58,165 INFO <aitemplate.compiler.transform.memory_planning> max_blob=557056 constant_offset=455680
2024-07-12 10:57:58,166 INFO <aitemplate.backend.codegen> generated 8 function srcs
2024-07-12 10:57:58,168 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,168 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,191 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/constant_folding_graph.txt
2024-07-12 10:57:58,194 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/constant_folding_graph.json
2024-07-12 10:57:58,194 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/constant_folding_pseudo_code.txt
2024-07-12 10:57:58,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,200 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/constant_folding_graph_vis.html
2024-07-12 10:57:58,200 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.035613
2024-07-12 10:57:58,224 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph.txt
2024-07-12 10:57:58,226 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph.json
2024-07-12 10:57:58,227 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:57:58,227 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,227 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,233 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/dedup_symbolic_name_graph_vis.html
2024-07-12 10:57:58,233 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:57:58,233 INFO <aitemplate.compiler.transform.memory_planning> max_blob=2211840 constant_offset=455680
2024-07-12 10:57:58,257 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/memory_planning_graph.txt
2024-07-12 10:57:58,260 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/test_multi_parallel_gemm_cat_groups_float32/memory_planning_graph.json
2024-07-12 10:57:58,260 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/test_multi_parallel_gemm_cat_groups_float32/memory_planning_pseudo_code.txt
2024-07-12 10:57:58,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=67, tensor_cnt=0, len(func_name_to_tensor_cnt)=67, len(user_provided_dim)=302
2024-07-12 10:57:58,266 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/test_multi_parallel_gemm_cat_groups_float32/memory_planning_graph_vis.html
2024-07-12 10:57:58,268 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_36_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_36_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_46_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:58,269 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_32_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_32_0_dim_1',
  'nop': False,
  'symbolic_value': 4,
  'values': [4]}, { 'depth': 0,
  'name': 'reshape_40_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:58,269 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_34_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_34_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_43_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:58,269 DEBUG <aitemplate.compiler.tensor_accessor> dim: 0, stride_dim: 1, mapping: [([0], [0]), ([1, 2], [1])], stride_strs: ['1280'], original: [{ 'depth': 0,
  'name': 'reshape_38_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'reshape_38_0_dim_1',
  'nop': False,
  'symbolic_value': 2,
  'values': [2]}, { 'depth': 0,
  'name': 'reshape_49_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}], actual: [{ 'depth': 0,
  'name': 'x_0_dim_0',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}, { 'depth': 0,
  'name': 'y_dim_1',
  'nop': False,
  'symbolic_value': 1280,
  'values': [1280]}]
2024-07-12 10:57:58,270 INFO <aitemplate.backend.codegen> generated 12 function srcs
2024-07-12 10:57:58,273 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:57:58,273 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:57:58,282 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float32 clean ', ' /usr/bin/make --output-sync -C ./tmp/test_multi_parallel_gemm_cat_groups_float32 -j24 all ']
2024-07-12 10:58:10,054 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_22.obj fused_elementwise_22.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_21.obj fused_elementwise_21.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_25.obj fused_elementwise_25.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_23.obj fused_elementwise_23.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_28.obj fused_elementwise_28.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_27.obj fused_elementwise_27.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_26.obj fused_elementwise_26.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_24.obj fused_elementwise_24.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_44_constant_folding.obj permute021_44_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_47_constant_folding.obj permute021_47_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o permute021_41_constant_folding.obj permute021_41_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_42_constant_folding.obj concatenate_42_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_51_constant_folding.obj concatenate_51_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_39_constant_folding.obj concatenate_39_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_45_constant_folding.obj concatenate_45_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_55_constant_folding.obj concatenate_55_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_57.obj perm102_bmm_rrr_bias_57.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_65.obj perm102_bmm_rrr_bias_65.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_61.obj perm102_bmm_rrr_bias_61.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_53.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so fused_elementwise_21.obj fused_elementwise_22.obj fused_elementwise_23.obj fused_elementwise_24.obj fused_elementwise_25.obj fused_elementwise_26.obj fused_elementwise_27.obj fused_elementwise_28.obj perm102_bmm_rrr_bias_53.obj perm102_bmm_rrr_bias_57.obj perm102_bmm_rrr_bias_61.obj perm102_bmm_rrr_bias_65.obj concatenate_39_constant_folding.obj permute021_41_constant_folding.obj concatenate_42_constant_folding.obj permute021_44_constant_folding.obj concatenate_45_constant_folding.obj permute021_47_constant_folding.obj concatenate_51_constant_folding.obj concatenate_55_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/test_multi_parallel_gemm_cat_groups_float32'

2024-07-12 10:58:10,054 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:58:10,054 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:11.781180, with optimize = True
[10:58:10] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:58:10] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:58:10] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
.INFO:__main__:_skip_fuse_parallel_gemm_cat, b: 4, ms: [256, 512], n: 128, k: 64
2024-07-12 10:58:10,072 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_parallel_gemm_cat_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:58:10,072 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:58:10,073 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:58:10,073 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:58:10,073 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:58:10,706 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.txt
2024-07-12 10:58:10,707 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph.json
2024-07-12 10:58:10,708 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/toposort_pseudo_code.txt
2024-07-12 10:58:10,708 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=302
2024-07-12 10:58:10,708 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,714 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_parallel_gemm_cat_float16/toposort_graph_vis.html
2024-07-12 10:58:10,725 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.txt
2024-07-12 10:58:10,726 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph.json
2024-07-12 10:58:10,726 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_pseudo_code.txt
2024-07-12 10:58:10,727 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,727 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,731 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_parallel_gemm_cat_float16/bind_constants_graph_vis.html
2024-07-12 10:58:10,742 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.txt
2024-07-12 10:58:10,744 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph.json
2024-07-12 10:58:10,744 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:58:10,744 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,744 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,810 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.txt
2024-07-12 10:58:10,811 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph.json
2024-07-12 10:58:10,811 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:58:10,811 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,811 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,816 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/remove_no_ops_graph_vis.html
2024-07-12 10:58:10,816 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,816 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,826 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.txt
2024-07-12 10:58:10,828 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph.json
2024-07-12 10:58:10,828 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_pseudo_code.txt
2024-07-12 10:58:10,828 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,828 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,833 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/name_graph_graph_vis.html
2024-07-12 10:58:10,843 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:10,845 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:10,845 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:10,845 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,845 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,849 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:10,859 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.txt
2024-07-12 10:58:10,861 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph.json
2024-07-12 10:58:10,861 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:58:10,861 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,861 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,865 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_parallel_gemm_cat_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:58:10,866 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,866 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,876 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:58:10,877 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:58:10,877 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:58:10,877 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,877 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,882 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:58:10,882 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:58:10,892 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:58:10,894 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:58:10,894 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:58:10,894 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,894 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,898 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,899 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,909 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:58:10,911 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:58:10,911 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:58:10,911 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,911 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,967 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_parallel_gemm_cat_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:58:10,977 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:58:10,978 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:58:10,978 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:58:10,979 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,979 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,983 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:58:10,983 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,983 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,993 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:58:10,995 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:58:10,995 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:58:10,995 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,995 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,999 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_parallel_gemm_cat_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:58:10,999 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:10,999 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,010 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:58:11,011 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:58:11,011 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:58:11,012 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,012 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,016 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_parallel_gemm_cat_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:58:11,027 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:58:11,028 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:58:11,028 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:58:11,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,033 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:58:11,043 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:58:11,044 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:58:11,045 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:11,045 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,045 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,049 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:58:11,049 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,049 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,049 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,049 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,060 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:58:11,061 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:58:11,061 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:58:11,061 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,061 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,066 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:58:11,066 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,066 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,076 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:58:11,078 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:58:11,078 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:58:11,078 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,078 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,082 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_parallel_gemm_cat_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:58:11,083 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,083 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,093 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:58:11,094 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:58:11,094 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:11,143 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,143 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,147 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:11,157 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.txt
2024-07-12 10:58:11,159 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph.json
2024-07-12 10:58:11,159 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:58:11,159 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,159 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,163 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:58:11,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,164 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,174 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:58:11,176 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph.json
2024-07-12 10:58:11,176 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:11,176 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,176 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,181 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:58:11,181 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,181 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,191 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.txt
2024-07-12 10:58:11,192 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph.json
2024-07-12 10:58:11,193 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:58:11,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,197 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:58:11,197 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,197 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,207 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:58:11,209 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph.json
2024-07-12 10:58:11,209 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:58:11,209 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,209 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,214 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:58:11,214 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,214 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,214 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,214 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,224 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:58:11,225 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:58:11,225 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:11,226 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,226 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,230 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_parallel_gemm_cat_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:58:11,240 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:58:11,241 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph.json
2024-07-12 10:58:11,241 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:58:11,241 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,242 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,293 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:58:11,303 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.txt
2024-07-12 10:58:11,305 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph.json
2024-07-12 10:58:11,305 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:58:11,305 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,305 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,309 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:58:11,309 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,309 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,319 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.txt
2024-07-12 10:58:11,321 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph.json
2024-07-12 10:58:11,321 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:58:11,321 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,321 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,326 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_parallel_gemm_cat_float16/18-apply_padding_graph_vis.html
2024-07-12 10:58:11,326 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,326 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,336 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:58:11,338 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:58:11,338 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:11,338 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,338 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_parallel_gemm_cat_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,342 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,353 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:58:11,355 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph.json
2024-07-12 10:58:11,355 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:11,355 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,355 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,359 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,360 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,370 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:58:11,372 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph.json
2024-07-12 10:58:11,372 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:58:11,372 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,372 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,377 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:58:11,377 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,377 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,387 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:58:11,388 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:58:11,388 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:58:11,389 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,389 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,393 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:58:11,393 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_5: total_params_size=120
2024-07-12 10:58:11,393 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,393 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,403 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:58:11,405 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:58:11,405 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:58:11,405 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,405 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,410 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:58:11,410 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:58:11,420 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:58:11,422 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph.json
2024-07-12 10:58:11,422 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:58:11,422 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,422 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,477 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:58:11,487 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:58:11,488 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:58:11,489 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:58:11,489 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,489 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_parallel_gemm_cat_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,493 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,494 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,504 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:58:11,505 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph.json
2024-07-12 10:58:11,505 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:11,506 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,506 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,510 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_parallel_gemm_cat_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:58:11,510 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,510 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,521 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:58:11,522 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph.json
2024-07-12 10:58:11,522 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:58:11,523 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,523 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,527 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_parallel_gemm_cat_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:58:11,527 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,527 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,538 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:58:11,539 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:58:11,539 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:58:11,540 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,540 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,544 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_parallel_gemm_cat_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:58:11,554 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.txt
2024-07-12 10:58:11,556 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph.json
2024-07-12 10:58:11,556 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:58:11,557 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,557 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,561 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/optimize_graph_graph_vis.html
2024-07-12 10:58:11,561 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.695681
2024-07-12 10:58:11,561 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'gemm_rcr_bias'}
2024-07-12 10:58:11,561 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 6 to 3
2024-07-12 10:58:11,571 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.txt
2024-07-12 10:58:11,573 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph.json
2024-07-12 10:58:11,573 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_pseudo_code.txt
2024-07-12 10:58:11,573 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,573 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,578 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_parallel_gemm_cat_float16/refine_graph_graph_vis.html
2024-07-12 10:58:11,579 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:58:11,616 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:11,617 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_1 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8', 0, 1)
2024-07-12 10:58:11,701 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:11,701 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_1 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8', 0, 1)
2024-07-12 10:58:11,739 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:11,739 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_1 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8', 0, 1)
2024-07-12 10:58:11,776 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:11,777 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_1 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8', 0, 1)
2024-07-12 10:58:11,777 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.198063
2024-07-12 10:58:11,777 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:11,777 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000049
2024-07-12 10:58:11,777 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:58:11,777 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_bias_1: M == 512 && N == 128 && K == 64
2024-07-12 10:58:11,777 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000070
2024-07-12 10:58:11,787 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.txt
2024-07-12 10:58:11,789 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph.json
2024-07-12 10:58:11,789 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/profile_pseudo_code.txt
2024-07-12 10:58:11,789 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,789 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,794 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_parallel_gemm_cat_float16/profile_graph_vis.html
2024-07-12 10:58:11,794 INFO <aitemplate.compiler.transform.constant_folding> No constants to fold, skipping constant folding.
2024-07-12 10:58:11,794 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,794 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,805 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.txt
2024-07-12 10:58:11,807 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph.json
2024-07-12 10:58:11,807 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_pseudo_code.txt
2024-07-12 10:58:11,807 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,807 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,812 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_parallel_gemm_cat_float16/constant_folding_graph_vis.html
2024-07-12 10:58:11,812 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.017833
2024-07-12 10:58:11,823 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:11,825 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:11,825 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:11,825 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,825 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,829 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_parallel_gemm_cat_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:11,829 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:11,829 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1048576 constant_offset=66560
2024-07-12 10:58:11,840 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.txt
2024-07-12 10:58:11,842 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph.json
2024-07-12 10:58:11,842 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_pseudo_code.txt
2024-07-12 10:58:11,842 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,842 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:11,847 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_parallel_gemm_cat_float16/memory_planning_graph_vis.html
2024-07-12 10:58:11,847 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:58:11,850 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:58:11,850 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:11,864 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_parallel_gemm_cat_float16 -j24 all ']
2024-07-12 10:58:19,946 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_0.obj split_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_5.obj concatenate_5.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o gemm_rcr_bias_1.obj gemm_rcr_bias_1.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so split_0.obj gemm_rcr_bias_1.obj concatenate_5.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_parallel_gemm_cat_float16'

2024-07-12 10:58:19,947 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:58:19,947 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.096763, with optimize = True
[10:58:19] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:58:19] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:58:19] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
[10:58:19] model_interface.cu:221: Error: Got wrong number of outputs; expected 1, got 5
E2024-07-12 10:58:19,957 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=302
2024-07-12 10:58:19,958 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=13, tensor_cnt=0, len(func_name_to_tensor_cnt)=13, len(user_provided_dim)=304
2024-07-12 10:58:20,024 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:58:20,025 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:58:20,026 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:58:20,026 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:58:20,026 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:58:20,676 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/toposort_graph.txt
2024-07-12 10:58:20,677 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/toposort_graph.json
2024-07-12 10:58:20,677 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/toposort_pseudo_code.txt
2024-07-12 10:58:20,678 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=304
2024-07-12 10:58:20,678 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,682 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/toposort_graph_vis.html
2024-07-12 10:58:20,687 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/bind_constants_graph.txt
2024-07-12 10:58:20,688 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/bind_constants_graph.json
2024-07-12 10:58:20,688 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/bind_constants_pseudo_code.txt
2024-07-12 10:58:20,689 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,689 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,692 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/bind_constants_graph_vis.html
2024-07-12 10:58:20,698 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_unused_ops_graph.txt
2024-07-12 10:58:20,699 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_unused_ops_graph.json
2024-07-12 10:58:20,699 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:58:20,699 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,699 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,744 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,745 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,750 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_no_ops_graph.txt
2024-07-12 10:58:20,751 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_no_ops_graph.json
2024-07-12 10:58:20,751 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:58:20,752 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,752 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,756 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/remove_no_ops_graph_vis.html
2024-07-12 10:58:20,756 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,756 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,761 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/name_graph_graph.txt
2024-07-12 10:58:20,762 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/name_graph_graph.json
2024-07-12 10:58:20,762 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/name_graph_pseudo_code.txt
2024-07-12 10:58:20,762 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,762 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,766 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/name_graph_graph_vis.html
2024-07-12 10:58:20,771 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:20,772 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:20,772 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:20,773 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,773 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,777 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:20,782 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/mark_param_tensor_graph.txt
2024-07-12 10:58:20,783 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/mark_param_tensor_graph.json
2024-07-12 10:58:20,783 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:58:20,783 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,783 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,787 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:58:20,787 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,787 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,792 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:58:20,793 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:58:20,793 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:58:20,793 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,793 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,797 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:58:20,797 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:58:20,803 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:58:20,804 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:58:20,804 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:58:20,804 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,804 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,808 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,814 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:58:20,815 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:58:20,815 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:58:20,815 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,815 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,819 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:58:20,824 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:58:20,825 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:58:20,825 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:58:20,825 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,825 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,883 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:58:20,883 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,883 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,888 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:58:20,889 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:58:20,889 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:58:20,889 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,890 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,893 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:58:20,893 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,893 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,899 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:58:20,900 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:58:20,900 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:58:20,900 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,900 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,904 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:58:20,909 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:58:20,910 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:58:20,910 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:58:20,911 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,911 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,914 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:58:20,920 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:58:20,921 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:58:20,921 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:20,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,921 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,925 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:58:20,925 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,925 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,925 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,925 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,930 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:58:20,931 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:58:20,931 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:58:20,932 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,932 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,935 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:58:20,936 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,936 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,941 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:58:20,942 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:58:20,942 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:58:20,942 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,942 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,946 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:58:20,946 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,946 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,951 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:58:20,952 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:58:20,952 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:20,953 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,953 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,957 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:20,962 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/11-merge_view_ops_graph.txt
2024-07-12 10:58:20,963 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/11-merge_view_ops_graph.json
2024-07-12 10:58:20,963 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:58:20,963 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:20,963 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,016 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,017 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,022 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:58:21,023 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/12-transform_memory_ops_graph.json
2024-07-12 10:58:21,023 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:21,024 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,024 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,028 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:58:21,028 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,028 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,034 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/13-fuse_ops_graph.txt
2024-07-12 10:58:21,035 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/13-fuse_ops_graph.json
2024-07-12 10:58:21,035 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:58:21,035 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,035 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,039 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:58:21,041 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, final_set: set()
2024-07-12 10:58:21,044 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, final_set: set()
2024-07-12 10:58:21,046 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_8_0'],
  'name': 'split_9',
  'nop': False,
  'op': 'split',
  'original_name': 'split_9',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 36,
  'values': [36]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_12'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_11_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_11_0_dim_1',
  'nop': False,
  'symbolic_value': 24,
  'values': [24]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_9_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_9'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['elementwise_10_0', 'elementwise_11_0', 'split_9_0'],
  'split_dim': 1,
  'split_sizes': [36, 24, 256]}}, final_set: set()
2024-07-12 10:58:21,046 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=308
2024-07-12 10:58:21,046 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,054 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:58:21,055 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/14-fuse_elementwise_graph.json
2024-07-12 10:58:21,055 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:58:21,056 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,056 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,060 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:58:21,060 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,060 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,060 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,060 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,068 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:58:21,069 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:58:21,069 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:21,070 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,070 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,073 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:58:21,082 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:58:21,083 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/16-fuse_group_ops_graph.json
2024-07-12 10:58:21,083 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:58:21,083 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,083 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,087 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:58:21,095 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/17-transform_special_ops_graph.txt
2024-07-12 10:58:21,097 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/17-transform_special_ops_graph.json
2024-07-12 10:58:21,097 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:58:21,097 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,097 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,101 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:58:21,101 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,101 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,110 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/18-apply_padding_graph.txt
2024-07-12 10:58:21,111 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/18-apply_padding_graph.json
2024-07-12 10:58:21,111 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:58:21,111 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,111 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,115 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/18-apply_padding_graph_vis.html
2024-07-12 10:58:21,115 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,115 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,123 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:58:21,124 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:58:21,124 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:21,125 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,125 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,179 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,188 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:58:21,189 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/20-transform_memory_ops_graph.json
2024-07-12 10:58:21,189 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:21,189 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,189 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,193 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,194 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,202 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:58:21,204 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/21-transform_strided_ops_graph.json
2024-07-12 10:58:21,204 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:58:21,204 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,204 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,208 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:58:21,208 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,208 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,216 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:58:21,217 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:58:21,217 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:58:21,218 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,218 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,222 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:58:21,222 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_6: total_params_size=120
2024-07-12 10:58:21,222 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_7: total_params_size=104
2024-07-12 10:58:21,222 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,222 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,230 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:58:21,231 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:58:21,231 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:58:21,232 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,232 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,236 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:58:21,236 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:58:21,244 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:58:21,245 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/24-split_large_split_ops_graph.json
2024-07-12 10:58:21,245 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:58:21,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,250 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:58:21,258 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:58:21,260 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:58:21,260 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:58:21,260 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,260 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,264 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:58:21,264 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,264 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,264 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,265 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,274 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:58:21,275 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/26-transform_memory_ops_graph.json
2024-07-12 10:58:21,275 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:21,275 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,275 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,279 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:58:21,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,287 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:58:21,289 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/27-eliminate_permutations_graph.json
2024-07-12 10:58:21,289 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:58:21,289 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,289 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,340 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:58:21,340 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,340 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,348 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:58:21,349 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:58:21,349 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:58:21,349 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,350 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,353 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:58:21,361 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/optimize_graph_graph.txt
2024-07-12 10:58:21,362 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/optimize_graph_graph.json
2024-07-12 10:58:21,363 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:58:21,363 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,363 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,367 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/optimize_graph_graph_vis.html
2024-07-12 10:58:21,367 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.579943
2024-07-12 10:58:21,367 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:58:21,367 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 7 to 7
2024-07-12 10:58:21,375 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/refine_graph_graph.txt
2024-07-12 10:58:21,376 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/refine_graph_graph.json
2024-07-12 10:58:21,376 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/refine_graph_pseudo_code.txt
2024-07-12 10:58:21,377 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,377 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,380 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/refine_graph_graph_vis.html
2024-07-12 10:58:21,380 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:58:21,418 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:21,419 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_8 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_4', 0, 1)
2024-07-12 10:58:21,419 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.038359
2024-07-12 10:58:21,419 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:21,419 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000046
2024-07-12 10:58:21,419 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:58:21,419 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_bias_8: M == 1024 && N == 316 && K == 256
2024-07-12 10:58:21,419 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000072
2024-07-12 10:58:21,427 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/profile_graph.txt
2024-07-12 10:58:21,429 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/profile_graph.json
2024-07-12 10:58:21,429 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/profile_pseudo_code.txt
2024-07-12 10:58:21,429 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,429 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,433 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/profile_graph_vis.html
2024-07-12 10:58:21,433 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:21,433 INFO <aitemplate.compiler.transform.memory_planning> max_blob=162432 constant_offset=162496
2024-07-12 10:58:21,433 INFO <aitemplate.backend.codegen> generated 2 function srcs
2024-07-12 10:58:21,434 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,434 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,441 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/constant_folding_graph.txt
2024-07-12 10:58:21,442 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/constant_folding_graph.json
2024-07-12 10:58:21,442 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/constant_folding_pseudo_code.txt
2024-07-12 10:58:21,442 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,442 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,445 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/constant_folding_graph_vis.html
2024-07-12 10:58:21,445 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.011716
2024-07-12 10:58:21,451 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:21,452 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:21,452 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:21,452 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,452 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,455 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:21,455 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:21,455 INFO <aitemplate.compiler.transform.memory_planning> max_blob=1892352 constant_offset=162432
2024-07-12 10:58:21,462 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/memory_planning_graph.txt
2024-07-12 10:58:21,463 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/memory_planning_graph.json
2024-07-12 10:58:21,463 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/memory_planning_pseudo_code.txt
2024-07-12 10:58:21,463 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,463 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:21,466 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16/memory_planning_graph_vis.html
2024-07-12 10:58:21,467 INFO <aitemplate.backend.codegen> generated 5 function srcs
2024-07-12 10:58:21,469 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:58:21,469 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:21,481 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_gemm_rcr_bias_float16 -j24 all ']
2024-07-12 10:58:29,691 DEBUG <aitemplate.backend.builder> make stdout:

make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
rm -f *.obj test_0.so
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
ld -r -b binary -o constants.obj constants.bin && objcopy --rename-section .data=.lrodata,alloc,load,readonly,data,contents constants.obj constants.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_0.obj fused_elementwise_0.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_1.obj fused_elementwise_1.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o split_9.obj split_9.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o fused_elementwise_2.obj fused_elementwise_2.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_6_constant_folding.obj concatenate_6_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o concatenate_7_constant_folding.obj concatenate_7_constant_folding.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o debug_utility.obj debug_utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o utility.obj utility.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o gemm_rcr_bias_8.obj gemm_rcr_bias_8.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container_base.obj model_container_base.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_interface.obj model_interface.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -t=0 -DCUTLASS_ENABLE_TENSOR_CORE_MMA=1 -w -gencode=arch=compute_80,code=[sm_80,compute_80] -O3 -std=c++17 --expt-relaxed-constexpr -DCUTLASS_DEBUG_TRACE_LEVEL=0 -DNDEBUG --use_fast_math -DAIT_USE_FAST_MATH=1 -Xcompiler=-fPIC -Xcompiler=-Wconversion -Xcompiler=-fno-strict-aliasing -Xcompiler -fvisibility=hidden -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/../static/include/kernels -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/tools/util/include -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/35_gemm_softmax -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/41_fused_multi_head_attention -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/examples/45_dual_gemm -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/./ -I/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/3rdparty/cutlass/../../backend/cuda/attention/src/fmha -c -o model_container.obj model_container.cu
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
make: Entering directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'
nvcc -shared -Xcompiler=-fPIC  -o test_0.so gemm_rcr_bias_8.obj split_9.obj fused_elementwise_0.obj fused_elementwise_1.obj fused_elementwise_2.obj concatenate_6_constant_folding.obj concatenate_7_constant_folding.obj constants.obj model_container_base.obj model_interface.obj debug_utility.obj utility.obj model_container.obj
make: Leaving directory '/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/tmp/fuse_single_source_parallel_gemm_rcr_bias_float16'

2024-07-12 10:58:29,691 DEBUG <aitemplate.backend.builder> make stderr:

/usr/bin/ld: warning: constants.obj: missing .note.GNU-stack section implies executable stack
/usr/bin/ld: NOTE: This behaviour is deprecated and will be removed in a future version of the linker

2024-07-12 10:58:29,691 INFO <aitemplate.compiler.compiler> compiled the final .so file elapsed time: 0:00:08.221570, with optimize = True
[10:58:29] model_container.cu:69: Device Runtime Version: 12000; Driver Version: 12020
[10:58:29] model_container.cu:83: Hardware accelerator device properties: 
  Device: 
     ASCII string identifying device: NVIDIA GeForce RTX 3090
     Major compute capability: 8
     Minor compute capability: 6
     UUID: GPU-a32e9269-82b6-22e9-8823-255bdb380fc1
     Unique identifier for a group of devices on the same multi-GPU board: 0
     PCI bus ID of the device: 1
     PCI device ID of the device: 0
     PCI domain ID of the device: 0
  Memory limits: 
     Constant memory available on device in bytes: 65536
     Global memory available on device in bytes: 25438126080
     Size of L2 cache in bytes: 6291456
     Shared memory available per block in bytes: 49152
     Shared memory available per multiprocessor in bytes: 102400
[10:58:29] model_container.cu:87: Init AITemplate Runtime with 1 concurrency
.2024-07-12 10:58:29,701 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=308
2024-07-12 10:58:29,701 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=16, tensor_cnt=0, len(func_name_to_tensor_cnt)=16, len(user_provided_dim)=308
2024-07-12 10:58:29,702 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=16, tensor_cnt=0, len(func_name_to_tensor_cnt)=16, len(user_provided_dim)=308
2024-07-12 10:58:29,702 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=19, tensor_cnt=0, len(func_name_to_tensor_cnt)=19, len(user_provided_dim)=311
2024-07-12 10:58:29,703 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_single_source_parallel_mix_gemm_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:58:29,703 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:58:29,704 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:58:29,704 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:58:29,704 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
2024-07-12 10:58:30,324 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/toposort_graph.txt
2024-07-12 10:58:30,326 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/toposort_graph.json
2024-07-12 10:58:30,326 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/toposort_pseudo_code.txt
2024-07-12 10:58:30,326 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=311
2024-07-12 10:58:30,326 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,333 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/toposort_graph_vis.html
2024-07-12 10:58:30,343 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/bind_constants_graph.txt
2024-07-12 10:58:30,345 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/bind_constants_graph.json
2024-07-12 10:58:30,345 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/bind_constants_pseudo_code.txt
2024-07-12 10:58:30,345 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,345 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,399 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/bind_constants_graph_vis.html
2024-07-12 10:58:30,409 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_unused_ops_graph.txt
2024-07-12 10:58:30,411 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_unused_ops_graph.json
2024-07-12 10:58:30,411 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:58:30,411 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,411 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,418 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,428 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_no_ops_graph.txt
2024-07-12 10:58:30,429 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_no_ops_graph.json
2024-07-12 10:58:30,429 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:58:30,429 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,429 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,436 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/remove_no_ops_graph_vis.html
2024-07-12 10:58:30,436 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,436 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,445 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/name_graph_graph.txt
2024-07-12 10:58:30,446 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/name_graph_graph.json
2024-07-12 10:58:30,447 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/name_graph_pseudo_code.txt
2024-07-12 10:58:30,447 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,447 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,453 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/name_graph_graph_vis.html
2024-07-12 10:58:30,463 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:30,464 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:30,464 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:30,465 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,465 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,517 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:30,527 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/mark_param_tensor_graph.txt
2024-07-12 10:58:30,528 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/mark_param_tensor_graph.json
2024-07-12 10:58:30,528 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:58:30,529 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,529 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,535 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:58:30,535 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,535 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,544 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:58:30,546 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:58:30,546 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:58:30,546 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,546 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,552 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:58:30,552 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:58:30,562 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:58:30,563 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:58:30,563 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:58:30,564 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,564 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,570 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,571 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,580 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:58:30,582 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:58:30,582 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:58:30,582 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,582 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,635 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:58:30,644 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:58:30,646 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:58:30,646 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:58:30,646 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,646 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,653 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:58:30,653 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,653 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,662 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:58:30,664 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:58:30,664 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:58:30,664 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,664 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,671 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:58:30,671 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,671 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,680 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:58:30,682 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:58:30,682 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:58:30,682 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,682 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,689 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:58:30,699 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:58:30,700 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:58:30,700 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:58:30,700 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,700 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,754 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:58:30,764 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:58:30,765 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:58:30,765 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:30,766 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,766 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,772 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:58:30,772 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,772 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,772 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,772 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,783 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:58:30,784 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:58:30,784 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:58:30,785 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,785 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,791 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:58:30,791 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,791 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,801 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:58:30,803 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:58:30,803 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:58:30,803 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,803 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,810 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:58:30,810 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,810 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,819 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:58:30,821 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:58:30,821 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:30,821 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,821 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,828 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:30,837 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/11-merge_view_ops_graph.txt
2024-07-12 10:58:30,838 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/11-merge_view_ops_graph.json
2024-07-12 10:58:30,839 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:58:30,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,912 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,913 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,923 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:58:30,925 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/12-transform_memory_ops_graph.json
2024-07-12 10:58:30,925 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:30,926 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,926 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,934 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:58:30,934 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,934 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,944 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/13-fuse_ops_graph.txt
2024-07-12 10:58:30,946 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/13-fuse_ops_graph.json
2024-07-12 10:58:30,946 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:58:30,946 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,955 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:58:30,957 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, final_set: set()
2024-07-12 10:58:30,959 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, final_set: set()
2024-07-12 10:58:30,961 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_17_0'],
  'name': 'split_18',
  'nop': False,
  'op': 'split',
  'original_name': 'split_18',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_2_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_6'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_1_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_4'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_18_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_18_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_18'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_18_2', 'split_18_1', 'split_18_0'],
  'split_dim': 1,
  'split_sizes': [32, 128, 256]}}, final_set: set()
2024-07-12 10:58:30,963 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, final_set: set()
2024-07-12 10:58:30,966 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, final_set: set()
2024-07-12 10:58:30,968 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_bias_11_0'],
  'name': 'split_12',
  'nop': False,
  'op': 'split',
  'original_name': 'split_12',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_13'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_12_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_12_0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_14'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_13_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_13_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_15'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_14_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_14_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_12'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_12_0', 'elementwise_13_0', 'elementwise_14_0'],
  'split_dim': 1,
  'split_sizes': [512, 128, 32]}}, final_set: set()
2024-07-12 10:58:30,968 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:30,968 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,984 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:58:30,987 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/14-fuse_elementwise_graph.json
2024-07-12 10:58:30,987 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:58:30,987 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,987 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,995 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:58:30,995 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,995 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,995 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:30,995 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,011 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:58:31,013 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:58:31,014 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:31,014 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,014 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,077 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:58:31,093 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:58:31,095 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/16-fuse_group_ops_graph.json
2024-07-12 10:58:31,095 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:58:31,095 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,095 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,102 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:58:31,117 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/17-transform_special_ops_graph.txt
2024-07-12 10:58:31,119 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/17-transform_special_ops_graph.json
2024-07-12 10:58:31,119 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:58:31,119 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,119 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,126 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:58:31,126 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,126 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,142 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/18-apply_padding_graph.txt
2024-07-12 10:58:31,144 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/18-apply_padding_graph.json
2024-07-12 10:58:31,144 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:58:31,144 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,144 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,151 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/18-apply_padding_graph_vis.html
2024-07-12 10:58:31,151 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,152 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,167 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:58:31,169 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:58:31,170 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:31,170 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,170 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,223 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,224 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,224 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,239 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:58:31,241 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/20-transform_memory_ops_graph.json
2024-07-12 10:58:31,241 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:31,242 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,242 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,248 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,249 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,265 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:58:31,267 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/21-transform_strided_ops_graph.json
2024-07-12 10:58:31,267 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:58:31,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,273 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:58:31,273 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,273 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,291 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:58:31,293 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:58:31,293 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:58:31,293 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,293 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,306 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:58:31,306 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_7: total_params_size=120
2024-07-12 10:58:31,306 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_16: total_params_size=120
2024-07-12 10:58:31,306 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_10: total_params_size=104
2024-07-12 10:58:31,306 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,307 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,403 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:58:31,416 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:58:31,417 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:58:31,420 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,421 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,543 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:58:31,543 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:58:31,543 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:58:31,558 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:58:31,561 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/24-split_large_split_ops_graph.json
2024-07-12 10:58:31,561 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:58:31,561 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,561 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,569 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:58:31,585 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:58:31,588 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:58:31,588 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:58:31,588 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,588 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,596 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,597 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,597 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,597 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,597 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,613 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:58:31,616 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/26-transform_memory_ops_graph.json
2024-07-12 10:58:31,617 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:31,617 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,618 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,627 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:58:31,627 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,627 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,644 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:58:31,647 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/27-eliminate_permutations_graph.json
2024-07-12 10:58:31,647 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:58:31,648 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,648 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,656 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:58:31,656 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,656 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,673 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:58:31,676 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:58:31,676 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:58:31,676 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,676 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,762 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:58:31,779 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/optimize_graph_graph.txt
2024-07-12 10:58:31,782 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/optimize_graph_graph.json
2024-07-12 10:58:31,782 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:58:31,782 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,782 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,791 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/optimize_graph_graph_vis.html
2024-07-12 10:58:31,791 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:01.255877
2024-07-12 10:58:31,791 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: {'fused_elementwise'}
2024-07-12 10:58:31,791 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 13 to 11
2024-07-12 10:58:31,807 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/refine_graph_graph.txt
2024-07-12 10:58:31,810 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/refine_graph_graph.json
2024-07-12 10:58:31,810 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/refine_graph_pseudo_code.txt
2024-07-12 10:58:31,810 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,810 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,819 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/refine_graph_graph_vis.html
2024-07-12 10:58:31,819 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:58:31,860 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:31,861 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_17 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8', 0, 1)
2024-07-12 10:58:31,901 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr_bias: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:31,901 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_bias_11 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_tn_align_8_8', 0, 1)
2024-07-12 10:58:31,901 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.082485
2024-07-12 10:58:31,901 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:31,901 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000060
2024-07-12 10:58:31,902 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:58:31,902 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_17: M == 1024 && N == 416 && K == 256
2024-07-12 10:58:31,902 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_bias_11: M == 1024 && N == 672 && K == 256
2024-07-12 10:58:31,902 INFO <aitemplate.compiler.transform.profile> ran 2 profilers elapsed time: 0:00:00.000093
2024-07-12 10:58:31,918 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/profile_graph.txt
2024-07-12 10:58:31,920 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/profile_graph.json
2024-07-12 10:58:31,921 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/profile_pseudo_code.txt
2024-07-12 10:58:31,921 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:31,921 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,001 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/profile_graph_vis.html
2024-07-12 10:58:32,001 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:32,001 INFO <aitemplate.compiler.transform.memory_planning> max_blob=558400 constant_offset=558400
2024-07-12 10:58:32,002 INFO <aitemplate.backend.codegen> generated 3 function srcs
2024-07-12 10:58:32,003 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,003 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,016 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/constant_folding_graph.txt
2024-07-12 10:58:32,019 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/constant_folding_graph.json
2024-07-12 10:58:32,019 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/constant_folding_pseudo_code.txt
2024-07-12 10:58:32,019 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,019 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,024 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/constant_folding_graph_vis.html
2024-07-12 10:58:32,025 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.023772
2024-07-12 10:58:32,038 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:32,040 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:32,040 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:32,041 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,041 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,050 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:32,050 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:32,050 INFO <aitemplate.compiler.transform.memory_planning> max_blob=4915200 constant_offset=558400
2024-07-12 10:58:32,090 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/memory_planning_graph.txt
2024-07-12 10:58:32,100 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_mix_gemm_float16/memory_planning_graph.json
2024-07-12 10:58:32,101 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_single_source_parallel_mix_gemm_float16/memory_planning_pseudo_code.txt
2024-07-12 10:58:32,102 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,103 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:32,131 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_single_source_parallel_mix_gemm_float16/memory_planning_graph_vis.html
2024-07-12 10:58:32,140 INFO <aitemplate.backend.codegen> generated 8 function srcs
2024-07-12 10:58:32,155 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:58:32,155 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:32,189 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_mix_gemm_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_mix_gemm_float16 -j24 all ']
E2024-07-12 10:58:34,199 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=6, tensor_cnt=0, len(func_name_to_tensor_cnt)=6, len(user_provided_dim)=314
2024-07-12 10:58:34,199 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=12, tensor_cnt=0, len(func_name_to_tensor_cnt)=12, len(user_provided_dim)=314
2024-07-12 10:58:34,200 INFO <aitemplate.compiler.compiler> Start to compile AIT model. test_dir='./tmp/fuse_single_source_parallel_gemm_simple_float16', with recompile = 1, __name__ = aitemplate.compiler.compiler
2024-07-12 10:58:34,200 INFO <aitemplate.backend.target> Loading profile cache from: /home/wewe5215/.aitemplate/cuda.db
2024-07-12 10:58:34,200 INFO <aitemplate.backend.profiler_cache> table_name='cuda_gemm_3' exists in the db
2024-07-12 10:58:34,201 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv_3' exists in the db
2024-07-12 10:58:34,201 INFO <aitemplate.backend.profiler_cache> table_name='cuda_conv3d_3' exists in the db
/tmp/tmp752848y4/cutlass_lib/library.py:861: ResourceWarning: unclosed file <_io.FileIO name=34 mode='rb' closefd=True>
  def __init__(self, element, layout, alignment = 1, complex_transform = ComplexTransform.none):
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/tmp/tmp752848y4/cutlass_lib/library.py:861: ResourceWarning: unclosed file <_io.FileIO name=36 mode='rb' closefd=True>
  def __init__(self, element, layout, alignment = 1, complex_transform = ComplexTransform.none):
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2024-07-12 10:58:34,798 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/toposort_graph.txt
2024-07-12 10:58:34,799 DEBUG <aitemplate.utils.graph_utils> Dumped toposort graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/toposort_graph.json
2024-07-12 10:58:34,799 DEBUG <aitemplate.utils.graph_utils> Dumped toposort pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/toposort_pseudo_code.txt
2024-07-12 10:58:34,799 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=314
2024-07-12 10:58:34,799 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,803 DEBUG <aitemplate.utils.graph_utils> Dumped toposort visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/toposort_graph_vis.html
2024-07-12 10:58:34,808 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/bind_constants_graph.txt
2024-07-12 10:58:34,809 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/bind_constants_graph.json
2024-07-12 10:58:34,809 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/bind_constants_pseudo_code.txt
2024-07-12 10:58:34,809 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,809 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,813 DEBUG <aitemplate.utils.graph_utils> Dumped bind_constants visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/bind_constants_graph_vis.html
2024-07-12 10:58:34,817 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_unused_ops_graph.txt
2024-07-12 10:58:34,818 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_unused_ops_graph.json
2024-07-12 10:58:34,818 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_unused_ops_pseudo_code.txt
2024-07-12 10:58:34,818 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,819 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.utils.graph_utils> Dumped remove_unused_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_unused_ops_graph_vis.html
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,823 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,828 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_no_ops_graph.txt
2024-07-12 10:58:34,829 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_no_ops_graph.json
2024-07-12 10:58:34,829 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_no_ops_pseudo_code.txt
2024-07-12 10:58:34,829 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,829 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,833 DEBUG <aitemplate.utils.graph_utils> Dumped remove_no_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/remove_no_ops_graph_vis.html
2024-07-12 10:58:34,833 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,833 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,837 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/name_graph_graph.txt
2024-07-12 10:58:34,838 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/name_graph_graph.json
2024-07-12 10:58:34,838 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/name_graph_pseudo_code.txt
2024-07-12 10:58:34,839 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,839 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,911 DEBUG <aitemplate.utils.graph_utils> Dumped name_graph visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/name_graph_graph_vis.html
2024-07-12 10:58:34,915 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:34,916 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:34,917 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:34,917 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,917 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,920 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:34,925 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/mark_param_tensor_graph.txt
2024-07-12 10:58:34,926 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/mark_param_tensor_graph.json
2024-07-12 10:58:34,926 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/mark_param_tensor_pseudo_code.txt
2024-07-12 10:58:34,926 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,926 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,929 DEBUG <aitemplate.utils.graph_utils> Dumped mark_param_tensor visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/mark_param_tensor_graph_vis.html
2024-07-12 10:58:34,929 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,929 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,934 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/00-remove_elementwise_no_ops_graph.txt
2024-07-12 10:58:34,935 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/00-remove_elementwise_no_ops_graph.json
2024-07-12 10:58:34,935 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/00-remove_elementwise_no_ops_pseudo_code.txt
2024-07-12 10:58:34,935 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,935 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,938 DEBUG <aitemplate.utils.graph_utils> Dumped 00-remove_elementwise_no_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/00-remove_elementwise_no_ops_graph_vis.html
2024-07-12 10:58:34,938 DEBUG <aitemplate.compiler.transform.dedup_make_jagged_ops> No make_jagged ops in the graph: skipping.
2024-07-12 10:58:34,942 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/01-dedup_make_jagged_ops_graph.txt
2024-07-12 10:58:34,943 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/01-dedup_make_jagged_ops_graph.json
2024-07-12 10:58:34,943 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/01-dedup_make_jagged_ops_pseudo_code.txt
2024-07-12 10:58:34,943 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,943 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.utils.graph_utils> Dumped 01-dedup_make_jagged_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/01-dedup_make_jagged_ops_graph_vis.html
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,947 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,952 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/02-fuse_permute_bmm_and_gemm_graph.txt
2024-07-12 10:58:34,952 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/02-fuse_permute_bmm_and_gemm_graph.json
2024-07-12 10:58:34,952 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/02-fuse_permute_bmm_and_gemm_pseudo_code.txt
2024-07-12 10:58:34,953 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,953 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,956 DEBUG <aitemplate.utils.graph_utils> Dumped 02-fuse_permute_bmm_and_gemm visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/02-fuse_permute_bmm_and_gemm_graph_vis.html
2024-07-12 10:58:34,960 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/03-fuse_bmm_permute_graph.txt
2024-07-12 10:58:34,961 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/03-fuse_bmm_permute_graph.json
2024-07-12 10:58:34,961 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/03-fuse_bmm_permute_pseudo_code.txt
2024-07-12 10:58:34,961 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,961 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,964 DEBUG <aitemplate.utils.graph_utils> Dumped 03-fuse_bmm_permute visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/03-fuse_bmm_permute_graph_vis.html
2024-07-12 10:58:34,965 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,965 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,969 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/04-fuse_expand_bmm_graph.txt
2024-07-12 10:58:34,970 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/04-fuse_expand_bmm_graph.json
2024-07-12 10:58:34,970 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/04-fuse_expand_bmm_pseudo_code.txt
2024-07-12 10:58:34,970 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,970 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,973 DEBUG <aitemplate.utils.graph_utils> Dumped 04-fuse_expand_bmm visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/04-fuse_expand_bmm_graph_vis.html
2024-07-12 10:58:34,973 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,973 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,978 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/05-transform_odd_alignment_graph.txt
2024-07-12 10:58:34,979 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/05-transform_odd_alignment_graph.json
2024-07-12 10:58:34,979 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/05-transform_odd_alignment_pseudo_code.txt
2024-07-12 10:58:34,979 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,979 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,982 DEBUG <aitemplate.utils.graph_utils> Dumped 05-transform_odd_alignment visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/05-transform_odd_alignment_graph_vis.html
2024-07-12 10:58:34,986 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/06-fuse_conv_elementwise_graph.txt
2024-07-12 10:58:34,987 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/06-fuse_conv_elementwise_graph.json
2024-07-12 10:58:34,987 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/06-fuse_conv_elementwise_pseudo_code.txt
2024-07-12 10:58:34,987 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,987 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,991 DEBUG <aitemplate.utils.graph_utils> Dumped 06-fuse_conv_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/06-fuse_conv_elementwise_graph_vis.html
2024-07-12 10:58:34,995 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/07-fuse_single_source_parallel_gemms_graph.txt
2024-07-12 10:58:34,996 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/07-fuse_single_source_parallel_gemms_graph.json
2024-07-12 10:58:34,996 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/07-fuse_single_source_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:34,996 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:34,996 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,047 DEBUG <aitemplate.utils.graph_utils> Dumped 07-fuse_single_source_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/07-fuse_single_source_parallel_gemms_graph_vis.html
2024-07-12 10:58:35,047 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,047 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,047 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,047 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,052 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/08-fuse_mm_elementwise_graph.txt
2024-07-12 10:58:35,053 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/08-fuse_mm_elementwise_graph.json
2024-07-12 10:58:35,053 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/08-fuse_mm_elementwise_pseudo_code.txt
2024-07-12 10:58:35,053 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,053 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,056 DEBUG <aitemplate.utils.graph_utils> Dumped 08-fuse_mm_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/08-fuse_mm_elementwise_graph_vis.html
2024-07-12 10:58:35,056 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,056 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,061 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/09-fuse_mm_reshape_permute_graph.txt
2024-07-12 10:58:35,061 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/09-fuse_mm_reshape_permute_graph.json
2024-07-12 10:58:35,061 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/09-fuse_mm_reshape_permute_pseudo_code.txt
2024-07-12 10:58:35,061 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,061 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,064 DEBUG <aitemplate.utils.graph_utils> Dumped 09-fuse_mm_reshape_permute visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/09-fuse_mm_reshape_permute_graph_vis.html
2024-07-12 10:58:35,064 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,064 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,069 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/10-move_view_op_before_concat_graph.txt
2024-07-12 10:58:35,070 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/10-move_view_op_before_concat_graph.json
2024-07-12 10:58:35,070 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/10-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:35,070 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,070 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,073 DEBUG <aitemplate.utils.graph_utils> Dumped 10-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/10-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:35,077 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/11-merge_view_ops_graph.txt
2024-07-12 10:58:35,078 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/11-merge_view_ops_graph.json
2024-07-12 10:58:35,078 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/11-merge_view_ops_pseudo_code.txt
2024-07-12 10:58:35,078 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,078 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.utils.graph_utils> Dumped 11-merge_view_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/11-merge_view_ops_graph_vis.html
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,082 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,087 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/12-transform_memory_ops_graph.txt
2024-07-12 10:58:35,087 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/12-transform_memory_ops_graph.json
2024-07-12 10:58:35,088 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/12-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:35,088 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,088 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,091 DEBUG <aitemplate.utils.graph_utils> Dumped 12-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/12-transform_memory_ops_graph_vis.html
2024-07-12 10:58:35,091 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,091 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,095 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/13-fuse_ops_graph.txt
2024-07-12 10:58:35,096 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/13-fuse_ops_graph.json
2024-07-12 10:58:35,096 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/13-fuse_ops_pseudo_code.txt
2024-07-12 10:58:35,096 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,096 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,100 DEBUG <aitemplate.utils.graph_utils> Dumped 13-fuse_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/13-fuse_ops_graph_vis.html
2024-07-12 10:58:35,102 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, final_set: set()
2024-07-12 10:58:35,104 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, final_set: set()
2024-07-12 10:58:35,106 DEBUG <aitemplate.compiler.transform.fuse_ops> original op set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, to_be_removed_set: {{ 'depth': 2,
  'has_profiler': False,
  'inputs': ['gemm_rcr_7_0'],
  'name': 'split_8',
  'nop': False,
  'op': 'split',
  'original_name': 'split_8',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_9'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_8_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'split_8_0_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_11'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_10_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_10_0_dim_1',
  'nop': False,
  'symbolic_value': 32,
  'values': [32]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': ['elementwise_10'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'elementwise_9_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'X_dim_0',
  'nop': False,
  'symbolic_value': 1024,
  'values': [1024]},
             { 'depth': 0,
  'name': 'elementwise_9_0_dim_1',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['split_8'],
  'value': None}],
  'output_masks': [True, True, True],
  'outputs': ['split_8_0', 'elementwise_10_0', 'elementwise_9_0'],
  'split_dim': 1,
  'split_sizes': [256, 32, 128]}}, final_set: set()
2024-07-12 10:58:35,106 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=0, tensor_cnt=0, len(func_name_to_tensor_cnt)=0, len(user_provided_dim)=316
2024-07-12 10:58:35,106 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,114 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/14-fuse_elementwise_graph.txt
2024-07-12 10:58:35,115 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/14-fuse_elementwise_graph.json
2024-07-12 10:58:35,115 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/14-fuse_elementwise_pseudo_code.txt
2024-07-12 10:58:35,115 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,115 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,118 DEBUG <aitemplate.utils.graph_utils> Dumped 14-fuse_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/14-fuse_elementwise_graph_vis.html
2024-07-12 10:58:35,118 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,118 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,118 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,118 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,126 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/15-fuse_parallel_gemms_graph.txt
2024-07-12 10:58:35,127 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/15-fuse_parallel_gemms_graph.json
2024-07-12 10:58:35,127 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/15-fuse_parallel_gemms_pseudo_code.txt
2024-07-12 10:58:35,127 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,127 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,131 DEBUG <aitemplate.utils.graph_utils> Dumped 15-fuse_parallel_gemms visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/15-fuse_parallel_gemms_graph_vis.html
2024-07-12 10:58:35,138 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/16-fuse_group_ops_graph.txt
2024-07-12 10:58:35,139 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/16-fuse_group_ops_graph.json
2024-07-12 10:58:35,140 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/16-fuse_group_ops_pseudo_code.txt
2024-07-12 10:58:35,140 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,140 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,143 DEBUG <aitemplate.utils.graph_utils> Dumped 16-fuse_group_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/16-fuse_group_ops_graph_vis.html
2024-07-12 10:58:35,150 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/17-transform_special_ops_graph.txt
2024-07-12 10:58:35,151 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/17-transform_special_ops_graph.json
2024-07-12 10:58:35,151 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/17-transform_special_ops_pseudo_code.txt
2024-07-12 10:58:35,152 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,152 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,154 DEBUG <aitemplate.utils.graph_utils> Dumped 17-transform_special_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/17-transform_special_ops_graph_vis.html
2024-07-12 10:58:35,154 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,154 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,162 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/18-apply_padding_graph.txt
2024-07-12 10:58:35,163 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/18-apply_padding_graph.json
2024-07-12 10:58:35,163 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/18-apply_padding_pseudo_code.txt
2024-07-12 10:58:35,163 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,163 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,221 DEBUG <aitemplate.utils.graph_utils> Dumped 18-apply_padding visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/18-apply_padding_graph_vis.html
2024-07-12 10:58:35,221 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,221 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,228 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/19-move_view_op_before_concat_graph.txt
2024-07-12 10:58:35,229 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/19-move_view_op_before_concat_graph.json
2024-07-12 10:58:35,229 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/19-move_view_op_before_concat_pseudo_code.txt
2024-07-12 10:58:35,230 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,230 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.utils.graph_utils> Dumped 19-move_view_op_before_concat visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/19-move_view_op_before_concat_graph_vis.html
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,233 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,241 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/20-transform_memory_ops_graph.txt
2024-07-12 10:58:35,242 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/20-transform_memory_ops_graph.json
2024-07-12 10:58:35,242 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/20-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:35,242 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,242 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,245 DEBUG <aitemplate.utils.graph_utils> Dumped 20-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/20-transform_memory_ops_graph_vis.html
2024-07-12 10:58:35,245 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,246 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,254 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/21-transform_strided_ops_graph.txt
2024-07-12 10:58:35,255 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/21-transform_strided_ops_graph.json
2024-07-12 10:58:35,255 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/21-transform_strided_ops_pseudo_code.txt
2024-07-12 10:58:35,255 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,255 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,258 DEBUG <aitemplate.utils.graph_utils> Dumped 21-transform_strided_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/21-transform_strided_ops_graph_vis.html
2024-07-12 10:58:35,258 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,258 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,266 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/22-split_large_slice_scatter_ops_graph.txt
2024-07-12 10:58:35,267 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/22-split_large_slice_scatter_ops_graph.json
2024-07-12 10:58:35,267 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/22-split_large_slice_scatter_ops_pseudo_code.txt
2024-07-12 10:58:35,267 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,267 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,270 DEBUG <aitemplate.utils.graph_utils> Dumped 22-split_large_slice_scatter_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/22-split_large_slice_scatter_ops_graph_vis.html
2024-07-12 10:58:35,270 DEBUG <aitemplate.compiler.transform.split_large_concat_ops> concat op concatenate_6: total_params_size=120
2024-07-12 10:58:35,270 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,270 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,278 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/23-split_large_concat_ops_graph.txt
2024-07-12 10:58:35,279 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/23-split_large_concat_ops_graph.json
2024-07-12 10:58:35,279 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/23-split_large_concat_ops_pseudo_code.txt
2024-07-12 10:58:35,279 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,279 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,283 DEBUG <aitemplate.utils.graph_utils> Dumped 23-split_large_concat_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/23-split_large_concat_ops_graph_vis.html
2024-07-12 10:58:35,283 DEBUG <aitemplate.compiler.transform.split_large_split_ops> split op op._attrs["name"]: total_params_size=88
2024-07-12 10:58:35,290 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/24-split_large_split_ops_graph.txt
2024-07-12 10:58:35,291 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/24-split_large_split_ops_graph.json
2024-07-12 10:58:35,291 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/24-split_large_split_ops_pseudo_code.txt
2024-07-12 10:58:35,291 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,291 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,294 DEBUG <aitemplate.utils.graph_utils> Dumped 24-split_large_split_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/24-split_large_split_ops_graph_vis.html
2024-07-12 10:58:35,302 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/25-transform_permute_to_reshape_graph.txt
2024-07-12 10:58:35,303 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/25-transform_permute_to_reshape_graph.json
2024-07-12 10:58:35,304 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/25-transform_permute_to_reshape_pseudo_code.txt
2024-07-12 10:58:35,304 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,304 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.utils.graph_utils> Dumped 25-transform_permute_to_reshape visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/25-transform_permute_to_reshape_graph_vis.html
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,308 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,316 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/26-transform_memory_ops_graph.txt
2024-07-12 10:58:35,317 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/26-transform_memory_ops_graph.json
2024-07-12 10:58:35,317 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/26-transform_memory_ops_pseudo_code.txt
2024-07-12 10:58:35,318 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,318 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,321 DEBUG <aitemplate.utils.graph_utils> Dumped 26-transform_memory_ops visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/26-transform_memory_ops_graph_vis.html
2024-07-12 10:58:35,321 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,321 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,329 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/27-eliminate_permutations_graph.txt
2024-07-12 10:58:35,330 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/27-eliminate_permutations_graph.json
2024-07-12 10:58:35,330 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/27-eliminate_permutations_pseudo_code.txt
2024-07-12 10:58:35,330 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,330 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,334 DEBUG <aitemplate.utils.graph_utils> Dumped 27-eliminate_permutations visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/27-eliminate_permutations_graph_vis.html
2024-07-12 10:58:35,334 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,334 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,341 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/28-fuse_duplicate_fused_elementwise_graph.txt
2024-07-12 10:58:35,342 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/28-fuse_duplicate_fused_elementwise_graph.json
2024-07-12 10:58:35,342 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/28-fuse_duplicate_fused_elementwise_pseudo_code.txt
2024-07-12 10:58:35,343 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,343 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,346 DEBUG <aitemplate.utils.graph_utils> Dumped 28-fuse_duplicate_fused_elementwise visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/28-fuse_duplicate_fused_elementwise_graph_vis.html
2024-07-12 10:58:35,354 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/optimize_graph_graph.txt
2024-07-12 10:58:35,355 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/optimize_graph_graph.json
2024-07-12 10:58:35,355 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/optimize_graph_pseudo_code.txt
2024-07-12 10:58:35,355 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,355 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,442 DEBUG <aitemplate.utils.graph_utils> Dumped optimize_graph visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/optimize_graph_graph_vis.html
2024-07-12 10:58:35,442 INFO <aitemplate.compiler.compiler> optimized graph elapsed time: 0:00:00.512303
2024-07-12 10:58:35,442 DEBUG <aitemplate.compiler.transform.refine_graph> refined ops: set()
2024-07-12 10:58:35,442 INFO <aitemplate.compiler.transform.refine_graph> reduced unique ops from 6 to 6
2024-07-12 10:58:35,449 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/refine_graph_graph.txt
2024-07-12 10:58:35,451 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/refine_graph_graph.json
2024-07-12 10:58:35,451 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/refine_graph_pseudo_code.txt
2024-07-12 10:58:35,451 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,451 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,455 DEBUG <aitemplate.utils.graph_utils> Dumped refine_graph visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/refine_graph_graph_vis.html
2024-07-12 10:58:35,455 INFO <aitemplate.compiler.transform.profile> Force profiler cache = False
2024-07-12 10:58:35,495 DEBUG <aitemplate.compiler.ops.gemm_universal.gemm_common> Filtered profiler kernels for gemm_rcr: reduced the number of generated kernels from 264 to 22
2024-07-12 10:58:35,496 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Load profiling result for gemm_rcr_7 from cache: ('cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8', 0, 1)
2024-07-12 10:58:35,496 INFO <aitemplate.compiler.transform.profile> generated 0 profilers elapsed time: 0:00:00.040821
2024-07-12 10:58:35,496 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:35,496 INFO <aitemplate.compiler.transform.profile> compiled profilers elapsed time: 0:00:00.000055
2024-07-12 10:58:35,496 INFO <aitemplate.backend.profiler_runner> Initialized profiler runner with devices: [0]
2024-07-12 10:58:35,496 INFO <aitemplate.compiler.ops.gemm_universal.gemm_common> Profile: gemm_rcr_7: M == 1024 && N == 416 && K == 256
2024-07-12 10:58:35,496 INFO <aitemplate.compiler.transform.profile> ran 1 profilers elapsed time: 0:00:00.000088
2024-07-12 10:58:35,504 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/profile_graph.txt
2024-07-12 10:58:35,505 DEBUG <aitemplate.utils.graph_utils> Dumped profile graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/profile_graph.json
2024-07-12 10:58:35,505 DEBUG <aitemplate.utils.graph_utils> Dumped profile pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/profile_pseudo_code.txt
2024-07-12 10:58:35,505 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,506 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,509 DEBUG <aitemplate.utils.graph_utils> Dumped profile visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/profile_graph_vis.html
2024-07-12 10:58:35,509 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:35,509 INFO <aitemplate.compiler.transform.memory_planning> max_blob=212992 constant_offset=212992
2024-07-12 10:58:35,510 INFO <aitemplate.backend.codegen> generated 1 function srcs
2024-07-12 10:58:35,510 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,510 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,517 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/constant_folding_graph.txt
2024-07-12 10:58:35,518 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/constant_folding_graph.json
2024-07-12 10:58:35,518 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/constant_folding_pseudo_code.txt
2024-07-12 10:58:35,518 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,518 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,521 DEBUG <aitemplate.utils.graph_utils> Dumped constant_folding visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/constant_folding_graph_vis.html
2024-07-12 10:58:35,521 INFO <aitemplate.compiler.compiler> folded constants elapsed time: 0:00:00.012162
2024-07-12 10:58:35,528 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph.txt
2024-07-12 10:58:35,529 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph.json
2024-07-12 10:58:35,529 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_pseudo_code.txt
2024-07-12 10:58:35,530 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,530 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,532 DEBUG <aitemplate.utils.graph_utils> Dumped dedup_symbolic_name visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/dedup_symbolic_name_graph_vis.html
2024-07-12 10:58:35,532 INFO <aitemplate.compiler.transform.memory_planning> Workspace shared_size=0 unique_size=0
2024-07-12 10:58:35,532 INFO <aitemplate.compiler.transform.memory_planning> max_blob=2490368 constant_offset=212992
2024-07-12 10:58:35,539 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/memory_planning_graph.txt
2024-07-12 10:58:35,540 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning graph to ./tmp/fuse_single_source_parallel_gemm_simple_float16/memory_planning_graph.json
2024-07-12 10:58:35,540 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning pseudo code to ./tmp/fuse_single_source_parallel_gemm_simple_float16/memory_planning_pseudo_code.txt
2024-07-12 10:58:35,540 DEBUG <aitemplate.compiler.transform.name_graph> before name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,540 DEBUG <aitemplate.compiler.transform.name_graph> after name_graph: func_cnt=3, tensor_cnt=0, len(func_name_to_tensor_cnt)=3, len(user_provided_dim)=316
2024-07-12 10:58:35,544 DEBUG <aitemplate.utils.graph_utils> Dumped memory_planning visualization to ./tmp/fuse_single_source_parallel_gemm_simple_float16/memory_planning_graph_vis.html
2024-07-12 10:58:35,545 INFO <aitemplate.backend.codegen> generated 5 function srcs
2024-07-12 10:58:35,547 INFO <aitemplate.backend.codegen> generated 8 library srcs
2024-07-12 10:58:35,547 INFO <aitemplate.backend.builder> Using 24 CPU for building
2024-07-12 10:58:35,559 DEBUG <aitemplate.backend.builder> make cmds=[' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_gemm_simple_float16 clean ', ' /usr/bin/make --output-sync -C ./tmp/fuse_single_source_parallel_gemm_simple_float16 -j24 all ']
E
======================================================================
ERROR: test_fuse_parallel_gemm_cat_partial_fp16 (__main__.ParallelGemmCatFusionTestCase.test_fuse_parallel_gemm_cat_partial_fp16)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 570, in test_fuse_parallel_gemm_cat_partial_fp16
    self._test_fuse_parallel_gemm_cat_partial(4, 4, [128, 256], 32, 64, True)
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 562, in _test_fuse_parallel_gemm_cat_partial
    module.run_with_tensors({"X1": x_pt, "X2": xx_pt}, {"output0": out})
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 597, in run_with_tensors
    outputs_ait = self.run(
                  ^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 495, in run
    return self._run_impl(
           ^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 419, in _run_impl
    inputs = self._dict_to_ordered_list(inputs, is_inputs=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 342, in _dict_to_ordered_list
    raise ValueError(
ValueError: Did not get correct number of inputs expected 1, got 2

======================================================================
ERROR: test_skip_parallel_gemm_cat_groups (__main__.ParallelGemmCatFusionTestCase.test_skip_parallel_gemm_cat_groups)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 729, in test_skip_parallel_gemm_cat_groups
    self._skip_fuse_parallel_gemm_output_cat(
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 720, in _skip_fuse_parallel_gemm_output_cat
    module.run_with_tensors([x_pt], out)
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 597, in run_with_tensors
    outputs_ait = self.run(
                  ^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 495, in run
    return self._run_impl(
           ^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 434, in _run_impl
    self.DLL.AITemplateModelContainerRun(
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/model.py", line 196, in _wrapped_func
    raise RuntimeError(f"Error in function: {method.__name__}")
RuntimeError: Error in function: AITemplateModelContainerRun

======================================================================
ERROR: test_mix_gemm (__main__.SingleSourceParallelGemmFusionTestCase.test_mix_gemm)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 165, in _run_make_cmds
    out, err = proc.communicate(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/subprocess.py", line 1209, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/subprocess.py", line 2115, in _communicate
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 958, in test_mix_gemm
    with compile_model(
         ^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/utils/misc.py", line 93, in inner_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/compiler.py", line 343, in compile_model
    compile_engine.make(
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 914, in make
    _run_make_cmds(cmds, self._timeout, build_dir, allow_cache=allow_cache)
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 175, in _run_make_cmds
    stdout = out.decode()
             ^^^
UnboundLocalError: cannot access local variable 'out' where it is not associated with a value

======================================================================
ERROR: test_simple_gemm_rcr (__main__.SingleSourceParallelGemmFusionTestCase.test_simple_gemm_rcr)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 165, in _run_make_cmds
    out, err = proc.communicate(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/subprocess.py", line 1209, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/subprocess.py", line 2115, in _communicate
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wewe5215/Desktop/AITemplate/tests/unittest/compiler/test_parallel_gemm_fusions.py", line 790, in test_simple_gemm_rcr
    with compile_model(
         ^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/utils/misc.py", line 93, in inner_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/compiler/compiler.py", line 343, in compile_model
    compile_engine.make(
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 914, in make
    _run_make_cmds(cmds, self._timeout, build_dir, allow_cache=allow_cache)
  File "/home/wewe5215/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/aitemplate/backend/builder.py", line 175, in _run_make_cmds
    stdout = out.decode()
             ^^^
UnboundLocalError: cannot access local variable 'out' where it is not associated with a value

----------------------------------------------------------------------
Ran 10 tests in 270.617s

FAILED (errors=4)
