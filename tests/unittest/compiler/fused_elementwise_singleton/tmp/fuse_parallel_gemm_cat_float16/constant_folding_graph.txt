Tensors: { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 0,
  'dst_ops': ['split_0'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': True,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'X',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'X_dim_1',
  'nop': False,
  'symbolic_value': 256,
  'values': [256]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a13f21ac0>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'W0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'W0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
             { 'depth': 0,
  'name': 'W0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a1065d7f0>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'B0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'B0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a1f3718e0>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'W1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'W1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
             { 'depth': 0,
  'name': 'W1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a13f21e80>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'B1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'B1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a13f21160>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'W2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'W2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
             { 'depth': 0,
  'name': 'W2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a13f23f20>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'B2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'B2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f7a13f35940>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'W3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'W3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
             { 'depth': 0,
  'name': 'W3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': <aitemplate.compiler.base._TorchConstantTensorData object at 0x7f79fd74bb60>,
  'depth': 0,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': True,
  'is_view_of': None,
  'name': 'B3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'B3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': [],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['concatenate_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': True,
  'is_param': False,
  'is_view_of': None,
  'name': 'output1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'W0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['gemm_rcr_bias_1'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['concatenate_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': True,
  'is_param': False,
  'is_view_of': None,
  'name': 'output2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'W1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['gemm_rcr_bias_1'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['concatenate_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': True,
  'is_param': False,
  'is_view_of': None,
  'name': 'output3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'W2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['gemm_rcr_bias_1'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 2,
  'dst_ops': ['concatenate_5'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': True,
  'is_param': False,
  'is_view_of': None,
  'name': 'output4',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'W3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'skip_constant_folding': False,
  'src_ops': ['gemm_rcr_bias_1'],
  'value': None}

{ 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 3,
  'dst_ops': [],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': True,
  'is_param': False,
  'is_view_of': None,
  'name': 'output0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'output0_dim_1',
  'nop': False,
  'symbolic_value': 512,
  'values': [512]}],
  'skip_constant_folding': False,
  'src_ops': ['concatenate_5'],
  'value': None}

Operators: { 'depth': 0,
  'has_profiler': False,
  'inputs': ['X'],
  'name': 'split_0',
  'nop': False,
  'op': 'split',
  'original_name': 'split_0',
  'original_outputs': [ { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_2',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_3',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_0',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None},
                        { 'check_nan_and_inf': False,
  'check_outputs': False,
  'constant_folding_output_idx': None,
  'data': None,
  'depth': 1,
  'dst_ops': ['gemm_rcr_bias_1'],
  'dtype': 'float16',
  'external_tensor': None,
  'has_output_aliases': False,
  'is_input': False,
  'is_internal_constant': False,
  'is_output': False,
  'is_param': False,
  'is_view_of': None,
  'name': 'split_0_1',
  'nop': False,
  'offset': None,
  'original_name': None,
  'shape': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
             { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'skip_constant_folding': False,
  'src_ops': ['split_0'],
  'value': None}],
  'output_masks': [True, True, True, True],
  'outputs': ['split_0_2', 'split_0_3', 'split_0_0', 'split_0_1'],
  'split_dim': 1,
  'split_sizes': [64, 64, 64, 64]}

{ 'alpha': 1.0,
  'depth': 1,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'exec_path': OrderedDict([ ( 'M == 512 && N == 128 && K == 64',
                               ExecItem(profiling_key='M == 512 && N == 128 && '
                                                      'K == 64',
                                        exec_cond='M >= 256 && M <= 512 && N '
                                                  '== 128 && K == 64',
                                        algo='cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8'))]),
  'f_ab_alignment': <function gemm_rcr.__init__.<locals>.cal_align_ab at 0x7f7a1145a520>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'split_0_2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'W0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
                       { 'depth': 0,
  'name': 'W0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'B0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['split_0_2', 'W0', 'B0'],
  'name': 'gemm_rcr_bias_1',
  'nop': False,
  'num_sources': 0,
  'op': 'gemm_rcr_bias',
  'op_instance': OrderedDict([ ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11446360>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113206b0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11320d70>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11300830>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11302690>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137c530>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137e390>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11394230>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11396090>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11397ef0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11339d90>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1133bbf0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113d5a90>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113d78f0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11349790>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1134aa50>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1134b410>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113b73b0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113b6210>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113b5fd0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113b5310>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1134bfb0>)]),
  'original_name': 'gemm_rcr_bias_1',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['output1'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0}

{ 'alpha': 1.0,
  'depth': 1,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'exec_path': OrderedDict([ ( 'M == 512 && N == 128 && K == 64',
                               ExecItem(profiling_key='M == 512 && N == 128 && '
                                                      'K == 64',
                                        exec_cond='M >= 256 && M <= 512 && N '
                                                  '== 128 && K == 64',
                                        algo='cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8'))]),
  'f_ab_alignment': <function gemm_rcr.__init__.<locals>.cal_align_ab at 0x7f7a1145b600>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'split_0_3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'W1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
                       { 'depth': 0,
  'name': 'W1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'B1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['split_0_3', 'W1', 'B1'],
  'name': 'gemm_rcr_bias_1',
  'nop': False,
  'num_sources': 0,
  'op': 'gemm_rcr_bias',
  'op_instance': OrderedDict([ ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11397320>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11396390>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137fe60>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137e750>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f79fdf283e0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f79fdf28440>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10749ca0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107d7b60>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11395940>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137d070>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114dbd40>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114d9df0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114c0110>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114c2630>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114c1ca0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140e330>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140c350>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114de480>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114dc590>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140a720>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11408860>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114cce00>)]),
  'original_name': 'gemm_rcr_bias_2',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['output2'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0}

{ 'alpha': 1.0,
  'depth': 1,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'exec_path': OrderedDict([ ( 'M == 512 && N == 128 && K == 64',
                               ExecItem(profiling_key='M == 512 && N == 128 && '
                                                      'K == 64',
                                        exec_cond='M >= 256 && M <= 512 && N '
                                                  '== 128 && K == 64',
                                        algo='cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8'))]),
  'f_ab_alignment': <function gemm_rcr.__init__.<locals>.cal_align_ab at 0x7f7a11458c20>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'split_0_0_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'W2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
                       { 'depth': 0,
  'name': 'W2_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'B2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['split_0_0', 'W2', 'B2'],
  'name': 'gemm_rcr_bias_1',
  'nop': False,
  'num_sources': 0,
  'op': 'gemm_rcr_bias',
  'op_instance': OrderedDict([ ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140ccb0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114c2d20>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140ab40>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a113953d0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137c7a0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114d8bc0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114dda30>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114cc830>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107ea210>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107e84d0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107e8f20>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107ebcb0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114cc5c0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f18ad0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f18170>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f18a70>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f19c10>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10728770>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107281a0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1072b5f0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1072a030>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10729730>)]),
  'original_name': 'gemm_rcr_bias_3',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['output3'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0}

{ 'alpha': 1.0,
  'depth': 1,
  'epilogue': 'LinearCombination',
  'epilogue_alignment': 8,
  'exec_path': OrderedDict([ ( 'M == 512 && N == 128 && K == 64',
                               ExecItem(profiling_key='M == 512 && N == 128 && '
                                                      'K == 64',
                                        exec_cond='M >= 256 && M <= 512 && N '
                                                  '== 128 && K == 64',
                                        algo='cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8'))]),
  'f_ab_alignment': <function gemm_rcr.__init__.<locals>.cal_align_ab at 0x7f7a11458b80>,
  'has_profiler': True,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'split_0_1_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'W3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]},
                       { 'depth': 0,
  'name': 'W3_dim_1',
  'nop': False,
  'symbolic_value': 64,
  'values': [64]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'B3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'inputs': ['split_0_1', 'W3', 'B3'],
  'name': 'gemm_rcr_bias_1',
  'nop': False,
  'num_sources': 0,
  'op': 'gemm_rcr_bias',
  'op_instance': OrderedDict([ ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114df920>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114da510>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1137e3c0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a11395d90>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107ea750>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107eacc0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107ebd40>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_32x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107e9100>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140bd40>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_32x6_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114cd250>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_32x10_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f1aa80>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f19160>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f1bc50>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10f19370>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10728f20>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x4_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1072b140>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_256x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a10729e20>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x256_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1072b680>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a1140fc20>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_128x64_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a114c1df0>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x128_64x3_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107af380>),
                               ( 'cutlass_tensorop_f16_s16816gemm_f16_64x64_64x5_tn_align_8_8',
                                 <cutlass_lib.gemm_operation.GemmOperation object at 0x7f7a107aeff0>)]),
  'original_name': 'gemm_rcr_bias_4',
  'output_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'outputs': ['output4'],
  'permute_shape': '',
  'split_k': 1,
  'workspace': 0}

{ 'concat_dim': 1,
  'depth': 2,
  'fast_cat': True,
  'has_profiler': False,
  'input_accessors': [ { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W0_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W1_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W2_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'},
                       { '_dim_mapping': [([0], [0]), ([1], [1])],
  'actual_shapes': None,
  'actual_total_elements_from_stride_dim': None,
  'is_contiguous': True,
  'is_from_strided_tensor': False,
  'offset': 0,
  'original_shapes': [ { 'depth': 0,
  'name': 'input_batch',
  'nop': False,
  'symbolic_value': input_batch,
  'values': [256, 512]},
                       { 'depth': 0,
  'name': 'W3_dim_0',
  'nop': False,
  'symbolic_value': 128,
  'values': [128]}],
  'original_total_elements_from_stride_dim': None,
  'stride_dim': None,
  'tensor_dtype': 'float16'}],
  'input_masks': [True, True, True, True],
  'inputs': ['output1', 'output2', 'output3', 'output4'],
  'name': 'concatenate_5',
  'nop': False,
  'op': 'concatenate',
  'original_inputs': ['output1', 'output2', 'output3', 'output4'],
  'original_name': 'concatenate_5',
  'outputs': ['output0']}

